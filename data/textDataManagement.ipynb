{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping UK asylum data (18 October 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook scraps the tribunal decision's data related to asylum applications from https://tribunalsdecisions.service.gov.uk/\n",
    "\n",
    "The script mac_env.sh should be run from the terminal to install the necessary libraries and to activate the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current environment: /Users/albertamurgopacheco/anaconda3/envs/tfm/bin/python\n",
      "Current working directory: /Users/albertamurgopacheco/Documents/GitHub/TFM\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join, getsize\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import whois\n",
    "import sys\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import textract\n",
    "\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "\n",
    "# What environment am I using?\n",
    "print(f'Current environment: {sys.executable}')\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir('/Users/albertamurgopacheco/Documents/GitHub/TFM')\n",
    "# What's my working directory?\n",
    "print(f'Current working directory: {os.getcwd()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define working directories in colab and local execution\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    docs_path = '/content/gdrive/MyDrive/TFM/data/raw'\n",
    "    input_path = '/content/gdrive/MyDrive/TFM'\n",
    "    output_path = '/content/gdrive/MyDrive/TFM/output'\n",
    "\n",
    "else:\n",
    "    docs_path = './data/raw'\n",
    "    input_path = '.'\n",
    "    output_path = './output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD DOCUMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all files in docs_path (name, size and last modification_time)\n",
    "files_name_list_raw = [f for f in listdir(docs_path) if isfile(join(docs_path, f))]\n",
    "files_size_list = [getsize(join(docs_path, f)) for f in listdir(docs_path) if isfile(join(docs_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 34953\n",
      "Number of unique file names: 34953\n",
      "Number of unique file sizes: 34953\n"
     ]
    }
   ],
   "source": [
    "# Obtain/check number of files\n",
    "print('Number of files:', len(files_name_list_raw))\n",
    "# Unique files based on size file_name\n",
    "print('Number of unique file names:', len(set(files_name_list_raw)))\n",
    "# Unique files based on size file_name\n",
    "print('Number of unique file sizes:', len(set(files_name_list_raw)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicated files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate something from the file name\n",
    "#files_name_list = [re.sub('^\\d*_|\\.\\w{3}\\Z', '', file_name) for file_name in files_name_list_raw]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to obtain the data from the court's decision detailed page using beautifulSoup.     TO DO: 2. Try with different files make sure it works, 3. Capture exceptions and 204 responses. 4. Create function, 5. How am I storing the dicts? In a list? 5. Try function with just a few obs. https://stackoverflow.com/questions/20638006/convert-list-of-dictionaries-to-a-pandas-dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 16366/34952 [25:02<28:26, 10.89it/s]\n"
     ]
    },
    {
     "ename": "ShellError",
     "evalue": "The command `antiword ./data/raw/HU077022015.doc` failed with exit code 1\n------------- stdout -------------\nb''------------- stderr -------------\nb'./data/raw/HU077022015.doc is not a Word Document.\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mShellError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fc/h07gydfn7nd0zq3mglwpn3r40000gn/T/ipykernel_4084/2960934521.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Extract text from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Create and open the new and we prepare to write the Binary Data which is represented by the wb - Write Binary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfm/lib/python3.8/site-packages/textract/parsers/__init__.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(filename, input_encoding, output_encoding, extension, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiletype_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfm/lib/python3.8/site-packages/textract/parsers/utils.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, filename, input_encoding, output_encoding, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# output encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# http://nedbatchelder.com/text/unipain/unipain.html#35\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mbyte_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0municode_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0municode_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfm/lib/python3.8/site-packages/textract/parsers/doc_parser.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, filename, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'antiword'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfm/lib/python3.8/site-packages/textract/parsers/utils.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# if pipe is busted, raise an error (unlike Fabric)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             raise exceptions.ShellError(\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             )\n",
      "\u001b[0;31mShellError\u001b[0m: The command `antiword ./data/raw/HU077022015.doc` failed with exit code 1\n------------- stdout -------------\nb''------------- stderr -------------\nb'./data/raw/HU077022015.doc is not a Word Document.\\n'"
     ]
    }
   ],
   "source": [
    "# Delete DS_Store files in raw data folder\n",
    "!find . -name '.DS_Store' -type f -delete\n",
    "\n",
    "# Destination directory of txt files\n",
    "dest_files_path = os.path.join(os.getcwd(), 'data/processed/txt_files')\n",
    "\n",
    "# Loop to extract txt from word files (with decorator progress bar)\n",
    "for word_file in  tqdm(os.listdir(docs_path)):\n",
    "    file, extension = os.path.splitext(word_file)\n",
    "    \n",
    "    # Create txt file concatenating .txt extension to file name\n",
    "    dest_file_name = file + '.txt'\n",
    "    \n",
    "    # Extract text from the file\n",
    "    content = textract.process(os.path.join(docs_path, word_file))\n",
    "    \n",
    "    # Create and open new file & prepare to write the Binary Data (represented by wb - Write Binary)\n",
    "    write_text_file = open(os.path.join(dest_files_path, dest_file_name), \"wb\")\n",
    "    \n",
    "    # Write the content and close the newly created file\n",
    "    write_text_file.write(content)\n",
    "    write_text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined all the necessary functions, we can open a browser and start scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Obtain a dataframe with the link and the date of each of the tribunal decisions. \n",
    "  1. GET DATES\n",
    " 2. Build function that gets data per page\n",
    " 3. Loop over 1667 pages and append the lists\n",
    " 4. Build dataframe or iterate over each list to 1) open url 2) extract additional content, and 3) download file using class doc-file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we scrape the detailed data on each tribunal decission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0da6e46dab1e0b3d9fa32aec1170dd2df7038a4f7be3a54c97a348d8ad782954"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('tfm': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
