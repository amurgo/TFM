{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word3Vec (11th November 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook applies word2vec to the corpus of tribunal decisions.\n",
    "\n",
    "In particular, the notebook does:\n",
    "\n",
    "1. Data preparation for word2vec.\n",
    "\n",
    "2. Implementation of word2vec.\n",
    "\n",
    "3. Topic model with Latent Dirichlet Allocation (LDA) and Latent Semantic Indexing (LSI).\n",
    "\n",
    "4. Key word extraction\n",
    "\n",
    "The resulting trained model is... .\n",
    "\n",
    "This notebook should run in the tfm environment, which can be created with the environment.yml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current environment: /Users/albertamurgopacheco/anaconda3/envs/tfm/bin/python\n",
      "Current working directory: /Users/albertamurgopacheco/Documents/GitHub/TFM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/albertamurgopacheco/anaconda3/envs/tfm/lib/python3.8/site-packages/matplotlib_inline/config.py:66: DeprecationWarning: InlineBackend._figure_formats_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n",
      "  def _figure_formats_changed(self, name, old, new):\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join, getsize\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import whois\n",
    "import sys\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import textract\n",
    "import gensim\n",
    "import spacy\n",
    "import scipy as sp\n",
    "import sys\n",
    "import multiprocessing\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel, LdaMulticore\n",
    "import gensim.downloader as api\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import strip_tags\n",
    "from gensim.parsing.preprocessing import strip_punctuation\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces\n",
    "from gensim.parsing.preprocessing import strip_non_alphanum\n",
    "from gensim.parsing.preprocessing import strip_numeric\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "import logging\n",
    "\n",
    "from smart_open import smart_open\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "from collections import defaultdict  # For word frequency\n",
    "\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "#import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "\n",
    "# What environment am I using?\n",
    "print(f'Current environment: {sys.executable}')\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir('/Users/albertamurgopacheco/Documents/GitHub/TFM')\n",
    "# What's my working directory?\n",
    "print(f'Current working directory: {os.getcwd()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define working directories in colab and local execution\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    docs_path = '/content/gdrive/MyDrive/TFM/data/raw'\n",
    "    input_path = '/content/gdrive/MyDrive/TFM'\n",
    "    output_path = '/content/gdrive/MyDrive/TFM/output'\n",
    "\n",
    "else:\n",
    "    docs_path = './data/raw'\n",
    "    input_path = '.'\n",
    "    output_path = './output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD2VEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data to a list of documents (corpus) where each document is a judicial decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35305/35305 [00:00<00:00, 210756.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corpus includes 35305 documents.\n",
      "The documents are <class 'str'>.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Open jsonDataFinal file as data\n",
    "with open('./data/jsonDataFinal.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# List to store the judicial decisions\n",
    "corpus = []\n",
    "\n",
    "corruptFiles = ['HU077022015', 'HU029682017']\n",
    "\n",
    "# Search data list of dictionaries for dict where {\"File\":} = file_name\n",
    "for d in tqdm(data):\n",
    "    # Dealing with corrupt and empty files\n",
    "    if d.get('File') not in corruptFiles:\n",
    "        doc = d.get('String')\n",
    "        if doc:\n",
    "            corpus.append(doc)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "print(f'The corpus includes {len(corpus)} documents.')\n",
    "print(f'The documents are {type(corpus[0])}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim-implemented filters for preprocessing data\n",
    "CUSTOM_FILTERS = [lambda x: x.lower(), strip_tags, strip_punctuation, \n",
    "strip_multiple_whitespaces, strip_non_alphanum, strip_numeric, remove_stopwords]\n",
    "\n",
    "# List storing thr preprocessed documents\n",
    "corpus_clean = [preprocess_string(doc, CUSTOM_FILTERS) for doc in corpus]\n",
    "\n",
    "# Removing non-numerical characters\n",
    "#brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in corpus_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available cores 10.\n"
     ]
    }
   ],
   "source": [
    "# Number of available processing cores\n",
    "cores = multiprocessing.cpu_count()\n",
    "print(f'Available cores {cores}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatizing and removing the stopwords and non-alphabetic characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_7/fl0v9rpx6zg6s4j03vcw0fc40000gn/T/ipykernel_34975/922438625.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mstemmed_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstem_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus_clean\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time to clean up everything: {} mins'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "# IF RAN, DO IT BEFORE CLEANING... \n",
    "\n",
    "import spacy\n",
    "#nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
    "#nlp = spacy.load('en_core_web_sm') # disabling Named Entity Recognition for speed\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def stem_doc(doc):\n",
    "    # Lemmatizes and removes stopwords\n",
    "    # doc needs to be a spacy Doc object\n",
    "    stem_doc = [porter_stemmer.stem(wd) for wd in doc]\n",
    "    # if len(wd) > 2\n",
    "    return stem_doc\n",
    "\n",
    "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
    "    # if a sentence is only one or two words long,\n",
    "    # the benefit for the training is very small\n",
    "\n",
    "#txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size = 50, n_process = cores -1)]\n",
    "stemmed_corpus = [stem_doc(doc) for doc in corpus_clean]\n",
    "\n",
    "#print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pic', 'iac', 'fh', 'ck', 'v', 'upper', 'tribun', 'immigr', 'asylum', 'chamber', 'appeal', 'number', 'hu', 'immigr', 'act']\n"
     ]
    }
   ],
   "source": [
    "print(stemmed_corpus[0][:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Word2Vec uses context words to learn the vector representation of a target word,\n",
    "# if a sentence is only one or two words long,\n",
    "# the benefit for the training is very small\n",
    "\n",
    "def lemmatizer_doc(doc):\n",
    "    # Lemmatizes and removes stopwords\n",
    "    # doc needs to be a spacy Doc object\n",
    "    lemm_doc = [wordnet_lemmatizer.lemmatize(wd) for wd in doc]\n",
    "    # if len(wd) > 2\n",
    "    return lemm_doc\n",
    "\n",
    "\n",
    "\n",
    "# txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size = 50, n_process = cores -1)]\n",
    "lemmatized_corpus = [lemmatizer_doc(doc) for doc in stemmed_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pic', 'iac', 'fh', 'ck', 'v', 'upper', 'tribun', 'immigr', 'asylum', 'chamber', 'appeal', 'number', 'hu', 'immigr', 'act']\n"
     ]
    }
   ],
   "source": [
    "#lemmatized_corpus = lemmatized\n",
    "print(lemmatized_corpus[0][:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting common phrases (multi-word or collocations) expressions from the stream of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [row.split() for row in corpus if row]\n",
    "\n",
    "phrases = Phrases(sent, min_count = 30, progress_per = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90189"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram = Phraser(phrases)\n",
    "\n",
    "#sentences = bigram[corpus_clean]\n",
    "sentences = bigram[lemmatized_corpus]\n",
    "\n",
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_freq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_7/fl0v9rpx6zg6s4j03vcw0fc40000gn/T/ipykernel_23376/2599036840.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_freq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'word_freq' is not defined"
     ]
    }
   ],
   "source": [
    "sorted(word_freq, key = word_freq.get, reverse = True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementation of word2vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word embedding model is a model that can provide numerical vectors for a given word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_model = Word2Vec(min_count = 20,\n",
    "                     window = 10,\n",
    "                     vector_size = 300,\n",
    "                     sample = 6e-5,\n",
    "                     alpha = 0.03,\n",
    "                     min_alpha = 0.0007,\n",
    "                     negative = 20,\n",
    "                     workers = cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per = 10000)\n",
    "\n",
    "#print('Time to build the vocabulary: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w2v_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_7/fl0v9rpx6zg6s4j03vcw0fc40000gn/T/ipykernel_90943/4165752595.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#t = time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'w2v_model' is not defined"
     ]
    }
   ],
   "source": [
    "#t = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples = w2v_model.corpus_count, epochs = 30, report_delay = 1)\n",
    "\n",
    "#print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w2v_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_7/fl0v9rpx6zg6s4j03vcw0fc40000gn/T/ipykernel_90943/342700253.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./output/gensim-model-All_bigrams_lemmatized'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'w2v_model' is not defined"
     ]
    }
   ],
   "source": [
    "w2v_model.save('./output/gensim-model-All_bigrams_lemmatized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lemm = Word2Vec.load('./output/gensim-model-All_bigrams_lemmatized')\n",
    "model = Word2Vec.load('./output/gensim-model-All_bigrams')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.051099308"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.wv.similarity('refugee', 'error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5783935"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lemm.wv.similarity('refuge', 'convent')\n",
    "model_lemm.wv.similarity('refuge', 'geneva')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('refuge', 0.6041285991668701), ('convent', 0.551478922367096), ('stateless_person', 0.45458465814590454), ('protocol', 0.41364872455596924), ('humanitarian', 0.3975497782230377), ('refoul', 0.3917050361633301), ('european', 0.3764244616031647), ('derog', 0.3744756877422333), ('defin', 0.3737797439098358), ('qualif', 0.3719629943370819)]\n"
     ]
    }
   ],
   "source": [
    "word = 'geneva'\n",
    "\n",
    "try:\n",
    "    vec = model_lemm.wv.most_similar(positive = [word])\n",
    "    print(vec)\n",
    "except KeyError:\n",
    "    print(f'The word {word} does not appear in this model')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('refugee_status', 0.6638965010643005),\n",
       " ('refugee_convention', 0.5883638262748718),\n",
       " ('refugees', 0.5871933698654175),\n",
       " ('geneva', 0.5129669308662415),\n",
       " ('granted_refugee', 0.5052950382232666),\n",
       " ('humanitarian_protection', 0.49545037746429443),\n",
       " ('recognised', 0.4840916395187378),\n",
       " ('international_protection', 0.48296958208084106),\n",
       " ('founded_fear', 0.4610556662082672),\n",
       " ('cessation_clause', 0.4556953012943268)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive = [\"refugee\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fingerprint_match', 0.6826852560043335),\n",
       " ('fingerprint', 0.5869845151901245),\n",
       " ('ifb', 0.5495399832725525),\n",
       " ('data', 0.3474268317222595),\n",
       " ('yi', 0.34197482466697693),\n",
       " ('dunkirk', 0.3346039056777954),\n",
       " ('hungari', 0.3305904269218445),\n",
       " ('lookup_tool', 0.3303433656692505),\n",
       " ('match', 0.32926681637763977),\n",
       " ('printout', 0.31014716625213623)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"biometric\"])\n",
    "model_lemm.wv.most_similar(positive=[\"eurodac\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fingerprint_match', 0.7210105061531067),\n",
       " ('fingerprint', 0.6880550980567932),\n",
       " ('fingerprints', 0.5672035217285156),\n",
       " ('ifb', 0.5238295197486877),\n",
       " ('fingerprinted', 0.49927783012390137),\n",
       " ('prints', 0.47691816091537476),\n",
       " ('asu', 0.40677061676979065),\n",
       " ('yi', 0.3775590658187866),\n",
       " ('fingerprinting', 0.3729415237903595),\n",
       " ('hungary', 0.3618243634700775)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"eurodac\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of gensim tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kingdom', 0.7254781723022461),\n",
       " ('united', 0.7136476039886475),\n",
       " ('lawfully', 0.5895837545394897),\n",
       " ('remain', 0.5732899308204651),\n",
       " ('years', 0.5701707005500793),\n",
       " ('leave', 0.5506826639175415),\n",
       " ('lived', 0.5331628322601318),\n",
       " ('aged', 0.5244055390357971),\n",
       " ('overstayed', 0.5227060914039612),\n",
       " ('parents', 0.5147008895874023)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"uk\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odd-One-Out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'remain'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['refuggee', 'uk', 'remain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'eurodac' appeared 241 times in the training corpus.\n",
      "Word 'biometric' appeared 345 times in the training corpus.\n"
     ]
    }
   ],
   "source": [
    "model.wv.doesnt_match(['biometric', 'eurodac', 'identity'])\n",
    "\n",
    "print(f\"Word 'eurodac' appeared {model.wv.get_vecattr('eurodac', 'count')} times in the training corpus.\")\n",
    "print(f\"Word 'biometric' appeared {model.wv.get_vecattr('biometric', 'count')} times in the training corpus.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "data = [d for d in dataset]\n",
    "print(type(data[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(1613 unique tokens: ['abandoned', 'ability', 'able', 'absence', 'accept']...)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize(split) the sentences into words\n",
    "texts = [[text for text in doc.split()] for doc in corpus_pre]\n",
    "\n",
    "# Create dictionary\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# Get information about the dictionary\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the word to id map\n",
    "#print(dictionary.token2id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a bag of words corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the docs\n",
    "tokenized_list = [simple_preprocess(doc) for doc in corpus_pre]\n",
    "\n",
    "# Create the Corpus\n",
    "mydict = corpora.Dictionary()\n",
    "mycorpus = [mydict.doc2bow(doc, allow_update=True) for doc in tokenized_list]\n",
    "#pprint(mycorpus)\n",
    "\n",
    "word_counts = [[(mydict[id], count) for id, count in line] for line in mycorpus]\n",
    "#pprint(word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.doesnt_match(['jimbo', 'milhouse', 'kearney'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Topic model with Latent Dirichlet Allocation (LDA) and Latent Semantic Indexing (LSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of topic models is to extract the underlying topics from a collection of text documents. Each document in the text is considered as a combination of topics and each topic is considered as a combination of related words.\n",
    "\n",
    "Topic modeling can be done by algorithms like Latent Dirichlet Allocation (LDA) and Latent Semantic Indexing (LSI)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1. Latent Dirichlet Allocation (LDA)\n",
    "Each document can be described by a distribution of topics and each topic can be described by a distribution of words. https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel, LdaMulticore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fc/h07gydfn7nd0zq3mglwpn3r40000gn/T/ipykernel_34371/437228251.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# See trigram example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrigram_mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbigram_mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_words' is not defined"
     ]
    }
   ],
   "source": [
    "# Starting from corpus_clean\n",
    "\n",
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(corpus_clean, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[corpus_clean], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See trigram example\n",
    "#print(trigram_mod[bigram_mod[corpus_clean[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['pic', 'upper', 'tribunal', 'immigration', 'asylum', 'chamber', 'appeal', 'number', 'immigration', 'act', 'hear', 'field_house', 'decision', 'reason', 'promulgate', 'extempore', 'upper', 'tribunal', 'judge', 'anonymity', 'direction', 'appellant', 'respondent', 'counsel_instructe', 'consultant', 'office', 'present', 'officer', 'decision', 'reason', 'appellant', 'bear', 'section', 'nationality', 'act', 'decision', 'secretary', 'state', 'refuse', 'application', 'leave', 'remain', 'appeal', 'decision', 'hear', 'tier', 'tribunal', 'march', 'reason', 'set', 'decision', 'refuse', 'reason', 'set', 'decision', 'copy', 'annex', 'decision', 'set', 'aside', 'appellant', 'enter', 'visit', 'visa', 'remain', 'leave', 'form', 'relationship', 'refer', 'sponsor', 'son', 'british', 'previous', 'relationship', 'case', 'long', 'contact', 'child', 'father', 'appellant', 'form', 'parental', 'relationship', 'appellant', 'family', 'live', 'relatively', 'recently', 'sponsor', 'employ', 'secretary', 'state', 'case', 'tier', 'tribunal', 'requirement', 'immigration', 'rule', 'accept', 'appellant', 'establish', 'parental', 'relationship', 'judge', 'tier', 'tribunal', 'number', 'finding', 'requirement', 'immigration', 'rule', 'meet', 'challenge', 'subsist', 'relationship', 'appellant', 'sponsor', 'genuine_subsiste', 'relationship', 'enjoy', 'family', 'best_interest', 'remain', 'balance', 'reasonable_expect', 'leave', 'united', 'away', 'tie', 'judge', 'interference', 'appellant', 'right', 'respect', 'family', 'life', 'leave', 'dismiss', 'appeal', 'basis', 'appellant', 'seek', 'permission', 'appeal', 'decision', 'grant', 'tier', 'tribunal', 'judge', 'subsequent', 'secretary', 'state', 'letter', 'pursuant', 'rule', 'procedure', 'rule', 'state', 'oppose', 'application', 'permission', 'ask', 'tribunal', 'determine', 'appeal', 'fresh', 'oral', 'decision', 'basis', 'decision', 'tier', 'tribunal', 'involve', 'make', 'error', 'law', 'need', 'hear', 'certain', 'finding', 'tier', 'tribunal', 'preserve', 'subsist', 'family', 'life', 'appellant', 'partner', 'identify', 'necessary', 'consider', 'parental', 'relationship', 'appellant', 'hear', 'evidence', 'appellant', 'sponsor', 'adopt', 'witness', 'statement', 'give', 'evidence', 'assistance', 'court', 'interpreter', 'cross_examine', 'tufan', 'behalf', 'secretary', 'state', 'evidence', 'appellant', 'confusing', 'wife', 'work', 'nature', 'work', 'unfortunately', 'documentary', 'evidence', 'nature', 'work', 'payslip', 'take', 'evidence', 'look', 'round', 'accept', 'cease', 'work', 'work', 'confusion', 'online', 'company', 'think', 'company', 'fulfil', 'online', 'order', 'matter', 'entirely', 'clear', 'accept', 'sponsor', 'evidence', 'familiar', 'computer', 'work', 'online', 'capacity', 'misgiving', 'evidence', 'point', 'satisfied', 'relationship', 'subsist', 'accept', 'sponsor', 'receipt', 'sense', 'give', 'previously', 'employ', 'dispute', 'receipt', 'child', 'benefit', 'normal', 'circumstance', 'term', 'article', 'accept', 'meet', 'requirement', 'immigration', 'rule', 'start', 'point', 'assessment', 'position', 'respect', 'article', 'right', 'case', 'regard', 'section', 'act', 'start', 'point', 'appellant', 'requirement', 'immigration', 'rule', 'unlawfully', 'expectation', 'able', 'stay', 'take', 'starting', 'point', 'consider', 'subparagraph', 'section', 'apply', 'start', 'point', 'normally', 'heavy', 'weight', 'attach', 'favour', 'removal', 'give', 'failure', 'meet', 'requirement', 'immigration', 'rule', 'appellant', 'show', 'ability', 'speak', 'english', 'matter', 'financially_independent', 'factor', 'normally', 'weigh', 'similarly', 'private', 'family', 'life', 'little', 'weight', 'attach', 'give', 'term', 'section', 'question', 'turn', 'section', 'require', 'find', 'fact', 'parental', 'relationship', 'exist', 'biological', 'parent', 'child', 'fact', 'sensitive', 'matter', 'number', 'factor', 'account', 'doubt', 'accept', 'appellant', 'sponsor', 'live', 'married', 'couple', 'accept', 'child', 'contact', 'biological', 'father', 'accept', 'evidence', 'somewhat', 'unusual', 'age', 'take', 'school', 'appellant', 'sufficient', 'evidence', 'witness', 'statement', 'evidence', 'close', 'relationship', 'appellant', 'stepson', 'factor', 'tend', 'relatively', 'recent', 'relationship', 'year', 'look', 'evidence', 'satisfy', 'balance_probabilitie', 'parental', 'relationship', 'exist', 'appellant', 'stepson', 'follow', 'basis', 'satisfied', 'section', 'act', 'apply', 'case', 'secretary', 'state', 'urge', 'dismiss', 'appeal', 'basis', 'primarily', 'decision', 'youna', 'ukut', 'basis', 'proportionate', 'expect', 'appellant', 'application', 'entry_clearance', 'point', 'youna', 'distinguished', 'basis', 'tribunal', 'youna', 'section', 'apply', 'establish', 'child', 'leave', 'fact', 'case', 'different', 'child', 'younger', 'secondly', 'importantly', 'tribunal', 'note', 'younas', 'section', 'effect', 'standalone', 'provision', 'describe', 'self', 'contain', 'discussion', 'youna', 'revolve', 'tribunal', 'establish', 'reasonable_expect', 'child', 'leave', 'conclude', 'case', 'find', 'distinguishe', 'appeal', 'turn', 'recent', 'decision', 'court', 'appeal', 'bangladesh', 'ewca_civ', 'important', 'note', 'say', 'case', 'paragraph', 'paragraph', 'court', 'appeal', 'case', 'agree', 'say', 'important', 'emphasise', 'approach', 'approve', 'provide', 'presumption', 'opposite', 'direction', 'represent', 'common', 'sense', 'start', 'point', 'adopt', 'reason', 'give', 'paras', 'judgment', 'remain', 'necessary', 'case', 'evaluate', 'circumstance', 'order', 'establish', 'reasonable_expect', 'child', 'leave', 'parent', 'emphasise', 'follow', 'passage', 'conclusion', 'evaluation', 'reasonable', 'hypothesis', 'parent', 'leave', 'abandon', 'family', 'entitle', 'leave', 'remain', 'spell', 'case', 'qualify', 'child', 'paragraph', 'ade', 'case', 'parent', 'article', 'apply', 'section', 'applying', 'case', 'section', 'engage', 'public', 'require', 'appellant', 'leave', 'express', 'requirement', 'section', 'give', 'public', 'factor', 'set', 'remainder', 'section', 'attract', 'materially', 'adverse', 'weight', 'submission', 'proceed', 'basis', 'public', 'removal', 'preserve', 'finding', 'section', 'meet', 'proportionate', 'remove', 'respect', 'fact', 'section', 'meet', 'mean', 'public', 'removal', 'basis', 'difficult', 'understand', 'circumstance', 'case', 'proportionate', 'give', 'appellant', 'able', 'stay', 'family', 'long', 'stay', 'give', 'red', 'list', 'unclear', 'unclear', 'long', 'able', 'return', 'certainly', 'reasonable', 'require', 'wife', 'stay', 'give', 'reason', 'difficult', 'live', 'return', 'proper', 'period', 'significant', 'difficulty', 'certainly', 'advice', 'far', 'understand', 'current', 'advice', 'government', 'go', 'list', 'good', 'reason', 'fact', 'appellant', 'parental', 'relationship', 'child', 'expect', 'leave', 'united', 'give', 'section', 'apply', 'sufficiently', 'compelling', 'circumstance', 'removal', 'proportionate', 'reason', 'take', 'account', 'factor', 'relevant', 'section', 'conclude', 'require', 'appellant', 'leave', 'amount', 'interference', 'article', 'right', 'allow', 'appeal', 'basis', 'conclusion', 'decision', 'tier', 'tribunal', 'involve', 'make', 'error', 'law', 'set', 'aside', 'remake', 'decision', 'allow', 'appeal', 'article', 'ground', 'notice', 'decision', 'decision', 'tier', 'tribunal', 'involve', 'make', 'error', 'law', 'set', 'aside', 'remake', 'appeal', 'allow', 'appeal', 'human', 'right', 'ground', 'anonymity', 'direction', 'upper', 'tribunal', 'error', 'law', 'decision', 'pic', 'upper', 'tribunal', 'immigration', 'asylum', 'chamber', 'appeal', 'number', 'immigration', 'act', 'decide', 'rule', 'decision', 'reason', 'promulgate', 'hear', 'field_house', 'upper', 'tribunal', 'iqbal', 'anonymity', 'direction', 'appellant', 'respondent', 'decision', 'reason', 'appellant', 'appeal', 'permission', 'decision', 'tier', 'tribunal', 'judge', 'phull', 'promulgate', 'dismiss', 'appeal', 'nationality', 'act', 'decision', 'respondent', 'refuse', 'leave', 'remain', 'human', 'right', 'claim', 'seek', 'leave', 'remain', 'basis', 'relationship', 'partner', 'settle', 'son', 'early', 'relationship', 'british', 'judge', 'appellant', 'establish', 'family', 'life', 'partner', 'son', 'reasonable_expect', 'son', 'leave', 'removal', 'proportionate', 'sponsor', 'support', 'application', 'return', 'appellant', 'seek', 'permission', 'appeal', 'ground', 'err', 'make', 'find', 'parental', 'relationship', 'material', 'act', 'engage', 'reasonable_expect', 'son', 'leave', 'err', 'assessment', 'proportionality', 'tier', 'tribunal', 'judge', 'adio', 'grant', 'permission', 'ground', 'upper', 'tribunal', 'judge', 'give', 'direction', 'provide', 'matter', 'review', 'file', 'case', 'light', 'present', 'need_precaution', 'overriding_objective', 'express', 'procedure', 'rule', 'reach', 'provisional', 'view', 'case', 'appropriate', 'determine', 'follow', 'question', 'hear', 'make', 'tier', 'tribunal', 'decision', 'involve', 'make', 'error', 'law', 'decision', 'set', 'aside', 'follow', 'direction', 'appellant', 'submission', 'support', 'assertion', 'error', 'law', 'question', 'tier', 'tribunal', 'decision', 'set', 'error', 'law', 'file', 'serve', 'party', 'later', 'day', 'notice', 'send', 'date', 'send', 'cover', 'letter', 'covering_email', 'party', 'file_serve', 'submission', 'response', 'later', 'day', 'notice', 'send', 'iii', 'submission', 'accordance', 'party', 'seek', 'permission', 'appeal', 'file_serve', 'reply', 'late', 'day', 'notice', 'send', 'iv', 'submission', 'rely', 'document', 'previously', 'provide', 'party', 'electronic', 'form', 'accompany', 'electronic', 'copy', 'document', 'party', 'consider', 'forego', 'direction', 'hear', 'necessary', 'consider', 'question', 'set', 'paragraph', 'submit', 'reason', 'view', 'later', 'day', 'notice', 'send', 'take', 'account', 'tribunal', 'direction', 'paragraph', 'comply', 'case', 'respondent', 'reply', 'state', 'oppose', 'application', 'permission', 'invite', 'upper', 'tribunal', 'determine', 'appeal', 'oral', 'hearing', 'consider', 'parental', 'relationship', 'exist', 'appellant', 'partner', 'son', 'tribunal', 'power', 'decision', 'hear', 'rule', 'procedure', 'rule', 'rule', 'require', 'regard', 'view', 'party', 'overriding_objective', 'rule', 'enable', 'tribunal', 'deal', 'case', 'fairly_justly', 'bearing_mind', 'concession', 'respondent', 'satisfy', 'particular', 'circumstance', 'case', 'correct', 'decision', 'absence', 'hear', 'satisfied', 'judge', 'err', 'reach', 'decision', 'claim', 'ground', 'appeal', 'accept', 'respondent', 'decision', 'clearly', 'involve', 'make', 'error', 'law', 'claim', 'error', 'go', 'weight', 'attach', 'public', 'operation', 'section', 'act', 'require', 'find', 'parental', 'relationship', 'exist', 'appellant', 'partner', 'son', 'error', 'infect', 'finding', 'proportionality', 'set', 'judge', 'err', 'consider', 'reasonable_expect', 'appellant', 'partner', 'give', 'finding', 'reasonable_expect', 'son', 'leave', 'consider', 'finding', 'family', 'life', 'judge', 'phull', 'preserve', 'necessary', 'upper', 'tribunal', 'finding', 'exist', 'parental', 'relationship', 'fresh', 'finding', 'proportionality', 'event', 'give', 'find', 'reasonable_expect', 'appellant', 'partner', 'leave', 'notice', 'decision', 'direction', 'decision', 'tier', 'tribunal', 'involve', 'make', 'error', 'law', 'set', 'appeal', 'remade', 'upper', 'tribunal', 'date', 'fix', 'regard', 'pilot_practice', 'direction', 'utiac', 'guidance', 'note', 'upper', 'tribunal', 'provisionally', 'view', 'forthcoming', 'hearing', 'appeal', 'hold', 'face', 'face', 'date', 'fix', 'necessary', 'oral', 'evidence', 'court', 'interpreter', 'party', 'wishing', 'adduce', 'evidence', 'serve', 'work', 'day', 'hear', 'accompany', 'application', 'pursuant', 'rule', 'tribunal', 'procedure', 'upper', 'tribunal', 'rule', 'explain', 'permit', 'sign', 'date', 'upper', 'tribunal', 'judge', 'rintoul', 'overriding_objective', 'enable', 'upper', 'tribunal', 'deal', 'case', 'fairly_justly', 'rule', 'tribunal', 'procedure', 'upper', 'tribunal', 'rule', 'rule']]\n"
     ]
    }
   ],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(corpus_clean)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en_core_web_sm' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 3), (3, 1), (4, 9), (5, 2), (6, 1), (7, 3), (8, 8), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 2), (15, 1), (16, 1), (17, 3), (18, 1), (19, 1), (20, 3), (21, 22), (22, 33), (23, 6), (24, 5), (25, 1), (26, 1), (27, 1), (28, 1), (29, 5), (30, 4), (31, 1), (32, 1), (33, 2), (34, 1), (35, 2), (36, 3), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 10), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 2), (49, 2), (50, 1), (51, 19), (52, 1), (53, 1), (54, 2), (55, 1), (56, 2), (57, 10), (58, 5), (59, 3), (60, 1), (61, 1), (62, 1), (63, 1), (64, 2), (65, 1), (66, 1), (67, 1), (68, 1), (69, 2), (70, 2), (71, 1), (72, 1), (73, 7), (74, 1), (75, 2), (76, 1), (77, 2), (78, 1), (79, 1), (80, 1), (81, 4), (82, 1), (83, 1), (84, 1), (85, 1), (86, 4), (87, 5), (88, 2), (89, 1), (90, 30), (91, 1), (92, 3), (93, 1), (94, 2), (95, 1), (96, 10), (97, 1), (98, 3), (99, 1), (100, 1), (101, 1), (102, 2), (103, 1), (104, 1), (105, 1), (106, 1), (107, 2), (108, 2), (109, 2), (110, 2), (111, 2), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 4), (119, 11), (120, 5), (121, 1), (122, 1), (123, 1), (124, 13), (125, 1), (126, 5), (127, 2), (128, 1), (129, 1), (130, 2), (131, 1), (132, 2), (133, 5), (134, 5), (135, 1), (136, 2), (137, 1), (138, 9), (139, 1), (140, 2), (141, 1), (142, 2), (143, 2), (144, 2), (145, 1), (146, 5), (147, 8), (148, 2), (149, 4), (150, 1), (151, 3), (152, 1), (153, 2), (154, 1), (155, 1), (156, 13), (157, 2), (158, 1), (159, 1), (160, 2), (161, 5), (162, 1), (163, 10), (164, 2), (165, 1), (166, 1), (167, 2), (168, 1), (169, 1), (170, 1), (171, 9), (172, 2), (173, 1), (174, 1), (175, 2), (176, 2), (177, 1), (178, 6), (179, 1), (180, 1), (181, 12), (182, 1), (183, 1), (184, 3), (185, 9), (186, 18), (187, 2), (188, 5), (189, 1), (190, 2), (191, 1), (192, 3), (193, 3), (194, 2), (195, 8), (196, 1), (197, 1), (198, 1), (199, 1), (200, 4), (201, 1), (202, 5), (203, 1), (204, 2), (205, 2), (206, 5), (207, 1), (208, 1), (209, 1), (210, 2), (211, 3), (212, 6), (213, 4), (214, 1), (215, 1), (216, 3), (217, 1), (218, 2), (219, 1), (220, 3), (221, 2), (222, 3), (223, 5), (224, 1), (225, 4), (226, 10), (227, 1), (228, 7), (229, 7), (230, 1), (231, 1), (232, 1), (233, 7), (234, 1), (235, 2), (236, 2), (237, 1), (238, 7), (239, 1), (240, 1), (241, 2), (242, 3), (243, 1), (244, 1), (245, 2), (246, 1), (247, 1), (248, 5), (249, 1), (250, 3), (251, 1), (252, 3), (253, 5), (254, 3), (255, 1), (256, 1), (257, 1), (258, 5), (259, 2), (260, 1), (261, 4), (262, 2), (263, 11), (264, 2), (265, 8), (266, 2), (267, 2), (268, 1), (269, 1), (270, 1), (271, 3), (272, 3), (273, 19), (274, 2), (275, 1), (276, 1), (277, 1), (278, 7), (279, 1), (280, 2), (281, 5), (282, 1), (283, 2), (284, 1), (285, 6), (286, 6), (287, 3), (288, 6), (289, 1), (290, 3), (291, 1), (292, 1), (293, 5), (294, 1), (295, 1), (296, 18), (297, 3), (298, 2), (299, 2), (300, 1), (301, 1), (302, 5), (303, 17), (304, 4), (305, 1), (306, 5), (307, 2), (308, 1), (309, 2), (310, 11), (311, 1), (312, 1), (313, 1), (314, 1), (315, 1), (316, 1), (317, 8), (318, 1), (319, 1), (320, 8), (321, 1), (322, 4), (323, 1), (324, 7), (325, 2), (326, 4), (327, 2), (328, 5), (329, 1), (330, 1), (331, 1), (332, 3), (333, 1), (334, 1), (335, 2), (336, 5), (337, 1), (338, 2), (339, 1), (340, 1), (341, 13), (342, 36), (343, 1), (344, 2), (345, 1), (346, 2), (347, 2), (348, 1), (349, 2), (350, 1), (351, 1), (352, 14), (353, 1), (354, 1), (355, 4), (356, 1), (357, 1), (358, 1), (359, 4), (360, 2), (361, 1), (362, 2), (363, 7), (364, 1), (365, 4), (366, 1), (367, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corp = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corp[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abandon'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('abandon', 1),\n",
       "  ('ability', 1),\n",
       "  ('able', 3),\n",
       "  ('absence', 1),\n",
       "  ('accept', 9),\n",
       "  ('accompany', 2),\n",
       "  ('accordance', 1),\n",
       "  ('account', 3),\n",
       "  ('act', 8),\n",
       "  ('adduce', 1),\n",
       "  ('ade', 1),\n",
       "  ('adio', 1),\n",
       "  ('adopt', 2),\n",
       "  ('adverse', 1),\n",
       "  ('advice', 2),\n",
       "  ('age', 1),\n",
       "  ('agree', 1),\n",
       "  ('allow', 3),\n",
       "  ('amount', 1),\n",
       "  ('annex', 1),\n",
       "  ('anonymity', 3),\n",
       "  ('appeal', 22),\n",
       "  ('appellant', 33),\n",
       "  ('application', 6),\n",
       "  ('apply', 5),\n",
       "  ('applying', 1),\n",
       "  ('approach', 1),\n",
       "  ('appropriate', 1),\n",
       "  ('approve', 1),\n",
       "  ('article', 5),\n",
       "  ('aside', 4),\n",
       "  ('ask', 1),\n",
       "  ('assertion', 1),\n",
       "  ('assessment', 2),\n",
       "  ('assistance', 1),\n",
       "  ('asylum', 2),\n",
       "  ('attach', 3),\n",
       "  ('attract', 1),\n",
       "  ('away', 1),\n",
       "  ('balance', 1),\n",
       "  ('balance_probabilitie', 1),\n",
       "  ('bangladesh', 1),\n",
       "  ('basis', 10),\n",
       "  ('bear', 1),\n",
       "  ('bearing_mind', 1),\n",
       "  ('behalf', 1),\n",
       "  ('benefit', 1),\n",
       "  ('best_interest', 1),\n",
       "  ('biological', 2),\n",
       "  ('british', 2),\n",
       "  ('capacity', 1),\n",
       "  ('case', 19),\n",
       "  ('cease', 1),\n",
       "  ('certain', 1),\n",
       "  ('certainly', 2),\n",
       "  ('challenge', 1),\n",
       "  ('chamber', 2),\n",
       "  ('child', 10),\n",
       "  ('circumstance', 5),\n",
       "  ('claim', 3),\n",
       "  ('clear', 1),\n",
       "  ('clearly', 1),\n",
       "  ('close', 1),\n",
       "  ('common', 1),\n",
       "  ('company', 2),\n",
       "  ('compelling', 1),\n",
       "  ('comply', 1),\n",
       "  ('computer', 1),\n",
       "  ('concession', 1),\n",
       "  ('conclude', 2),\n",
       "  ('conclusion', 2),\n",
       "  ('confusing', 1),\n",
       "  ('confusion', 1),\n",
       "  ('consider', 7),\n",
       "  ('consultant', 1),\n",
       "  ('contact', 2),\n",
       "  ('contain', 1),\n",
       "  ('copy', 2),\n",
       "  ('correct', 1),\n",
       "  ('counsel_instructe', 1),\n",
       "  ('couple', 1),\n",
       "  ('court', 4),\n",
       "  ('cover', 1),\n",
       "  ('covering_email', 1),\n",
       "  ('cross_examine', 1),\n",
       "  ('current', 1),\n",
       "  ('date', 4),\n",
       "  ('day', 5),\n",
       "  ('deal', 2),\n",
       "  ('decide', 1),\n",
       "  ('decision', 30),\n",
       "  ('describe', 1),\n",
       "  ('determine', 3),\n",
       "  ('different', 1),\n",
       "  ('difficult', 2),\n",
       "  ('difficulty', 1),\n",
       "  ('direction', 10),\n",
       "  ('discussion', 1),\n",
       "  ('dismiss', 3),\n",
       "  ('dispute', 1),\n",
       "  ('distinguishe', 1),\n",
       "  ('distinguished', 1),\n",
       "  ('document', 2),\n",
       "  ('documentary', 1),\n",
       "  ('doubt', 1),\n",
       "  ('early', 1),\n",
       "  ('effect', 1),\n",
       "  ('electronic', 2),\n",
       "  ('emphasise', 2),\n",
       "  ('employ', 2),\n",
       "  ('enable', 2),\n",
       "  ('engage', 2),\n",
       "  ('english', 1),\n",
       "  ('enjoy', 1),\n",
       "  ('enter', 1),\n",
       "  ('entirely', 1),\n",
       "  ('entitle', 1),\n",
       "  ('entry_clearance', 1),\n",
       "  ('err', 4),\n",
       "  ('error', 11),\n",
       "  ('establish', 5),\n",
       "  ('evaluate', 1),\n",
       "  ('evaluation', 1),\n",
       "  ('event', 1),\n",
       "  ('evidence', 13),\n",
       "  ('ewca_civ', 1),\n",
       "  ('exist', 5),\n",
       "  ('expect', 2),\n",
       "  ('expectation', 1),\n",
       "  ('explain', 1),\n",
       "  ('express', 2),\n",
       "  ('extempore', 1),\n",
       "  ('face', 2),\n",
       "  ('fact', 5),\n",
       "  ('factor', 5),\n",
       "  ('failure', 1),\n",
       "  ('fairly_justly', 2),\n",
       "  ('familiar', 1),\n",
       "  ('family', 9),\n",
       "  ('far', 1),\n",
       "  ('father', 2),\n",
       "  ('favour', 1),\n",
       "  ('field_house', 2),\n",
       "  ('file', 2),\n",
       "  ('file_serve', 2),\n",
       "  ('financially_independent', 1),\n",
       "  ('find', 5),\n",
       "  ('finding', 8),\n",
       "  ('fix', 2),\n",
       "  ('follow', 4),\n",
       "  ('forego', 1),\n",
       "  ('form', 3),\n",
       "  ('forthcoming', 1),\n",
       "  ('fresh', 2),\n",
       "  ('fulfil', 1),\n",
       "  ('genuine_subsiste', 1),\n",
       "  ('give', 13),\n",
       "  ('go', 2),\n",
       "  ('good', 1),\n",
       "  ('government', 1),\n",
       "  ('grant', 2),\n",
       "  ('ground', 5),\n",
       "  ('guidance', 1),\n",
       "  ('hear', 10),\n",
       "  ('hearing', 2),\n",
       "  ('heavy', 1),\n",
       "  ('hold', 1),\n",
       "  ('human', 2),\n",
       "  ('hypothesis', 1),\n",
       "  ('identify', 1),\n",
       "  ('iii', 1),\n",
       "  ('immigration', 9),\n",
       "  ('important', 2),\n",
       "  ('importantly', 1),\n",
       "  ('infect', 1),\n",
       "  ('interference', 2),\n",
       "  ('interpreter', 2),\n",
       "  ('invite', 1),\n",
       "  ('involve', 6),\n",
       "  ('iqbal', 1),\n",
       "  ('iv', 1),\n",
       "  ('judge', 12),\n",
       "  ('judgment', 1),\n",
       "  ('late', 1),\n",
       "  ('later', 3),\n",
       "  ('law', 9),\n",
       "  ('leave', 18),\n",
       "  ('letter', 2),\n",
       "  ('life', 5),\n",
       "  ('light', 1),\n",
       "  ('list', 2),\n",
       "  ('little', 1),\n",
       "  ('live', 3),\n",
       "  ('long', 3),\n",
       "  ('look', 2),\n",
       "  ('make', 8),\n",
       "  ('march', 1),\n",
       "  ('married', 1),\n",
       "  ('material', 1),\n",
       "  ('materially', 1),\n",
       "  ('matter', 4),\n",
       "  ('mean', 1),\n",
       "  ('meet', 5),\n",
       "  ('misgiving', 1),\n",
       "  ('nationality', 2),\n",
       "  ('nature', 2),\n",
       "  ('necessary', 5),\n",
       "  ('need', 1),\n",
       "  ('need_precaution', 1),\n",
       "  ('normal', 1),\n",
       "  ('normally', 2),\n",
       "  ('note', 3),\n",
       "  ('notice', 6),\n",
       "  ('number', 4),\n",
       "  ('office', 1),\n",
       "  ('officer', 1),\n",
       "  ('online', 3),\n",
       "  ('operation', 1),\n",
       "  ('oppose', 2),\n",
       "  ('opposite', 1),\n",
       "  ('oral', 3),\n",
       "  ('order', 2),\n",
       "  ('overriding_objective', 3),\n",
       "  ('paragraph', 5),\n",
       "  ('paras', 1),\n",
       "  ('parent', 4),\n",
       "  ('parental', 10),\n",
       "  ('particular', 1),\n",
       "  ('partner', 7),\n",
       "  ('party', 7),\n",
       "  ('passage', 1),\n",
       "  ('payslip', 1),\n",
       "  ('period', 1),\n",
       "  ('permission', 7),\n",
       "  ('permit', 1),\n",
       "  ('phull', 2),\n",
       "  ('pic', 2),\n",
       "  ('pilot_practice', 1),\n",
       "  ('point', 7),\n",
       "  ('position', 1),\n",
       "  ('power', 1),\n",
       "  ('present', 2),\n",
       "  ('preserve', 3),\n",
       "  ('presumption', 1),\n",
       "  ('previous', 1),\n",
       "  ('previously', 2),\n",
       "  ('primarily', 1),\n",
       "  ('private', 1),\n",
       "  ('procedure', 5),\n",
       "  ('proceed', 1),\n",
       "  ('promulgate', 3),\n",
       "  ('proper', 1),\n",
       "  ('proportionality', 3),\n",
       "  ('proportionate', 5),\n",
       "  ('provide', 3),\n",
       "  ('provision', 1),\n",
       "  ('provisional', 1),\n",
       "  ('provisionally', 1),\n",
       "  ('public', 5),\n",
       "  ('pursuant', 2),\n",
       "  ('qualify', 1),\n",
       "  ('question', 4),\n",
       "  ('reach', 2),\n",
       "  ('reason', 11),\n",
       "  ('reasonable', 2),\n",
       "  ('reasonable_expect', 8),\n",
       "  ('receipt', 2),\n",
       "  ('recent', 2),\n",
       "  ('recently', 1),\n",
       "  ('red', 1),\n",
       "  ('refer', 1),\n",
       "  ('refuse', 3),\n",
       "  ('regard', 3),\n",
       "  ('relationship', 19),\n",
       "  ('relatively', 2),\n",
       "  ('relevant', 1),\n",
       "  ('rely', 1),\n",
       "  ('remade', 1),\n",
       "  ('remain', 7),\n",
       "  ('remainder', 1),\n",
       "  ('remake', 2),\n",
       "  ('removal', 5),\n",
       "  ('remove', 1),\n",
       "  ('reply', 2),\n",
       "  ('represent', 1),\n",
       "  ('require', 6),\n",
       "  ('requirement', 6),\n",
       "  ('respect', 3),\n",
       "  ('respondent', 6),\n",
       "  ('response', 1),\n",
       "  ('return', 3),\n",
       "  ('review', 1),\n",
       "  ('revolve', 1),\n",
       "  ('right', 5),\n",
       "  ('rintoul', 1),\n",
       "  ('round', 1),\n",
       "  ('rule', 18),\n",
       "  ('satisfied', 3),\n",
       "  ('satisfy', 2),\n",
       "  ('say', 2),\n",
       "  ('school', 1),\n",
       "  ('secondly', 1),\n",
       "  ('secretary', 5),\n",
       "  ('section', 17),\n",
       "  ('seek', 4),\n",
       "  ('self', 1),\n",
       "  ('send', 5),\n",
       "  ('sense', 2),\n",
       "  ('sensitive', 1),\n",
       "  ('serve', 2),\n",
       "  ('set', 11),\n",
       "  ('settle', 1),\n",
       "  ('show', 1),\n",
       "  ('sign', 1),\n",
       "  ('significant', 1),\n",
       "  ('similarly', 1),\n",
       "  ('somewhat', 1),\n",
       "  ('son', 8),\n",
       "  ('speak', 1),\n",
       "  ('spell', 1),\n",
       "  ('sponsor', 8),\n",
       "  ('standalone', 1),\n",
       "  ('start', 4),\n",
       "  ('starting', 1),\n",
       "  ('state', 7),\n",
       "  ('statement', 2),\n",
       "  ('stay', 4),\n",
       "  ('stepson', 2),\n",
       "  ('submission', 5),\n",
       "  ('submit', 1),\n",
       "  ('subparagraph', 1),\n",
       "  ('subsequent', 1),\n",
       "  ('subsist', 3),\n",
       "  ('sufficient', 1),\n",
       "  ('sufficiently', 1),\n",
       "  ('support', 2),\n",
       "  ('take', 5),\n",
       "  ('tend', 1),\n",
       "  ('term', 2),\n",
       "  ('think', 1),\n",
       "  ('tie', 1),\n",
       "  ('tier', 13),\n",
       "  ('tribunal', 36),\n",
       "  ('tufan', 1),\n",
       "  ('turn', 2),\n",
       "  ('ukut', 1),\n",
       "  ('unclear', 2),\n",
       "  ('understand', 2),\n",
       "  ('unfortunately', 1),\n",
       "  ('united', 2),\n",
       "  ('unlawfully', 1),\n",
       "  ('unusual', 1),\n",
       "  ('upper', 14),\n",
       "  ('urge', 1),\n",
       "  ('utiac', 1),\n",
       "  ('view', 4),\n",
       "  ('visa', 1),\n",
       "  ('visit', 1),\n",
       "  ('weigh', 1),\n",
       "  ('weight', 4),\n",
       "  ('wife', 2),\n",
       "  ('wishing', 1),\n",
       "  ('witness', 2),\n",
       "  ('work', 7),\n",
       "  ('year', 1),\n",
       "  ('youna', 4),\n",
       "  ('younas', 1),\n",
       "  ('younger', 1)]]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corp[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus = corp,\n",
    "                                           id2word = id2word,\n",
    "                                           num_topics = 5, \n",
    "                                           random_state = 100,\n",
    "                                           update_every = 1,\n",
    "                                           chunksize = 100,\n",
    "                                           passes = 10,\n",
    "                                           alpha = 'auto',\n",
    "                                           per_word_topics = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.022*\"sponsor\" + 0.019*\"regulation\" + 0.018*\"marriage\" + 0.016*\"right\" + 0.016*\"appellant\" + 0.015*\"evidence\" + 0.014*\"member\" + 0.013*\"family\" + 0.012*\"residence\" + 0.012*\"entry_clearance\"'), (1, '0.020*\"decision\" + 0.019*\"appeal\" + 0.018*\"application\" + 0.016*\"state\" + 0.015*\"leave\" + 0.013*\"immigration\" + 0.013*\"case\" + 0.013*\"rule\" + 0.012*\"secretary\" + 0.011*\"claimant\"'), (2, '0.016*\"appellant\" + 0.013*\"evidence\" + 0.011*\"report\" + 0.010*\"risk\" + 0.010*\"say\" + 0.009*\"return\" + 0.008*\"adjudicator\" + 0.007*\"country\" + 0.007*\"claim\" + 0.007*\"case\"'), (3, '0.024*\"article\" + 0.019*\"appellant\" + 0.017*\"child\" + 0.016*\"family\" + 0.015*\"case\" + 0.012*\"right\" + 0.012*\"life\" + 0.010*\"decision\" + 0.010*\"immigration\" + 0.009*\"consider\"'), (4, '0.061*\"appellant\" + 0.047*\"appeal\" + 0.036*\"tribunal\" + 0.034*\"judge\" + 0.023*\"decision\" + 0.022*\"determination\" + 0.017*\"evidence\" + 0.014*\"respondent\" + 0.014*\"immigration\" + 0.014*\"reason\"')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "print(lda_model.print_topics())\n",
    "doc_lda = lda_model[corp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fc/h07gydfn7nd0zq3mglwpn3r40000gn/T/ipykernel_34371/933021575.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#import pyLDAvis.gensim  # don't skip this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim_models\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgensimvis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "#import pyLDAvis.gensim  # don't skip this\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -6.931772735559883\n",
      "\n",
      "Coherence Score:  0.3940589043683872\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corp))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model = lda_model, texts = data_lemmatized, dictionary = id2word, coherence = 'c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/albertamurgopacheco/anaconda3/envs/tfm/lib/python3.8/site-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  default_term_info = default_term_info.sort_values(\n",
      "/Users/albertamurgopacheco/anaconda3/envs/tfm/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/albertamurgopacheco/anaconda3/envs/tfm/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/albertamurgopacheco/anaconda3/envs/tfm/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/albertamurgopacheco/anaconda3/envs/tfm/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el343711405733504493284260864967\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el343711405733504493284260864967_data = {\"mdsDat\": {\"x\": [-0.18430293950068977, 0.05952517405997558, 0.014296497684099026, -0.05649876713300903, 0.16698003488962435], \"y\": [-0.02956273697767929, 0.18065438058517735, 0.029241377706041374, -0.06037253648318563, -0.11996048483035343], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [34.76264021740198, 23.915208243635295, 21.80302644536519, 11.675672525361524, 7.843452568236013]}, \"tinfo\": {\"Term\": [\"judge\", \"appeal\", \"appellant\", \"tribunal\", \"decision\", \"family\", \"child\", \"sponsor\", \"application\", \"article\", \"right\", \"regulation\", \"evidence\", \"marriage\", \"determination\", \"member\", \"immigration\", \"life\", \"leave\", \"report\", \"claimant\", \"state\", \"risk\", \"rule\", \"secretary\", \"person\", \"residence\", \"adjudicator\", \"respondent\", \"tier\", \"remit\", \"fttj\", \"saunder\", \"afresh\", \"bradford\", \"savage\", \"mcgeachy\", \"reheard\", \"unsound\", \"clive_lane\", \"hopo\", \"pickup\", \"dismis\", \"ancestry\", \"hodgett\", \"chalkley\", \"hunter\", \"delivered_orally\", \"counsel_instructed\", \"parker\", \"uzbekistan\", \"digney\", \"novo\", \"slatter\", \"dean\", \"rothwell\", \"differently_constitute\", \"preferably\", \"parke\", \"keane\", \"judge\", \"working_holidaymaker\", \"adjournment\", \"surendran_guideline\", \"griffith\", \"error\", \"anonymity\", \"promulgate\", \"tier\", \"rehear\", \"determination\", \"permission\", \"upper\", \"pic\", \"direction\", \"rk\", \"tribunal\", \"arguable\", \"dismiss\", \"hearing\", \"hear\", \"appeal\", \"finding\", \"err\", \"chamber\", \"appellant\", \"ground\", \"aside\", \"respondent\", \"deputy\", \"sign\", \"field_house\", \"reason\", \"fail\", \"decision\", \"find\", \"material\", \"adjudicator\", \"asylum\", \"evidence\", \"paragraph\", \"officer\", \"immigration\", \"law\", \"submit\", \"consider\", \"date\", \"give\", \"claim\", \"set\", \"issue\", \"case\", \"persecution\", \"political\", \"kill\", \"torture\", \"returnee\", \"target\", \"clan\", \"military\", \"population\", \"airport\", \"scar\", \"rape\", \"ethnic\", \"traffic\", \"eritrean\", \"somali\", \"tamil\", \"camp\", \"civilian\", \"cipu\", \"beat\", \"profile\", \"persecute\", \"election\", \"founded_fear\", \"war\", \"flee\", \"mdc\", \"escape\", \"homosexual\", \"police\", \"arrest\", \"incident\", \"violence\", \"group\", \"government\", \"detain\", \"attack\", \"risk\", \"woman\", \"fear\", \"seeker\", \"report\", \"detention\", \"international\", \"people\", \"ill\", \"real\", \"expert\", \"organisation\", \"area\", \"protection\", \"treatment\", \"return\", \"authority\", \"say\", \"activity\", \"refugee\", \"face\", \"country\", \"know\", \"evidence\", \"situation\", \"claim\", \"adjudicator\", \"appellant\", \"ask\", \"state\", \"case\", \"human\", \"person\", \"give\", \"accept\", \"convention\", \"right\", \"asylum\", \"question\", \"consider\", \"take\", \"issue\", \"article\", \"fact\", \"deportation\", \"best_interest\", \"offend\", \"insurmountable_obstacle\", \"balancing_exercise\", \"democratic_society\", \"offender\", \"precarious\", \"integration\", \"disruption\", \"criminality\", \"imperative\", \"sentencing\", \"reoffende\", \"parental\", \"jamaican\", \"offending\", \"truly_exceptional\", \"health_moral\", \"probation\", \"exceptionality\", \"foreign_criminal\", \"juvenile\", \"strasbourg_jurisprudence\", \"sentencing_remark\", \"lord_bingham\", \"maslov\", \"nom\", \"pleaded_guilty\", \"nagre\", \"proportionality\", \"croatia\", \"tie\", \"interference\", \"razgar\", \"outweigh\", \"serbian\", \"child\", \"exceptional\", \"life\", \"expulsion\", \"legitimate_aim\", \"conducive\", \"offence\", \"proportionate\", \"conviction\", \"public\", \"deport\", \"convict\", \"private\", \"shala\", \"panel\", \"drug\", \"compelling\", \"sentence\", \"imprisonment\", \"article\", \"parent\", \"factor\", \"british\", \"family\", \"interest\", \"removal\", \"mother\", \"year\", \"court\", \"right\", \"circumstance\", \"breach\", \"case\", \"consideration\", \"remain\", \"live\", \"convention\", \"relationship\", \"consider\", \"appellant\", \"leave\", \"rule\", \"immigration\", \"state\", \"decision\", \"country\", \"paragraph\", \"appeal\", \"fact\", \"claimant\", \"tribunal\", \"law\", \"variation\", \"exercised_differently\", \"invalid\", \"cas\", \"evidential_flexibility\", \"wednesbury\", \"incorporation\", \"extension_stay\", \"transitional_arrangement\", \"diploma\", \"treasury_solicitor\", \"postgraduate\", \"accountant\", \"handbook\", \"raju\", \"khatel\", \"invalidate\", \"ankara_agreement\", \"ladd_marshall\", \"entrepreneur\", \"cancellation\", \"curtailment\", \"acca\", \"pbs\", \"confirmation_acceptance\", \"postal\", \"allowable\", \"entrepreneur_migrant\", \"module\", \"speedily\", \"fca\", \"racially_discriminate\", \"buxton_lj\", \"principled\", \"judicial_review\", \"award\", \"appealable\", \"applicant\", \"college\", \"ccol\", \"discretion\", \"appendix\", \"caseworker\", \"legitimate_expectation\", \"study\", \"english_language\", \"subsection\", \"migrant\", \"specify\", \"student\", \"business\", \"extension\", \"jurisdiction\", \"claimant\", \"qualification\", \"power\", \"application\", \"secretary\", \"course\", \"section\", \"document\", \"policy\", \"leave\", \"fund\", \"rule\", \"state\", \"requirement\", \"bank\", \"provision\", \"decision\", \"remain\", \"exercise\", \"immigration\", \"case\", \"apply\", \"appeal\", \"act\", \"time\", \"provide\", \"grant\", \"right\", \"paragraph\", \"date\", \"respondent\", \"follow\", \"point\", \"letter\", \"tribunal\", \"issue\", \"consider\", \"court\", \"treaty\", \"dependency\", \"eea\", \"reg\", \"free_movement\", \"european_economic\", \"exercising_treaty\", \"accession\", \"sole_responsibility\", \"domicile\", \"civil_partnership\", \"boc\", \"chikwamba\", \"pension\", \"payslip\", \"gurkha\", \"nepalese\", \"jobseeker\", \"metock\", \"derivative\", \"adoptive\", \"ecj\", \"maintain_accommodate\", \"talaq\", \"dissolution\", \"polygamous\", \"ofm\", \"wage_slip\", \"bill\", \"statutory_declaration\", \"sponsor\", \"regulation\", \"income\", \"eco\", \"hong_kong\", \"romanian\", \"marriage\", \"union\", \"tax\", \"divorce\", \"self_employe\", \"nepal\", \"directive\", \"entry_clearance\", \"employer\", \"spouse\", \"permanent\", \"residence\", \"household\", \"customary\", \"reside\", \"card\", \"employment\", \"durable\", \"national\", \"member\", \"worker\", \"qualified\", \"marry\", \"accommodation\", \"visit\", \"work\", \"requirement\", \"person\", \"financial\", \"right\", \"citizen\", \"family\", \"period\", \"evidence\", \"provide\", \"relationship\", \"state\", \"appellant\", \"live\", \"issue\", \"law\", \"wife\", \"application\", \"officer\", \"date\", \"immigration\", \"year\", \"say\", \"appeal\"], \"Freq\": [407916.0, 691423.0, 1011411.0, 505781.0, 428427.0, 176279.0, 132976.0, 58432.0, 151220.0, 248026.0, 216823.0, 50369.0, 366141.0, 50534.0, 289528.0, 78707.0, 300063.0, 94900.0, 161179.0, 97739.0, 80791.0, 253321.0, 84349.0, 173934.0, 98780.0, 109430.0, 43097.0, 229400.0, 219210.0, 128865.0, 21284.34808091549, 5598.071393839539, 6532.5973527156475, 5438.255190046935, 2123.65743233115, 2139.609254722961, 1048.3733141299858, 1233.9479989205422, 1065.0381238397454, 864.1337503142686, 841.4465089574635, 837.0238735397729, 806.1977212978314, 843.7476316932372, 718.7061490425891, 677.2430296900465, 2282.6733185554244, 658.566394428411, 1177.4649573552024, 745.5089018529701, 1475.7986829537301, 649.8755244823914, 592.580923990844, 612.7240111658114, 590.7724915149026, 592.6418286611383, 630.9676863676829, 698.1933554186041, 524.6129478116876, 513.8977106495925, 386655.1630796097, 1309.008139395859, 13804.599549956509, 870.3063463687888, 897.6088362603584, 105242.99108013933, 14883.470584118792, 39033.88708232498, 117465.58863135455, 2639.210265146818, 251034.39624904317, 59230.35090900048, 90451.60298849872, 23134.209826299728, 52089.48603044644, 2787.5732030763434, 419635.51116091886, 16956.79575934921, 72387.6227379032, 65997.23762254321, 133086.7137637988, 538556.4764513735, 80812.21176082648, 35533.65172177081, 18713.74281620937, 707836.8351449147, 154025.68974765475, 10706.002134926135, 164135.33616933812, 6692.9937447999255, 28092.79896019557, 11446.326421856893, 156139.22072991534, 70868.69314593056, 266080.1141903225, 45184.11115685344, 59022.45222971589, 144388.5481338098, 76820.97267968468, 199295.3184439856, 150594.72262765607, 62454.2569147672, 160887.02265889634, 115204.20594127568, 72619.33296211387, 112889.88484466446, 80519.20895558404, 86979.68645403531, 83168.30372993485, 71626.27073604507, 74824.95314811108, 85842.2784815545, 29971.071886243135, 19144.501891257234, 11610.585309344107, 10378.634061532208, 9217.716258540477, 8066.552453308061, 7356.066565588016, 7119.608070536696, 6684.661307724052, 6622.893375875292, 6329.439602333068, 6006.998088787014, 5979.769909772521, 5727.527538578061, 5721.086280283058, 5603.821767128225, 5599.927278294568, 5522.266969428226, 5377.973272479684, 5033.8583629846635, 4887.55347535925, 4830.383210351694, 4762.187409677544, 4718.198384944092, 4789.827892014912, 4672.3496090521385, 4724.810474403108, 4260.6303440751335, 4375.072449376955, 4083.6335601583924, 25128.53473113066, 18611.142988503256, 8194.624115263061, 14839.138252620569, 23827.098599915083, 33151.22235857857, 12650.790118197177, 11963.730261827706, 79087.35299710369, 25690.907229415992, 13563.634292102224, 16196.628244101581, 88933.08616808381, 15702.765506467505, 18477.27045426538, 24016.916955249802, 17110.70424921092, 26366.691305548884, 11122.141151550195, 8366.493194024308, 29540.377896002727, 31955.902852801326, 33367.5075399833, 71981.65566208202, 43765.16018883453, 77500.96125019678, 13947.24351989375, 22550.02576292291, 19653.71727177178, 55206.99201048432, 23920.557097805875, 105661.10275437719, 23785.454579187102, 54507.522424313895, 66767.00944845706, 124929.90509421736, 22973.4931332197, 50706.06916599039, 53159.58143319538, 29412.296999930753, 33554.764351269514, 35117.4318048476, 31789.655504453665, 26822.341420322406, 34988.11353710115, 29798.441916243257, 27808.046470796715, 32998.397722663874, 28933.990055750568, 28205.56227875063, 28492.990790967513, 27258.588808510794, 44034.851560384355, 9450.248230841129, 7945.30543019258, 4469.366896856714, 4457.96689924254, 3556.814829964456, 3466.192152035516, 2939.77769956437, 2815.5293852801715, 2230.7549258225495, 2031.4559607754397, 1841.0701497171835, 1793.14621483676, 1758.3676562252813, 1753.8722486072193, 1853.141948689856, 1468.9441817378172, 1602.1317475573774, 1430.2615143543612, 1404.1011443169693, 1364.009209422076, 1174.598478468433, 1192.611678553392, 1129.4400416615285, 925.815513512744, 888.4569809184468, 870.1362401896574, 851.1059724151792, 834.8057395159409, 818.938589087082, 33782.061681602325, 4202.287131461875, 12728.982337701245, 23884.806255607135, 2964.39505216447, 4228.296283054379, 1904.7772072406326, 125027.6409017357, 22152.924241662215, 88507.93985658337, 9980.461139113711, 3768.5139179564367, 3026.0098862214923, 29571.123213473013, 13615.715512533607, 12834.81209807327, 56867.74590971745, 13648.18843709673, 10148.71875630212, 32354.556194437668, 3369.1088580972287, 22876.762424185414, 8017.708442769428, 7721.443201815148, 21701.347450300218, 12793.19913923794, 173437.39760567804, 28612.649567002572, 29815.530945803028, 20031.319989004845, 113596.59225835542, 13150.993976294922, 39621.53756321717, 26588.363907130235, 51024.82178453818, 60970.643902728596, 90126.35815687448, 54670.605255189585, 30738.55233812673, 109687.69164009672, 34048.04114076213, 47283.88497560558, 35751.9516359884, 35982.44179932255, 27360.61556399497, 68038.4723685358, 138208.83479047852, 52776.41502280376, 54163.91212931517, 68824.0927040634, 62899.013502476635, 73082.20206657791, 42029.45547304585, 53031.989137613884, 62947.97586715118, 41123.857139513486, 34398.714715047754, 43959.074387600915, 35355.558527645946, 3738.5180672027054, 1468.5913527412376, 1311.2468558606063, 1083.6966215914872, 1004.3918727847911, 925.6286714229378, 874.074594428722, 744.4825726403039, 651.1138197852935, 601.195937386396, 544.7539016181721, 517.3559964034771, 517.4309452173835, 533.5036338308821, 456.5764248235242, 453.0672142866905, 497.86885396786926, 408.4549189774859, 466.78865153820993, 373.73671239130624, 380.8676130383249, 367.7839732874018, 358.8085428834014, 358.8316474049816, 337.8240302156771, 345.9219396195639, 1571.193235944605, 308.39890046604194, 308.30763760580027, 444.63527548849515, 464.4269186127822, 759.6808959932218, 374.7799378931431, 381.5962225792297, 2020.0533422615113, 4455.172088887056, 979.9809877429718, 35828.44895060692, 5782.670890637129, 445.30319339588317, 15685.954987841094, 4611.03361359719, 1363.2724905050243, 1314.6716221886888, 13646.25806862713, 1996.8160542109817, 2744.0169583439315, 4016.5608102281685, 6170.366566032297, 12191.349438975642, 8075.149759555536, 3101.058005326449, 11026.753518473477, 44301.714186675345, 4419.1101007847765, 9224.48272039685, 67845.60126726348, 44791.40922443306, 22619.940643746202, 28767.13551602826, 32772.53537716842, 18424.99804986124, 56406.55398537572, 7926.524345594348, 49172.70094265553, 63514.080069674215, 20074.519333227105, 5344.564079483572, 15549.856056545797, 78273.26829117083, 27163.41212804361, 12016.042698083695, 51796.10508523198, 49813.89311734938, 24618.757211411077, 75387.07579965102, 25867.184000145004, 23842.04856477572, 18496.173500926194, 22185.905638229957, 31165.506577433018, 33802.77794115691, 25211.019193827335, 30120.554660661728, 21845.477080378536, 20285.72486540549, 17586.878711915593, 23691.29798564909, 19690.82107818026, 19671.010247032562, 18979.935748362055, 9784.317003577751, 5656.369052299098, 5030.824416247462, 2312.514400998387, 2228.777110747124, 2070.1565197965306, 2038.888858073812, 1959.5301822105992, 1472.1879477305022, 1321.675728084271, 1256.6335585607394, 1327.5713212708927, 1177.8280393706332, 1182.1525192088243, 1038.9281728014673, 991.6788562704619, 1050.9947261087495, 887.9963536093345, 833.3139469630497, 784.7565428545381, 829.6888249389134, 853.9494316681114, 935.8948304627071, 709.1308038392372, 846.1589778111041, 604.3800712984411, 595.887420402736, 556.1207100647835, 595.9326965717091, 536.5800682383772, 57715.49445642218, 49685.31070454262, 12581.895445202721, 2274.3302366200937, 1036.6162868155232, 765.3886394554098, 47888.166000871846, 8633.70206171437, 4112.443513348356, 8725.044234099976, 3347.704791341885, 3652.108740798703, 10799.015006138194, 30188.824196933147, 5661.737382541358, 14492.561889893997, 8617.46139390599, 31975.945756200348, 5821.131908273294, 3792.1386944884257, 10835.74836458026, 9340.761972955359, 16781.878841294827, 2190.1438188866427, 24433.69555465319, 37364.22537506536, 9794.186299862009, 5040.249430659587, 9380.978113626128, 6560.06745387388, 12669.393837410355, 19912.57419762192, 19044.885341486894, 29868.92913497369, 7137.799244087377, 42548.03720914647, 15591.337889662858, 33427.83347487163, 15703.850532388919, 39953.864758001604, 16748.43807488671, 13501.44928858633, 26516.84027793244, 40435.41421708348, 15620.76164533345, 19103.719527400423, 20288.61413191309, 13002.39990878242, 17149.600074520084, 15065.474115204228, 16406.98610518473, 18556.243120683605, 13873.794445208787, 14134.471306657675, 14461.646897728264], \"Total\": [407916.0, 691423.0, 1011411.0, 505781.0, 428427.0, 176279.0, 132976.0, 58432.0, 151220.0, 248026.0, 216823.0, 50369.0, 366141.0, 50534.0, 289528.0, 78707.0, 300063.0, 94900.0, 161179.0, 97739.0, 80791.0, 253321.0, 84349.0, 173934.0, 98780.0, 109430.0, 43097.0, 229400.0, 219210.0, 128865.0, 21284.879296361996, 5598.565619828242, 6533.214882295961, 5438.833955710859, 2124.1591360770976, 2140.4575493773505, 1048.899634888791, 1234.5925062726922, 1065.6369213218998, 864.6310515092172, 841.9540451500802, 837.5293203515782, 806.7226969724724, 844.3210783917302, 719.2195578140069, 677.7491061797987, 2284.470427397653, 659.0894587893948, 1178.414094025575, 746.1103123261738, 1476.9959155213248, 650.4133011544668, 593.077588371394, 613.2480737856191, 591.2861195374813, 593.1899755382155, 631.5732263008033, 698.8842252196397, 525.1382117474685, 514.4166558067903, 407916.21769535146, 1310.5586672237503, 14154.961560999727, 871.4294367810174, 899.0524389270694, 112515.10282718435, 15548.653980815952, 41801.051643056184, 128865.36588801073, 2702.0851863296957, 289528.5261082194, 66024.3279017714, 102399.66625986385, 25242.891233771636, 58477.74544992632, 2874.2990991945626, 505781.1975043502, 18571.046819124393, 83854.47645098905, 76414.56411919354, 159903.4853946846, 691423.0076431674, 98351.10145161176, 41443.358266867916, 21233.635434884145, 1011411.0898844848, 202264.25204444132, 11963.515411801662, 219210.75064149758, 7281.78710511836, 34394.99152258349, 13005.365487626184, 225898.87937272587, 96925.29992140799, 428427.8466062216, 58828.58837451071, 81318.7069654756, 229400.1490598412, 110242.8895351255, 366141.3852146692, 262500.9209562407, 89429.97948364547, 300063.5328023, 200918.44855310163, 111486.20716239391, 236733.3440056097, 143199.6966830861, 168019.72807766378, 159000.00193336615, 121887.83160880046, 154292.96356601466, 306022.74061320035, 29971.77900429257, 19145.207053436097, 11611.288866857427, 10379.336095804914, 9218.416860682386, 8067.255636229953, 7356.76633846047, 7120.313740819207, 6685.364160887032, 6623.594386207887, 6330.151209742642, 6007.707269560446, 5980.48107981471, 5728.232983154801, 5721.799888721583, 5604.533521781162, 5600.648536208241, 5522.979025612557, 5378.671220563825, 5034.582675808104, 4888.258411258574, 4831.0853055429525, 4762.893206878567, 4718.899734611777, 4790.543732912519, 4673.0617992627185, 4725.5355000163745, 4261.3303529914865, 4375.798552196584, 4084.3439071801317, 25185.865544793814, 18788.434882522928, 8208.607198272626, 14974.207437848227, 24408.178734065936, 34248.12490015849, 12833.125470477116, 12180.254858901588, 84349.42277007995, 26680.79201981222, 13859.36049958416, 16655.590659315614, 97739.19491684287, 16563.99263087707, 19739.148632551667, 26276.233537222735, 18443.394172968354, 29729.96482012186, 11763.00325007473, 8617.811451127589, 35112.570233149294, 41677.83970642508, 44132.518113957354, 112416.19292574446, 64082.15511707763, 158230.66836450147, 16659.887749911366, 31695.497514357157, 26670.140984709487, 114948.89059894832, 36972.143028046085, 366141.3852146692, 37103.75142699216, 159000.00193336615, 229400.1490598412, 1011411.0898844848, 39187.188295283704, 253321.55385828298, 306022.74061320035, 76567.15578251235, 109430.55271223058, 168019.72807766378, 119338.60799818387, 69303.88100892774, 216823.83350598515, 110242.8895351255, 81177.20643730578, 236733.3440056097, 115391.25690450285, 154292.96356601466, 248026.43086841484, 152834.0609044251, 44035.44711516729, 9450.839798759394, 7945.89885753413, 4469.961897948537, 4458.562519501389, 3557.4189753634514, 3466.8012102150733, 2940.3840768349573, 2816.138631380893, 2231.3814819956306, 2032.0614571421493, 1841.6795009192865, 1793.7411597079772, 1758.9571952230108, 1754.4753164265783, 1853.7793913188837, 1469.534582054358, 1602.7799633915647, 1430.8615371238097, 1404.6947025930906, 1364.6027389764854, 1175.1870812786285, 1193.212279231309, 1130.0395832073289, 926.4065256186899, 889.056265287633, 870.7260314192855, 851.697484302809, 835.3996662791459, 819.5281243989159, 34290.6923575228, 4215.485832001157, 12948.048251724711, 24506.15344638088, 2981.3699000438282, 4270.945344879013, 1911.4104861828766, 132976.78226644153, 23020.406184952473, 94900.60601569146, 10304.936797661974, 3822.753968962229, 3062.9788001657826, 31360.81965804023, 14225.574832982022, 13463.314718243115, 62928.12938360639, 14487.704081205682, 10766.93927475685, 36067.06769270458, 3437.0983724859866, 25765.281060689813, 8593.967037985101, 8323.136218474447, 25382.681132489815, 14537.804889526933, 248026.43086841484, 35757.04248529332, 38577.346537205376, 24683.293927967276, 176279.67687855428, 15619.503011328348, 57989.76999028703, 39199.868887242796, 90696.09082058005, 116909.99806541174, 216823.83350598515, 111920.63646688564, 50909.37201687557, 306022.74061320035, 60474.91051140606, 98148.32479127456, 68539.30276866886, 69303.88100892774, 44894.73944603691, 236733.3440056097, 1011411.0898844848, 161179.19101055176, 173934.30491656292, 300063.5328023, 253321.55385828298, 428427.8466062216, 114948.89059894832, 262500.9209562407, 691423.0076431674, 152834.0609044251, 80791.77662641086, 505781.1975043502, 200918.44855310163, 3739.2034124330758, 1469.2769790152229, 1311.9287618003002, 1084.3601569567443, 1005.0559128224725, 926.3606169674715, 874.7832776499839, 745.1629859284153, 651.7870542005523, 601.8656776404456, 545.4581416790849, 518.0429564479153, 518.1232989867856, 534.2338983345494, 457.2415875512788, 453.7354444465897, 498.63261121841856, 409.1496506304384, 467.5968834868243, 374.4044943329799, 381.5503089908971, 368.4533639406938, 359.4742807806786, 359.49788438001747, 338.4885684537679, 346.63000067836293, 1574.5234472707205, 309.06231234654814, 308.9737244401575, 445.61651739214227, 465.97359250073424, 766.8248188481547, 375.62691581536683, 382.6691959810162, 2076.813656946919, 4663.388637174071, 998.7959354698702, 40913.73549062207, 6264.767848954329, 448.43134109966, 18523.777611407793, 5128.73023650328, 1442.0155045140377, 1403.0911196886343, 17657.994504955084, 2256.130756316924, 3247.9747591974924, 4942.090976315461, 7965.644757081578, 17539.023144983435, 11184.933563856077, 3838.2023859298442, 16427.63097434539, 80791.77662641086, 5911.540655533503, 14008.637728376281, 151220.75624708444, 98780.90077500018, 45646.43205039612, 63905.6016633069, 79211.00639271789, 38795.23869560778, 161179.19101055176, 13527.306001595152, 173934.30491656292, 253321.55385828298, 53214.44412640749, 8673.631303001888, 39073.05873147575, 428427.8466062216, 98148.32479127456, 30537.140694498798, 300063.5328023, 306022.74061320035, 99103.79559630553, 691423.0076431674, 112036.46483596349, 102168.14198247576, 69337.16409095655, 105272.2881260696, 216823.83350598515, 262500.9209562407, 143199.6966830861, 219210.75064149758, 111073.56277944583, 110131.07049097607, 68015.51095329288, 505781.1975043502, 154292.96356601466, 236733.3440056097, 116909.99806541174, 9785.387013916068, 5657.0338847272615, 5031.434227951049, 2313.131805540568, 2229.4093079683007, 2070.767539086067, 2039.4926586463819, 1960.1474161852557, 1472.795923642515, 1322.2890730394768, 1257.2499148581885, 1328.2259667609276, 1178.4520272296186, 1182.7957731670676, 1039.5331080474414, 992.2921788662978, 1051.6570379492625, 888.6019566709825, 833.921274988601, 785.3643495344577, 830.3753495413199, 854.6570610013536, 936.6872475264456, 709.7470538001401, 846.9755723376643, 604.9874254889048, 596.4922667865757, 556.7288780473707, 596.5879527765337, 537.1894330713653, 58432.6853061895, 50369.67131342927, 12623.424083860918, 2277.9132793460203, 1038.0304643873603, 766.3448088247708, 50534.17766604506, 8958.838106773508, 4252.010951541976, 9161.131086253092, 3453.435854040732, 3830.070560381801, 11970.593078476242, 35335.83624866238, 6303.294494246959, 17385.301763719606, 10341.176447856807, 43097.61138850088, 6783.2175083280945, 4279.202744259941, 13913.860022974055, 11809.78850048645, 22873.301718709088, 2362.297757701232, 43188.36806564669, 78707.32074439299, 14725.658253837148, 6543.939756297685, 15678.533817707139, 9754.979366692925, 24892.72190015951, 50513.82091934009, 53214.44412640749, 109430.55271223058, 11283.394825092408, 216823.83350598515, 42483.183407407516, 176279.67687855428, 48927.42504108005, 366141.3852146692, 69337.16409095655, 44894.73944603691, 253321.55385828298, 1011411.0898844848, 68539.30276866886, 154292.96356601466, 200918.44855310163, 45175.154615501306, 151220.75624708444, 89429.97948364547, 143199.6966830861, 300063.5328023, 90696.09082058005, 158230.66836450147, 691423.0076431674], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.2947, -7.6303, -7.4759, -7.6592, -8.5996, -8.5921, -9.3055, -9.1425, -9.2897, -9.4987, -9.5253, -9.5306, -9.5681, -9.5226, -9.683, -9.7424, -8.5273, -9.7704, -9.1893, -9.6464, -8.9635, -9.7837, -9.876, -9.8425, -9.879, -9.8759, -9.8132, -9.712, -9.9978, -10.0184, -3.3952, -9.0834, -6.7277, -9.4916, -9.4607, -4.6964, -6.6524, -5.6883, -4.5865, -8.3822, -3.8271, -5.2713, -4.8479, -6.2114, -5.3997, -8.3275, -3.3133, -6.522, -5.0707, -5.1631, -4.4617, -3.0638, -4.9606, -5.7822, -6.4234, -2.7905, -4.3156, -6.9819, -4.252, -7.4516, -6.0172, -6.915, -4.3019, -5.0919, -3.7689, -5.5419, -5.2748, -4.3802, -5.0112, -4.0579, -4.3381, -5.2183, -4.272, -4.606, -5.0675, -4.6263, -4.9642, -4.887, -4.9318, -5.0812, -5.0375, -4.9002, -5.5784, -6.0267, -6.5267, -6.6389, -6.7575, -6.8909, -6.9831, -7.0158, -7.0789, -7.0881, -7.1335, -7.1857, -7.1903, -7.2334, -7.2345, -7.2552, -7.2559, -7.2699, -7.2964, -7.3625, -7.392, -7.4037, -7.418, -7.4272, -7.4122, -7.437, -7.4258, -7.5292, -7.5027, -7.5717, -5.7547, -6.0549, -6.8752, -6.2814, -5.8078, -5.4776, -6.4409, -6.4968, -4.6081, -5.7325, -6.3713, -6.1939, -4.4908, -6.2248, -6.0621, -5.7999, -6.139, -5.7066, -6.5697, -6.8544, -5.5929, -5.5143, -5.4711, -4.7023, -5.1998, -4.6284, -6.3434, -5.8629, -6.0004, -4.9676, -5.8039, -4.3184, -5.8096, -4.9803, -4.7775, -4.1509, -5.8443, -5.0526, -5.0054, -5.5973, -5.4655, -5.42, -5.5195, -5.6894, -5.4237, -5.5842, -5.6533, -5.4822, -5.6136, -5.6391, -5.629, -5.6733, -5.1012, -6.6402, -6.8136, -7.389, -7.3915, -7.6173, -7.6431, -7.8079, -7.8511, -8.0839, -8.1774, -8.2759, -8.3022, -8.3218, -8.3244, -8.2693, -8.5017, -8.4149, -8.5283, -8.5468, -8.5758, -8.7253, -8.7101, -8.7645, -8.9633, -9.0045, -9.0253, -9.0474, -9.0668, -9.0859, -5.3663, -7.4506, -6.3423, -5.713, -7.7995, -7.4444, -8.2418, -4.0577, -5.7882, -4.4031, -6.5856, -7.5595, -7.779, -5.4994, -6.275, -6.334, -4.8455, -6.2726, -6.5689, -5.4094, -7.6716, -5.7561, -6.8045, -6.8422, -5.8088, -6.3373, -3.7304, -5.5324, -5.4912, -5.8889, -4.1535, -6.3097, -5.2068, -5.6057, -4.9539, -4.7758, -4.385, -4.8849, -5.4607, -4.1886, -5.3584, -5.03, -5.3096, -5.3032, -5.5771, -4.6661, -3.9574, -4.9201, -4.8942, -4.6546, -4.7447, -4.5946, -5.1478, -4.9153, -4.7439, -5.1696, -5.3482, -5.1029, -5.3207, -6.943, -7.8774, -7.9907, -8.1813, -8.2573, -8.3389, -8.3962, -8.5567, -8.6907, -8.7705, -8.8691, -8.9207, -8.9205, -8.8899, -9.0457, -9.0534, -8.9591, -9.157, -9.0235, -9.2459, -9.227, -9.2619, -9.2866, -9.2866, -9.3469, -9.3232, -7.8098, -9.438, -9.4383, -9.0722, -9.0286, -8.5365, -9.2431, -9.2251, -7.5585, -6.7676, -8.2819, -4.6829, -6.5068, -9.0707, -5.5089, -6.7332, -7.9518, -7.9881, -5.6482, -7.5701, -7.2522, -6.8712, -6.4419, -5.7609, -6.1729, -7.1299, -5.8613, -4.4706, -6.7757, -6.0398, -4.0444, -4.4596, -5.1428, -4.9024, -4.7721, -5.348, -4.2291, -6.1914, -4.3663, -4.1104, -5.2622, -6.5856, -5.5176, -3.9015, -4.9598, -5.7754, -4.3143, -4.3534, -5.0582, -3.939, -5.0087, -5.0902, -5.3441, -5.1622, -4.8223, -4.7411, -5.0344, -4.8565, -5.1777, -5.2517, -5.3945, -5.0966, -5.2815, -5.2825, -5.3183, -5.5831, -6.131, -6.2482, -7.0255, -7.0624, -7.1362, -7.1514, -7.1911, -7.4771, -7.5849, -7.6354, -7.5805, -7.7002, -7.6965, -7.8256, -7.8722, -7.8141, -7.9826, -8.0462, -8.1062, -8.0505, -8.0217, -7.9301, -8.2075, -8.0309, -8.3674, -8.3815, -8.4506, -8.3815, -8.4864, -3.8083, -3.9581, -5.3316, -7.0421, -7.8279, -8.1312, -3.995, -5.7082, -6.4498, -5.6976, -6.6556, -6.5685, -5.4844, -4.4564, -6.1301, -5.1902, -5.71, -4.3988, -6.1023, -6.5309, -5.481, -5.6294, -5.0435, -7.0799, -4.6679, -4.2431, -5.582, -6.2464, -5.6251, -5.9828, -5.3246, -4.8725, -4.917, -4.467, -5.8984, -4.1132, -5.1171, -4.3544, -5.1099, -4.1761, -5.0455, -5.261, -4.5861, -4.1641, -5.1152, -4.9139, -4.8538, -5.2987, -5.0219, -5.1514, -5.0661, -4.943, -5.2338, -5.2152, -5.1923], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.0566, 1.0565, 1.0565, 1.0565, 1.0564, 1.0562, 1.0561, 1.0561, 1.0561, 1.0561, 1.056, 1.056, 1.056, 1.0559, 1.0559, 1.0559, 1.0558, 1.0558, 1.0558, 1.0558, 1.0558, 1.0558, 1.0558, 1.0558, 1.0558, 1.0557, 1.0557, 1.0556, 1.0556, 1.0556, 1.0031, 1.0554, 1.0316, 1.0553, 1.055, 0.9898, 1.0129, 0.9881, 0.964, 1.0331, 0.914, 0.948, 0.9326, 0.9694, 0.9409, 1.026, 0.8699, 0.9657, 0.9096, 0.9101, 0.8731, 0.8068, 0.8602, 0.9028, 0.9303, 0.6997, 0.7842, 0.9456, 0.7673, 0.9723, 0.8542, 0.9289, 0.6873, 0.7435, 0.5803, 0.7927, 0.7362, 0.5937, 0.6954, 0.4484, 0.501, 0.6976, 0.4333, 0.5004, 0.628, 0.3161, 0.4809, 0.3982, 0.4086, 0.525, 0.3329, -0.2145, 1.4306, 1.4306, 1.4306, 1.4306, 1.4306, 1.4306, 1.4306, 1.4306, 1.4306, 1.4305, 1.4305, 1.4305, 1.4305, 1.4305, 1.4305, 1.4305, 1.4305, 1.4305, 1.4305, 1.4305, 1.4305, 1.4305, 1.4305, 1.4305, 1.4305, 1.4305, 1.4305, 1.4305, 1.4305, 1.4305, 1.4284, 1.4212, 1.429, 1.4216, 1.4066, 1.3981, 1.4163, 1.4127, 1.3662, 1.3928, 1.4091, 1.4027, 1.3362, 1.3773, 1.3646, 1.3407, 1.3557, 1.3106, 1.3746, 1.4011, 1.2579, 1.165, 1.151, 0.9849, 1.0493, 0.7169, 1.2529, 1.0902, 1.1254, 0.6973, 0.9952, 0.1879, 0.986, 0.3601, 0.1964, -0.6607, 0.8966, -0.178, -0.3197, 0.4739, 0.2485, -0.1347, 0.1078, 0.4814, -0.3934, 0.1224, 0.3593, -0.5398, 0.0473, -0.2687, -0.7332, -0.2933, 1.5231, 1.5231, 1.523, 1.523, 1.523, 1.523, 1.5229, 1.5229, 1.5229, 1.5228, 1.5228, 1.5228, 1.5228, 1.5228, 1.5228, 1.5228, 1.5227, 1.5227, 1.5227, 1.5227, 1.5227, 1.5226, 1.5226, 1.5226, 1.5225, 1.5224, 1.5224, 1.5224, 1.5224, 1.5224, 1.5082, 1.52, 1.5061, 1.4974, 1.5174, 1.5131, 1.5196, 1.4615, 1.4847, 1.4534, 1.4911, 1.5088, 1.511, 1.4644, 1.4793, 1.4753, 1.4219, 1.4634, 1.464, 1.4145, 1.5031, 1.4042, 1.4537, 1.4481, 1.3664, 1.3953, 1.1654, 1.3002, 1.2655, 1.3143, 1.0837, 1.3511, 1.1422, 1.1349, 0.9479, 0.8721, 0.6452, 0.8067, 1.0186, 0.4971, 0.9487, 0.7928, 0.8723, 0.8677, 1.0279, 0.2763, -0.4672, 0.4067, 0.3565, 0.0507, 0.13, -0.2454, 0.517, -0.0762, -0.8733, 0.2104, 0.6693, -0.9197, -0.2143, 2.1475, 2.1472, 2.1471, 2.1471, 2.147, 2.1469, 2.1469, 2.1467, 2.1466, 2.1465, 2.1464, 2.1463, 2.1463, 2.1463, 2.1462, 2.1462, 2.1461, 2.146, 2.1459, 2.1459, 2.1459, 2.1458, 2.1458, 2.1458, 2.1457, 2.1456, 2.1455, 2.1455, 2.1455, 2.1455, 2.1443, 2.1383, 2.1454, 2.1449, 2.12, 2.102, 2.1286, 2.0149, 2.0676, 2.1407, 1.9814, 2.0413, 2.0915, 2.0826, 1.8899, 2.0256, 1.9791, 1.9403, 1.8923, 1.784, 1.8219, 1.9344, 1.749, 1.5468, 1.8567, 1.7298, 1.3462, 1.3568, 1.4456, 1.3495, 1.2651, 1.4031, 1.0977, 1.6132, 0.8843, 0.7643, 1.1728, 1.6635, 1.2263, 0.4477, 0.8631, 1.215, 0.391, 0.3323, 0.755, -0.0685, 0.6818, 0.6925, 0.8262, 0.5906, 0.2079, 0.098, 0.4107, 0.1628, 0.5215, 0.4559, 0.7951, -0.9133, 0.089, -0.3401, 0.3296, 2.5454, 2.5454, 2.5454, 2.5452, 2.5452, 2.5452, 2.5452, 2.5452, 2.5451, 2.545, 2.545, 2.545, 2.545, 2.5449, 2.5449, 2.5449, 2.5449, 2.5448, 2.5448, 2.5447, 2.5447, 2.5447, 2.5446, 2.5446, 2.5445, 2.5445, 2.5445, 2.5444, 2.5444, 2.5444, 2.5331, 2.5318, 2.5422, 2.5439, 2.5441, 2.5442, 2.4917, 2.5085, 2.5121, 2.4967, 2.5144, 2.4979, 2.4425, 2.3881, 2.4381, 2.3635, 2.3631, 2.247, 2.3925, 2.4247, 2.2955, 2.311, 2.2358, 2.4698, 1.9759, 1.8005, 2.1377, 2.2844, 2.0319, 2.1487, 1.8701, 1.6146, 1.518, 1.247, 2.0876, 0.917, 1.5431, 0.8828, 1.4091, 0.3302, 1.1248, 1.344, 0.2886, -0.6739, 1.0667, 0.4565, 0.2527, 1.3001, 0.3687, 0.7644, 0.379, -0.2377, 0.668, 0.1301, -1.3218]}, \"token.table\": {\"Topic\": [4, 1, 2, 3, 4, 5, 5, 2, 3, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 1, 2, 4, 5, 1, 2, 1, 3, 4, 1, 4, 1, 2, 3, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 3, 5, 2, 4, 5, 2, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 3, 4, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 5, 1, 3, 4, 3, 4, 5, 2, 3, 5, 5, 1, 1, 2, 3, 4, 1, 3, 4, 5, 2, 3, 4, 5, 4, 2, 4, 1, 2, 5, 4, 1, 2, 3, 4, 5, 2, 4, 1, 2, 4, 1, 1, 3, 4, 5, 5, 2, 3, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 2, 1, 2, 3, 4, 2, 3, 4, 2, 1, 2, 3, 4, 5, 1, 3, 4, 5, 3, 4, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 2, 3, 2, 3, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5, 1, 1, 3, 4, 5, 1, 3, 5, 2, 3, 3, 1, 2, 4, 5, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 1, 4, 1, 2, 3, 4, 2, 5, 1, 3, 4, 5, 1, 1, 2, 3, 4, 5, 3, 5, 2, 5, 1, 2, 4, 5, 5, 2, 3, 2, 5, 5, 4, 5, 5, 2, 2, 4, 5, 2, 3, 4, 5, 3, 4, 5, 4, 4, 4, 5, 2, 1, 3, 4, 5, 1, 3, 4, 5, 2, 2, 5, 1, 2, 3, 4, 5, 4, 1, 3, 4, 3, 1, 3, 4, 5, 4, 5, 1, 2, 2, 3, 1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 5, 3, 4, 1, 2, 3, 1, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 2, 1, 2, 3, 4, 5, 3, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 2, 3, 5, 5, 4, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 1, 2, 3, 5, 1, 3, 4, 5, 3, 2, 3, 2, 3, 4, 5, 4, 3, 3, 1, 3, 4, 3, 4, 5, 1, 2, 4, 4, 4, 1, 2, 3, 4, 5, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 1, 4, 5, 3, 1, 4, 2, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 3, 5, 1, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 5, 3, 5, 1, 2, 5, 1, 2, 3, 5, 3, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 5, 5, 1, 2, 3, 4, 2, 4, 1, 2, 3, 5, 3, 2, 3, 4, 5, 4, 5, 5, 3, 1, 2, 3, 3, 3, 3, 1, 2, 3, 4, 5, 5, 2, 4, 1, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 2, 3, 5, 3, 1, 1, 5, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 5, 1, 3, 4, 5, 2, 2, 2, 3, 4, 5, 1, 3, 4, 5, 1, 3, 1, 2, 3, 4, 5, 2, 3, 2, 3, 4, 5, 2, 5, 2, 4, 4, 1, 2, 3, 4, 3, 1, 4, 1, 2, 3, 4, 3, 2, 1, 3, 5, 1, 3, 1, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 4, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 4, 5, 1, 2, 1, 1, 2, 3, 5, 1, 2, 3, 4, 1, 1, 2, 3, 4, 3, 1, 2, 3, 1, 3, 4, 5, 1, 2, 3, 5, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 1, 3, 5, 1, 1, 3, 4, 5, 1, 1, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 1, 3, 4, 2, 5, 4, 5, 1, 2, 3, 3, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 5, 2, 1, 3, 4, 5, 4, 4, 5, 3, 4, 5, 1, 2, 3, 4, 5, 5, 3, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 1, 2, 1, 2, 3, 4, 5, 5, 2, 2, 4, 5, 2, 3, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 2, 2, 4, 4, 1, 2, 3, 5, 1, 2, 3, 4, 5, 3, 2, 5, 1, 1, 2, 3, 4, 5, 1, 2, 4, 2, 3, 1, 2, 3, 5, 5, 2, 4, 1, 2, 3, 5, 2, 3, 5, 2, 3, 4, 5, 2, 3, 4, 5, 1, 5, 1, 2, 3, 4, 5], \"Freq\": [0.9986806266650048, 0.43707565284148264, 0.26638487353969964, 0.18499461633016512, 0.03428060766438853, 0.0772591548926087, 0.9999247933170544, 0.16627405748679513, 0.16125098176740368, 0.6724770759022047, 0.99783198518773, 0.4220411637338804, 0.06646050471961919, 0.27864142309119955, 0.23088018742712724, 0.0019814977233085494, 0.0058223681609449055, 0.8371605024814288, 0.011284589837707653, 0.04405791989828413, 0.10168135736742959, 0.9752764032956505, 0.02472631228927763, 0.6294198176930337, 0.29105037757662133, 0.07952915494941933, 0.9995479760550127, 0.9998466664513662, 0.9999102622876298, 0.0012702256060186342, 0.0006351128030093171, 0.9977622135276372, 0.999619720033116, 0.9971901463714635, 0.9571889642899482, 0.005016511403253104, 0.03775246402191759, 0.7789095735123994, 0.00010124048408311848, 0.09104122845805918, 0.10903166247962934, 0.020916284011572278, 0.015018082740738677, 0.004004822064196981, 0.9811814057282603, 0.6998509380402814, 0.12352049651172847, 0.13664967823892965, 0.03997879833868359, 0.09320045663503174, 0.899052940468894, 0.0077992013920528645, 0.08735452671680895, 0.8756961340822135, 0.03693136258228828, 0.3540387002993329, 0.08390382586943733, 0.4486553412624405, 0.11341035731879336, 0.3011388193603409, 0.041370766632401745, 0.3429031127972948, 0.24841631798124356, 0.06618313618095685, 0.05419711480429889, 0.8412941520330999, 0.10449249301995409, 0.9130880001087363, 0.0581011943219512, 0.02880828448771445, 0.990556164809237, 0.009420688902865777, 0.10258584099651369, 0.11487888569068011, 0.699268216668462, 0.044253348167651876, 0.039011971289194564, 0.8948874667256115, 0.017553368953145753, 0.06277419087529743, 0.02482547894802042, 0.18536670570147143, 0.5862375179074756, 0.05922854129035176, 0.07137536837100986, 0.09776154316386798, 0.6968340572706356, 0.270294076340459, 0.00012699231722821752, 0.032736805205474076, 0.013136014135456994, 0.9822454569787967, 0.004597604947409948, 0.08226939294360644, 0.6829514381974462, 0.11371340409333464, 0.0904307913710545, 0.030632552797477133, 0.04224395934527525, 0.00235879976039608, 0.9553139029604123, 0.9998738338872835, 0.6162355550149025, 0.3838069527866436, 0.9999471363342866, 0.9999111403031608, 0.9990144742719035, 0.9998298732545647, 0.9999250827895166, 0.06637284779077457, 0.19968818308405276, 0.6037984516841135, 0.13015285275574792, 0.05521953447451598, 0.8115205392949594, 0.01985148341343568, 0.11339653484531932, 0.12284382309073857, 0.0030398034825946953, 0.7219533271162402, 0.15207958011451697, 0.9983310146611672, 0.9998227359531845, 0.9985577026726763, 0.047079589950073886, 0.1618995970944987, 0.7909540462655399, 0.9996678622370679, 0.28050856556604925, 0.17371258061894154, 0.3584308792876309, 0.1627787526514664, 0.024570069482201307, 0.05409095793757513, 0.9452048162681398, 0.004459991567706944, 0.002229995783853472, 0.992348123814795, 0.9988947146178899, 0.8813375390845833, 0.042385582193872236, 0.032636898289281624, 0.04365714965968841, 0.9996164228842804, 0.015310943499298462, 0.9402242847889432, 0.04446640909201955, 0.9998842653213535, 0.32141525580622893, 0.06862005294503762, 0.48848006699975927, 0.08815175030673712, 0.03332718717252478, 0.12284860929442488, 0.0784074952212549, 0.42162565427893056, 0.01012165203996986, 0.36699227198876766, 0.9998012210180053, 0.9998752069914111, 0.5230691760296589, 0.34281760589439025, 0.07114465322296437, 0.06296855269345114, 0.025881346930504943, 0.42577353087634606, 0.5483478869991536, 0.9998958321597814, 0.9992701493797664, 0.04836571877928001, 0.02713588182335842, 0.9230988504969515, 0.0014366055082954458, 0.03736572270794859, 0.927655128707624, 0.024389844725767086, 0.010452790596757322, 0.9879271772420426, 0.011753264501227208, 0.998556617566142, 0.47686565014400734, 0.13938889825008374, 0.28740353533969326, 0.08309349104422684, 0.013246972086558659, 0.354576795875633, 0.022273699764234375, 0.5630103411823697, 0.06012410715869056, 0.09377541207487064, 0.38702017274537315, 0.5191917029201408, 0.05739792751027253, 0.9426077124623882, 0.04664527370433114, 0.9533313503106532, 0.9988000024501198, 0.05459817808852711, 0.48027431767579926, 0.36563206291948785, 0.029839348445450605, 0.06964834508871065, 0.22275563594486378, 0.10923088127666117, 0.16161175515000592, 0.49554804141156755, 0.010844221065372498, 0.13411171208152378, 0.17473270325922366, 0.5215208366172961, 0.16234710729685065, 0.007296210881149293, 0.9994776451576213, 0.0018977646512934132, 0.0009488823256467066, 0.9968008830918653, 0.9987695486456007, 0.009113847211916758, 0.10469239874201813, 0.8861463750663677, 0.562284710547927, 0.09156443975588889, 0.05551687736877034, 0.1760548421816439, 0.11457426503011509, 0.9995161064533273, 0.6210614041728258, 0.17058181576878553, 0.18269820839153486, 0.025656595590302547, 0.9998642691243171, 0.9998822249034053, 0.9998172390782292, 0.05791117731955894, 0.9420402241446251, 0.9999898464715, 0.9191424994141202, 0.042022651250667974, 0.0357055206705022, 0.003021236364427109, 0.9995360757912253, 0.004831247083388403, 0.9858081750313983, 0.0093508008065582, 0.0028978520499050946, 0.9480202237429105, 0.049082369095267545, 0.8670440988124569, 0.03838309181267412, 0.07259733706565259, 0.014924263450244295, 0.007049391738474567, 0.9990923834688802, 0.9993645561157295, 0.9985616763463911, 0.8907491148851333, 0.03750144577440721, 0.023290911602709814, 0.04844578015453518, 0.09782305624485053, 0.9021273991359018, 0.03141907726432527, 0.03708746749242518, 0.8468035154092889, 0.08470194540846451, 0.999104156886642, 0.8632574319667843, 0.028489832637573185, 0.05819605829692639, 0.01797161062571067, 0.03210323543756677, 0.9998290377514071, 0.9988481694519575, 0.047592376519341374, 0.9523933145212237, 0.307659264915493, 0.16025550713324857, 0.4137430073481925, 0.11835476440634989, 0.9997813843845716, 0.06702376183828675, 0.9329800736447623, 0.07281046575914053, 0.9270634884448706, 0.9992311992361197, 0.0013169948246938038, 0.9982820771179034, 0.9999136969835287, 0.9998093338145803, 0.03506103041857041, 0.06663182251493018, 0.8982604263798445, 0.10475094629824278, 0.12468685260542087, 0.03681147611983323, 0.7336938150154885, 0.06515579807970605, 0.8851437330964149, 0.049642512822633184, 0.9989196328059563, 0.9965627891072109, 0.14563119332416533, 0.8543451409372769, 0.9998602033036563, 0.8574112110120145, 0.09335633408581877, 0.006032329677295087, 0.04319148048943282, 0.935367762687345, 0.05139754446016283, 0.01102074271668717, 0.002204148543337434, 0.9998175070933777, 0.9999195583418308, 0.9996293456066027, 0.5443115912263047, 0.2885797789235183, 0.032662246014578275, 0.02532628207150969, 0.1091217808567991, 0.998949398924974, 0.0009556738409933239, 0.962320118160232, 0.03675000315819782, 0.9995583044359581, 0.095784999298475, 0.336966715480789, 0.39348805181896607, 0.17375562607784903, 0.9998114861804964, 0.9997584405884997, 0.05440787411122531, 0.9455068372891373, 0.03144124086947437, 0.9684678514733155, 0.08910421223583992, 0.015632317936112267, 0.08728044180996015, 0.8079302986647356, 0.9984392865045942, 0.1120354032516393, 0.7369289877870545, 0.12174663800470978, 0.029283684718718304, 0.4522159497104542, 0.1783568390363352, 0.2690761454393136, 0.06423306389888488, 0.036124146458769824, 0.07320358328109564, 0.13663459188196, 0.7728888240471485, 0.017289939818870677, 0.731171325314074, 0.09673428926815333, 0.11830760399295161, 0.05111152613421839, 0.002672160934348519, 0.028335654389934264, 0.13762221731727833, 0.644413479826499, 0.18963048147081532, 0.0021460443597958274, 0.9957645829452639, 0.013781299649845376, 0.9786887353429459, 0.007576107137349551, 0.8800982956526807, 0.046365478968946924, 0.02898803577328854, 0.04452008677117789, 0.04945320168705788, 0.19302701303658076, 0.12487376555029489, 0.6326110280326508, 0.768061944854984, 0.11237733528320422, 0.1099465443369785, 0.0096041740183044, 0.8216684796332362, 0.12483845954730577, 0.053481861640236876, 0.9998866795061908, 0.32890814957058745, 0.19222395920076676, 0.20874454208369528, 0.1966714621676151, 0.07345582329254162, 0.9998408072368997, 0.9998864987060272, 0.9998164051944891, 0.9998989705816363, 0.026317139566297987, 0.03518808548752203, 0.5859999026461914, 0.35247225126996856, 0.5176773048924066, 0.20900521862389793, 0.1524106739903972, 0.08165707775493009, 0.03925729481570837, 0.9679654023875214, 0.030863003539067, 0.0011679471537962914, 0.6104075549592516, 0.00216581214352401, 0.16353781518819893, 0.21074872024659513, 0.013137360502165378, 0.9988293909437304, 0.0011122821725431296, 0.7615087611534911, 0.025990751933984542, 0.1338793174092386, 0.07861497936128746, 0.9761891806677572, 0.02032105735557173, 0.0034824392645637033, 0.9997055515779317, 0.9995621799079419, 0.9993978892426296, 0.8322958043816597, 0.060417694937380924, 0.051305948583611746, 0.02889242838326259, 0.027091341938591675, 0.8636704371833629, 0.05641594700815912, 0.015677639646433456, 0.048786511353843, 0.015455168966976553, 0.9996947276925086, 0.9999157986722109, 0.999007288877626, 0.9988668679061811, 0.04570102604249348, 0.09611957735388951, 0.858147330946305, 0.20998559807640335, 0.38413337545858783, 0.2901243982876741, 0.1157415331604109, 0.9993563377402402, 0.0004377382118879721, 0.048472639667935705, 0.9277576480515076, 0.0206578028115028, 0.0031447573833783787, 0.5361764506918676, 0.22936475938029235, 0.17261677724139285, 0.061840237054816706, 0.99963104279602, 0.11996309025005429, 0.8799815444776058, 0.998342325568278, 0.0015837035060875671, 0.003247930175491657, 0.996718474830147, 0.9991046037687322, 0.9997848084680592, 0.9999507725296801, 0.11876178125863705, 0.8419602077263266, 0.03924580696040136, 0.9746531642454638, 0.012772302298883407, 0.01256827191072233, 0.008207040891968722, 0.9360586084006547, 0.055676160125145834, 0.9992920638472582, 0.998731307972672, 0.48495406576325123, 0.18280807723245257, 0.08080731429249871, 0.12762085544863588, 0.1238164045752242, 0.9995795663051744, 0.9993225800748429, 0.9478784692222504, 0.0021818205832274326, 0.04431792416133205, 0.005621252356562362, 0.008185616433682043, 0.011074657527922764, 0.007704109584641923, 0.9726438350610428, 0.32341851410572686, 0.6712471212203746, 0.005356828390985125, 0.9998220943288937, 0.9991900421534041, 0.9983791337979189, 0.999975121895533, 0.07183786987909327, 0.6470006345548909, 0.13748188727237617, 0.09682965894847662, 0.04687312820047765, 0.9987235084152541, 0.5733868683022019, 0.06823166363628767, 0.1759718943412785, 0.08143104885500785, 0.10098126949570652, 0.23985726542993432, 0.08274020930609427, 0.3274368091135596, 0.34996453106845077, 0.9859384178530272, 0.014125941778737985, 0.06271866364568571, 0.9372163942508717, 0.49869507005971936, 0.15380315244832465, 0.02281832450050663, 0.2585733717721715, 0.06611727144251181, 0.025574125412841986, 0.028324371285422027, 0.9326389336793648, 0.004847176633665972, 0.008630081876027023, 0.2504548384149457, 0.5216277165915845, 0.2279130275474698, 0.9988119252640425, 0.9992662999007829, 0.03569861197547782, 0.01666199073356559, 0.9476358815308658, 0.045667535518618366, 0.1167200977640665, 0.23930809115343032, 0.5983340093577638, 0.9991661769683146, 0.7258108521703153, 0.16185697597956167, 0.03620323182524157, 0.07000849143379764, 0.006124052122612195, 0.9991423060330397, 0.9999224765591678, 0.02922218642747853, 0.3400319023298295, 0.1560210649258419, 0.47472077116361205, 0.9988952494483204, 0.06373820342636546, 0.06373820342636546, 0.059691333367548616, 0.8128138513133654, 0.9999559372198155, 0.9968485202360755, 0.014617395829772204, 0.1620158480189935, 0.6782675747329553, 0.1451025261426602, 0.9993555750154356, 0.22506059930825625, 0.1513370449669509, 0.057862802229560945, 0.5657541855450549, 0.04621324782652457, 0.9535072376410606, 0.9993752355325423, 0.9991810656768818, 0.9998691766930411, 0.05704570287088589, 0.9429281607573876, 0.9998868778032233, 0.9997688906382308, 0.999636223562966, 0.6983564165014853, 0.052566264994611756, 0.013295317821440836, 0.06731523404968363, 0.16845581411270497, 0.9991747306478462, 0.9707801159777474, 0.02912572425417339, 0.009833888427150963, 0.9899447683331969, 0.04672955040404925, 0.06303055635895015, 0.8879002695958759, 0.0023287151364144144, 0.5736932253472148, 0.06475786804128493, 0.2020259578778412, 0.1287728815459471, 0.030754177816182907, 0.06790270758546721, 0.8002060017063316, 0.13189010254244785, 0.9997290834347294, 0.9997368088164664, 0.9998521501119186, 0.9994871658792641, 0.9986150561612452, 0.9993272100009819, 0.9140198866773535, 0.04772373476676526, 0.014537852217627057, 0.023709638564349888, 0.0015328826304885062, 0.09941254819594793, 0.30312243057033383, 0.2749787054745648, 0.32096518438922, 0.16661547249366285, 0.8332707640614584, 0.8970935696327004, 0.009693396666637316, 0.08922468712993817, 0.003998526124987893, 0.9998124654826867, 0.9999740087402733, 0.30663282939125375, 0.2773722625692959, 0.14304962930384998, 0.2729493661477383, 0.9164560345230891, 0.04143740866737923, 0.017034498782957045, 0.025036751699601983, 0.9993679978256093, 0.9995215867383261, 0.5386036813730992, 0.1418491614614791, 0.10484779589013565, 0.18419869987245965, 0.030509101428150668, 0.9977421643622818, 0.0022631741561005237, 0.03358659577334988, 0.4792340664759178, 0.47492941452338566, 0.012243770523669373, 0.9999891851033254, 0.998367857830918, 0.9999455286386398, 0.9981824981186568, 0.9979867375187057, 0.013206137783494745, 0.30031471164952644, 0.02798273519529697, 0.658450891432192, 0.9998693786849197, 0.9987348044386583, 0.998251241573546, 0.02944514394816784, 0.012726291028445422, 0.8970787499462999, 0.060775664344994255, 0.9995054422916181, 0.9997753495386001, 0.9338042576850855, 0.04011860788384199, 0.026075898982342142, 0.014814515691414827, 0.985165293479086, 0.015605696262290405, 0.9571493707538116, 0.015394808474962158, 0.011880012019491345, 0.06617425517798191, 0.766738396833789, 0.16706720043665266, 0.17135110954948338, 0.22540581526377204, 0.09494186972176155, 0.26675449223358677, 0.24154434666566346, 0.010774687563962292, 0.017403295827777575, 0.41258607652882684, 0.3979724266499136, 0.16128760339213863, 0.04905596321132985, 0.9036976080019131, 0.03696280221235932, 0.010281570520806742, 0.13668179702759395, 0.11570587768177508, 0.7475208676546259, 0.029492936547018605, 0.09443852220755179, 0.06463995937507186, 0.041106735394549246, 0.7701782393625584, 0.12794231848839543, 0.3425592136072887, 0.274535192550778, 0.16721442626241861, 0.08774630604591187, 0.007824472881580153, 0.9910998983334861, 0.9994716413426595, 0.9998822729655905, 0.9941738527501828, 0.005702076753290522, 0.032929739605254846, 0.8868829868965827, 0.07608485289794327, 0.0041036039140358435, 0.6911897944494699, 0.11536135138148179, 0.10860168969462368, 0.06267406035529621, 0.02217363810705458, 0.07045164692519859, 0.7114575182101336, 0.21807513817598417, 0.9999430185775612, 0.013579600226965067, 0.9864070720420459, 0.9766531467442795, 0.022945242553294932, 0.999520079483974, 0.08094489565682939, 0.008865181197418298, 0.6094477958355831, 0.30072565664910667, 0.17537742021176347, 0.06610403197199334, 0.48176064238035343, 0.27675459624772736, 0.9999586891544108, 0.08287668671224216, 0.04254198629194786, 0.6832584438020097, 0.19132684957809545, 0.9994558166477215, 0.07177263948171873, 0.9099010900966062, 0.018324276167036104, 0.04216900198505357, 0.22270269274726823, 0.37724719913099397, 0.3578915520522929, 0.001868640331084958, 0.030904436244866614, 0.18844519031172155, 0.7787917933706386, 0.20126405433026756, 0.05680129179161806, 0.7419436708859392, 0.7487543358146255, 0.025021583038006643, 0.060909421462801226, 0.13740658207617104, 0.0279046533169529, 0.13992646068694317, 0.6403170052871928, 0.20220396553559472, 0.006004473042828139, 0.011546379273468037, 0.9999547795799771, 0.08299825581445244, 0.16136602436297298, 0.4156646367822483, 0.14373881088648727, 0.19623304003074696, 0.005797312938737215, 0.9376116326910228, 0.056586042242520916, 0.9699756023237994, 0.02992033780482308, 0.9982451648275231, 0.9996797391290316, 0.38117265039696413, 0.31140492972897277, 0.2827101877550177, 0.02471622836025504, 0.9999671092563414, 0.9997862375838832, 0.180717178885501, 0.48979758981658383, 0.16737589668136418, 0.0727798227678066, 0.08932528786038368, 0.9998181386661238, 0.2699813404288118, 0.0006074048680388731, 0.2759642783789947, 0.4534378574054861, 0.21757091143988636, 0.3322713415933938, 0.4501483320908523, 0.9724662626083981, 0.027498274265274205, 0.030404502772838116, 0.9694692884139239, 0.019068119615641404, 0.1259520215107553, 0.8549530243368473, 0.9995868078825275, 0.9995611801002606, 0.0005231738589009309, 0.0026158692945046544, 0.9966462012062733, 0.5876386432887244, 0.09616218325729677, 0.19428518571077935, 0.08086123011551206, 0.0410459348891951, 0.00029094308385381457, 0.9801872495035013, 0.019493186618205576, 0.8167758954542654, 0.059747070984178106, 0.03741823861636848, 0.04692543677297492, 0.03913360464462468, 0.6410403014584918, 0.24008354027295545, 0.06298554486056318, 0.0558703613589848, 0.9995954756382882, 0.9994595832119453, 0.9999048053189283, 0.032514631005826, 0.003264017012167861, 0.774576344810604, 0.18968960405329377, 0.9986164844253299, 0.012270529691437123, 0.9877177421775364, 0.13361861827717803, 0.03272879629776767, 0.8336352280202932, 0.19613806738212297, 0.2001645703956432, 0.24829707161510592, 0.25072481607914016, 0.10467723569560348, 0.999647362625355, 0.9990800470861576, 0.1891211370542457, 0.07121263195078471, 0.03495063521683829, 0.6950786197854415, 0.009635656364837963, 0.09740630508845971, 0.11224377714263206, 0.7727944414169309, 0.01749915597228724, 0.6513720562241493, 0.07409885231781899, 0.07889765221977192, 0.13426773034081013, 0.06137082042834009, 0.1548657355096814, 0.8448341515677252, 0.9983596643392061, 0.001147539844068053, 0.3468807002693984, 0.2507469003821114, 0.26012369398871416, 0.08990282520785317, 0.05235231994222489, 0.9989474365604758, 0.9998842033732257, 0.9999683118719078, 0.032690414390770126, 0.9670718271571709, 0.012897696761189873, 0.9830825273843466, 0.004016049290909421, 0.9115404995790938, 0.03862170386669461, 0.04753798631452104, 0.0023047309721535665, 0.17887180529459556, 0.20873434307592587, 0.2714349058511477, 0.23336041487462367, 0.10759714120949325, 0.9999676187569405, 0.9999593272208923, 0.9987924672705908, 0.9991600791260086, 0.01894294809648776, 0.7560864737842148, 0.22498149718902746, 0.9998582566112004, 0.8296789245440281, 0.03474625013091525, 0.08691307667605004, 0.046840412646609375, 0.0018209455087386448, 0.9995133683915575, 0.03627702567303647, 0.9637410451107596, 0.9994023092582888, 0.8833231914101773, 0.009277373986641186, 0.04857437706268764, 0.04814468816225373, 0.010683628569879429, 0.999325715453334, 0.000677049942719061, 0.9999456000621952, 0.990970644796433, 0.009015502193376808, 0.0312541152839945, 0.20303123219191285, 0.2567417105141502, 0.5089439415590312, 0.9986907845522095, 0.999772782961508, 0.9996107164306574, 0.21128870683985992, 0.0664081844441676, 0.43448661475670725, 0.28781307138102236, 0.9629024498569145, 0.022787929216963296, 0.014317416054078913, 0.27293520365475676, 0.20010365115995368, 0.13275574640667287, 0.39420894396004724, 0.17697001757601838, 0.12692132112416668, 0.030966357641851256, 0.6650976025094105, 0.9988106848913128, 0.0007630333727206361, 0.0019074692021978988, 0.21022956808270135, 0.562593156312993, 0.07230741634690069, 0.15297241451614826], \"Term\": [\"acca\", \"accept\", \"accept\", \"accept\", \"accept\", \"accept\", \"accession\", \"accommodation\", \"accommodation\", \"accommodation\", \"accountant\", \"act\", \"act\", \"act\", \"act\", \"act\", \"activity\", \"activity\", \"activity\", \"activity\", \"activity\", \"adjournment\", \"adjournment\", \"adjudicator\", \"adjudicator\", \"adjudicator\", \"adoptive\", \"afresh\", \"airport\", \"allowable\", \"allowable\", \"allowable\", \"ancestry\", \"ankara_agreement\", \"anonymity\", \"anonymity\", \"anonymity\", \"appeal\", \"appeal\", \"appeal\", \"appeal\", \"appeal\", \"appealable\", \"appealable\", \"appealable\", \"appellant\", \"appellant\", \"appellant\", \"appellant\", \"appendix\", \"appendix\", \"appendix\", \"applicant\", \"applicant\", \"applicant\", \"application\", \"application\", \"application\", \"application\", \"apply\", \"apply\", \"apply\", \"apply\", \"apply\", \"area\", \"area\", \"area\", \"arguable\", \"arguable\", \"arguable\", \"arrest\", \"arrest\", \"article\", \"article\", \"article\", \"article\", \"article\", \"aside\", \"aside\", \"aside\", \"aside\", \"ask\", \"ask\", \"ask\", \"ask\", \"ask\", \"asylum\", \"asylum\", \"asylum\", \"asylum\", \"attack\", \"attack\", \"attack\", \"authority\", \"authority\", \"authority\", \"authority\", \"authority\", \"award\", \"award\", \"award\", \"balancing_exercise\", \"bank\", \"bank\", \"beat\", \"best_interest\", \"bill\", \"boc\", \"bradford\", \"breach\", \"breach\", \"breach\", \"breach\", \"british\", \"british\", \"british\", \"british\", \"business\", \"business\", \"business\", \"business\", \"buxton_lj\", \"camp\", \"cancellation\", \"card\", \"card\", \"card\", \"cas\", \"case\", \"case\", \"case\", \"case\", \"case\", \"caseworker\", \"caseworker\", \"ccol\", \"ccol\", \"ccol\", \"chalkley\", \"chamber\", \"chamber\", \"chamber\", \"chamber\", \"chikwamba\", \"child\", \"child\", \"child\", \"cipu\", \"circumstance\", \"circumstance\", \"circumstance\", \"circumstance\", \"circumstance\", \"citizen\", \"citizen\", \"citizen\", \"citizen\", \"citizen\", \"civil_partnership\", \"civilian\", \"claim\", \"claim\", \"claim\", \"claim\", \"claimant\", \"claimant\", \"claimant\", \"clan\", \"clive_lane\", \"college\", \"college\", \"college\", \"college\", \"compelling\", \"compelling\", \"compelling\", \"compelling\", \"conducive\", \"conducive\", \"confirmation_acceptance\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consideration\", \"consideration\", \"consideration\", \"consideration\", \"convention\", \"convention\", \"convention\", \"convict\", \"convict\", \"conviction\", \"conviction\", \"counsel_instructed\", \"country\", \"country\", \"country\", \"country\", \"country\", \"course\", \"course\", \"course\", \"course\", \"course\", \"court\", \"court\", \"court\", \"court\", \"court\", \"criminality\", \"croatia\", \"croatia\", \"croatia\", \"curtailment\", \"customary\", \"customary\", \"customary\", \"date\", \"date\", \"date\", \"date\", \"date\", \"dean\", \"decision\", \"decision\", \"decision\", \"decision\", \"delivered_orally\", \"democratic_society\", \"dependency\", \"deport\", \"deport\", \"deportation\", \"deputy\", \"deputy\", \"deputy\", \"deputy\", \"derivative\", \"detain\", \"detain\", \"detain\", \"detention\", \"detention\", \"detention\", \"determination\", \"determination\", \"determination\", \"determination\", \"determination\", \"differently_constitute\", \"digney\", \"diploma\", \"direction\", \"direction\", \"direction\", \"direction\", \"directive\", \"directive\", \"discretion\", \"discretion\", \"discretion\", \"discretion\", \"dismis\", \"dismiss\", \"dismiss\", \"dismiss\", \"dismiss\", \"dismiss\", \"disruption\", \"dissolution\", \"divorce\", \"divorce\", \"document\", \"document\", \"document\", \"document\", \"domicile\", \"drug\", \"drug\", \"durable\", \"durable\", \"ecj\", \"eco\", \"eco\", \"eea\", \"election\", \"employer\", \"employer\", \"employer\", \"employment\", \"employment\", \"employment\", \"employment\", \"english_language\", \"english_language\", \"english_language\", \"entrepreneur\", \"entrepreneur_migrant\", \"entry_clearance\", \"entry_clearance\", \"eritrean\", \"err\", \"err\", \"err\", \"err\", \"error\", \"error\", \"error\", \"error\", \"escape\", \"ethnic\", \"european_economic\", \"evidence\", \"evidence\", \"evidence\", \"evidence\", \"evidence\", \"evidential_flexibility\", \"exceptional\", \"exceptional\", \"exceptional\", \"exceptionality\", \"exercise\", \"exercise\", \"exercise\", \"exercise\", \"exercised_differently\", \"exercising_treaty\", \"expert\", \"expert\", \"expulsion\", \"expulsion\", \"extension\", \"extension\", \"extension\", \"extension\", \"extension_stay\", \"face\", \"face\", \"face\", \"face\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"factor\", \"factor\", \"factor\", \"factor\", \"fail\", \"fail\", \"fail\", \"fail\", \"fail\", \"family\", \"family\", \"family\", \"family\", \"fca\", \"fca\", \"fear\", \"fear\", \"fear\", \"field_house\", \"field_house\", \"field_house\", \"field_house\", \"financial\", \"financial\", \"financial\", \"financial\", \"find\", \"find\", \"find\", \"find\", \"finding\", \"finding\", \"finding\", \"flee\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"foreign_criminal\", \"founded_fear\", \"free_movement\", \"fttj\", \"fund\", \"fund\", \"fund\", \"fund\", \"give\", \"give\", \"give\", \"give\", \"give\", \"government\", \"government\", \"government\", \"grant\", \"grant\", \"grant\", \"grant\", \"grant\", \"griffith\", \"griffith\", \"ground\", \"ground\", \"ground\", \"ground\", \"group\", \"group\", \"group\", \"gurkha\", \"handbook\", \"health_moral\", \"hear\", \"hear\", \"hear\", \"hear\", \"hear\", \"hearing\", \"hearing\", \"hearing\", \"hearing\", \"hearing\", \"hodgett\", \"homosexual\", \"hong_kong\", \"hopo\", \"household\", \"household\", \"household\", \"human\", \"human\", \"human\", \"human\", \"hunter\", \"hunter\", \"ill\", \"ill\", \"ill\", \"ill\", \"immigration\", \"immigration\", \"immigration\", \"immigration\", \"imperative\", \"imprisonment\", \"imprisonment\", \"incident\", \"incident\", \"income\", \"income\", \"incorporation\", \"insurmountable_obstacle\", \"integration\", \"interest\", \"interest\", \"interest\", \"interference\", \"interference\", \"interference\", \"international\", \"international\", \"international\", \"invalid\", \"invalidate\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"jamaican\", \"jobseeker\", \"judge\", \"judge\", \"judge\", \"judge\", \"judicial_review\", \"judicial_review\", \"judicial_review\", \"judicial_review\", \"jurisdiction\", \"jurisdiction\", \"jurisdiction\", \"juvenile\", \"keane\", \"khatel\", \"kill\", \"know\", \"know\", \"know\", \"know\", \"know\", \"ladd_marshall\", \"law\", \"law\", \"law\", \"law\", \"law\", \"leave\", \"leave\", \"leave\", \"leave\", \"legitimate_aim\", \"legitimate_aim\", \"legitimate_expectation\", \"legitimate_expectation\", \"letter\", \"letter\", \"letter\", \"letter\", \"letter\", \"life\", \"life\", \"life\", \"life\", \"life\", \"live\", \"live\", \"live\", \"lord_bingham\", \"maintain_accommodate\", \"marriage\", \"marriage\", \"marriage\", \"marry\", \"marry\", \"marry\", \"marry\", \"maslov\", \"material\", \"material\", \"material\", \"material\", \"material\", \"mcgeachy\", \"mdc\", \"member\", \"member\", \"member\", \"member\", \"metock\", \"migrant\", \"migrant\", \"migrant\", \"migrant\", \"military\", \"module\", \"mother\", \"mother\", \"mother\", \"mother\", \"nagre\", \"national\", \"national\", \"national\", \"national\", \"nepal\", \"nepal\", \"nepalese\", \"nom\", \"novo\", \"offence\", \"offence\", \"offend\", \"offender\", \"offending\", \"officer\", \"officer\", \"officer\", \"officer\", \"officer\", \"ofm\", \"organisation\", \"organisation\", \"outweigh\", \"outweigh\", \"panel\", \"panel\", \"panel\", \"panel\", \"paragraph\", \"paragraph\", \"paragraph\", \"paragraph\", \"paragraph\", \"parent\", \"parent\", \"parent\", \"parental\", \"parke\", \"parker\", \"payslip\", \"pbs\", \"pension\", \"people\", \"people\", \"people\", \"people\", \"period\", \"period\", \"period\", \"period\", \"period\", \"permanent\", \"permanent\", \"permission\", \"permission\", \"permission\", \"permission\", \"persecute\", \"persecution\", \"person\", \"person\", \"person\", \"person\", \"pic\", \"pic\", \"pic\", \"pic\", \"pickup\", \"pleaded_guilty\", \"point\", \"point\", \"point\", \"point\", \"point\", \"police\", \"police\", \"policy\", \"policy\", \"policy\", \"policy\", \"political\", \"polygamous\", \"population\", \"postal\", \"postgraduate\", \"power\", \"power\", \"power\", \"power\", \"precarious\", \"preferably\", \"principled\", \"private\", \"private\", \"private\", \"private\", \"probation\", \"profile\", \"promulgate\", \"promulgate\", \"promulgate\", \"proportionality\", \"proportionality\", \"proportionate\", \"proportionate\", \"proportionate\", \"proportionate\", \"protection\", \"protection\", \"protection\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provision\", \"provision\", \"provision\", \"provision\", \"provision\", \"public\", \"public\", \"public\", \"public\", \"qualification\", \"qualification\", \"qualification\", \"qualified\", \"qualified\", \"qualified\", \"qualified\", \"qualified\", \"question\", \"question\", \"question\", \"question\", \"question\", \"racially_discriminate\", \"racially_discriminate\", \"raju\", \"rape\", \"razgar\", \"razgar\", \"real\", \"real\", \"real\", \"real\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"refugee\", \"refugee\", \"refugee\", \"reg\", \"regulation\", \"regulation\", \"rehear\", \"rehear\", \"reheard\", \"relationship\", \"relationship\", \"relationship\", \"relationship\", \"remain\", \"remain\", \"remain\", \"remain\", \"remit\", \"removal\", \"removal\", \"removal\", \"removal\", \"reoffende\", \"report\", \"report\", \"report\", \"requirement\", \"requirement\", \"requirement\", \"requirement\", \"reside\", \"reside\", \"reside\", \"reside\", \"residence\", \"residence\", \"residence\", \"respondent\", \"respondent\", \"respondent\", \"respondent\", \"respondent\", \"return\", \"return\", \"return\", \"return\", \"return\", \"returnee\", \"right\", \"right\", \"right\", \"right\", \"right\", \"risk\", \"risk\", \"risk\", \"rk\", \"rk\", \"romanian\", \"rothwell\", \"rule\", \"rule\", \"rule\", \"rule\", \"saunder\", \"savage\", \"say\", \"say\", \"say\", \"say\", \"say\", \"scar\", \"secretary\", \"secretary\", \"secretary\", \"secretary\", \"section\", \"section\", \"section\", \"seeker\", \"seeker\", \"self_employe\", \"self_employe\", \"sentence\", \"sentence\", \"sentence\", \"sentencing\", \"sentencing_remark\", \"serbian\", \"serbian\", \"serbian\", \"set\", \"set\", \"set\", \"set\", \"set\", \"shala\", \"shala\", \"shala\", \"sign\", \"sign\", \"sign\", \"sign\", \"sign\", \"situation\", \"situation\", \"situation\", \"situation\", \"slatter\", \"sole_responsibility\", \"somali\", \"specify\", \"specify\", \"specify\", \"specify\", \"speedily\", \"sponsor\", \"sponsor\", \"spouse\", \"spouse\", \"spouse\", \"state\", \"state\", \"state\", \"state\", \"state\", \"statutory_declaration\", \"strasbourg_jurisprudence\", \"student\", \"student\", \"student\", \"student\", \"student\", \"study\", \"study\", \"study\", \"study\", \"submit\", \"submit\", \"submit\", \"submit\", \"submit\", \"subsection\", \"subsection\", \"surendran_guideline\", \"surendran_guideline\", \"take\", \"take\", \"take\", \"take\", \"take\", \"talaq\", \"tamil\", \"target\", \"tax\", \"tax\", \"tie\", \"tie\", \"tie\", \"tier\", \"tier\", \"tier\", \"tier\", \"time\", \"time\", \"time\", \"time\", \"time\", \"torture\", \"traffic\", \"transitional_arrangement\", \"treasury_solicitor\", \"treatment\", \"treatment\", \"treatment\", \"treaty\", \"tribunal\", \"tribunal\", \"tribunal\", \"tribunal\", \"tribunal\", \"truly_exceptional\", \"union\", \"union\", \"unsound\", \"upper\", \"upper\", \"upper\", \"upper\", \"upper\", \"uzbekistan\", \"uzbekistan\", \"variation\", \"violence\", \"violence\", \"visit\", \"visit\", \"visit\", \"visit\", \"wage_slip\", \"war\", \"wednesbury\", \"wife\", \"wife\", \"wife\", \"wife\", \"woman\", \"woman\", \"woman\", \"work\", \"work\", \"work\", \"work\", \"worker\", \"worker\", \"worker\", \"worker\", \"working_holidaymaker\", \"working_holidaymaker\", \"year\", \"year\", \"year\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 3, 4, 2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el343711405733504493284260864967\", ldavis_el343711405733504493284260864967_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el343711405733504493284260864967\", ldavis_el343711405733504493284260864967_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el343711405733504493284260864967\", ldavis_el343711405733504493284260864967_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "4     -0.184303 -0.029563       1        1  34.762640\n",
       "2      0.059525  0.180654       2        1  23.915208\n",
       "3      0.014296  0.029241       3        1  21.803026\n",
       "1     -0.056499 -0.060373       4        1  11.675673\n",
       "0      0.166980 -0.119960       5        1   7.843453, topic_info=            Term          Freq         Total Category  logprob  loglift\n",
       "181        judge  4.079160e+05  4.079160e+05  Default  30.0000  30.0000\n",
       "21        appeal  6.914230e+05  6.914230e+05  Default  29.0000  29.0000\n",
       "22     appellant  1.011411e+06  1.011411e+06  Default  28.0000  28.0000\n",
       "342     tribunal  5.057810e+05  5.057810e+05  Default  27.0000  27.0000\n",
       "90      decision  4.284270e+05  4.284270e+05  Default  26.0000  26.0000\n",
       "..           ...           ...           ...      ...      ...      ...\n",
       "86          date  1.640699e+04  1.431997e+05   Topic5  -5.0661   0.3790\n",
       "171  immigration  1.855624e+04  3.000635e+05   Topic5  -4.9430  -0.2377\n",
       "364         year  1.387379e+04  9.069609e+04   Topic5  -5.2338   0.6680\n",
       "299          say  1.413447e+04  1.582307e+05   Topic5  -5.2152   0.1301\n",
       "21        appeal  1.446165e+04  6.914230e+05   Topic5  -5.1923  -1.3218\n",
       "\n",
       "[459 rows x 6 columns], token_table=       Topic      Freq    Term\n",
       "term                          \n",
       "14620      4  0.998681    acca\n",
       "4          1  0.437076  accept\n",
       "4          2  0.266385  accept\n",
       "4          3  0.184995  accept\n",
       "4          4  0.034281  accept\n",
       "...      ...       ...     ...\n",
       "364        1  0.001907    year\n",
       "364        2  0.210230    year\n",
       "364        3  0.562593    year\n",
       "364        4  0.072307    year\n",
       "364        5  0.152972    year\n",
       "\n",
       "[936 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 3, 4, 2, 1])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corp, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building LDA Mallet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim.models.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fc/h07gydfn7nd0zq3mglwpn3r40000gn/T/ipykernel_34371/1915903805.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Building LDA Mallet Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLdaMallet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmallet_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./data/mallet-2.0.8/bin/mallet'\u001b[0m \u001b[0;31m# update this path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mldamallet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMallet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmallet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim.models.wrappers'"
     ]
    }
   ],
   "source": [
    "# Building LDA Mallet Model\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "\n",
    "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "mallet_path = './data/mallet-2.0.8/bin/mallet' # update this path\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus = corp, num_topics = 5, id2word = id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[3]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What topic each document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimal_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fc/h07gydfn7nd0zq3mglwpn3r40000gn/T/ipykernel_34371/343875353.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mdf_topic_sents_keywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_topics_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimal_model' is not defined"
     ]
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corp, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most representative document for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0da6e46dab1e0b3d9fa32aec1170dd2df7038a4f7be3a54c97a348d8ad782954"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('tfm': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
