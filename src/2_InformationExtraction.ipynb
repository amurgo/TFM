{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information extraction (20th November 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook extracts additional information from the text of the tribunal decisions and stores it in the relevant dictionary.\n",
    "\n",
    "In particular, the notebook performs information extraction on:\n",
    "\n",
    "1. The label included in the name of the file ('Code label:').\n",
    "\n",
    "2. The court where the case was heard ('Heard at').\n",
    "\n",
    "3. The judges ('Judges:').\n",
    "\n",
    "4. The legal representation ('Representation:') for the appellant ('Representation appellant:') and the respondent ('Representation respondent:').\n",
    "\n",
    "5. The decision/ruling by the judge ('Decision:').\n",
    "\n",
    "6. The sense of the decision/ruling ('Decision label:').\n",
    "\n",
    "7. The nationality of the the subject of the case (appellant or respondent).\n",
    "\n",
    "Each of these fields is added to the dictionary of each judicial decision.\n",
    "\n",
    "The resulting data set - a list of updated dictionaries -  is serialised as a json object (jsonDataFinal.json).\n",
    "\n",
    "This notebook should run in the tfm environment, which can be created with the environment.yml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current environment: /Users/albertamurgopacheco/anaconda3/envs/tfm/bin/python\n",
      "Current working directory: /Users/albertamurgopacheco/Documents/GitHub/TFM\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join, getsize\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import whois\n",
    "import sys\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import textract\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import stanza\n",
    "import spacy\n",
    "\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "\n",
    "# What environment am I using?\n",
    "print(f'Current environment: {sys.executable}')\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir('/Users/albertamurgopacheco/Documents/GitHub/TFM')\n",
    "# What's my working directory?\n",
    "print(f'Current working directory: {os.getcwd()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define working directories in colab and local execution\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    docs_path = '/content/gdrive/MyDrive/TFM/data/raw'\n",
    "    input_path = '/content/gdrive/MyDrive/TFM'\n",
    "    output_path = '/content/gdrive/MyDrive/TFM/output'\n",
    "\n",
    "else:\n",
    "    docs_path = './data/raw'\n",
    "    input_path = '.'\n",
    "    output_path = './output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFORMATION EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Auxiliary functions and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to capture whether all elements exist in a list\n",
    "def sublist(sublist, lst):\n",
    "    \"\"\"\n",
    "    Given a list of sentences/lists all_exist checks whether sublist list exists in lst\n",
    "\n",
    "    :sublist: list to search\n",
    "    :lst: list to be searched\n",
    "    :return: the list with the match\n",
    "    \"\"\"\n",
    "    if not isinstance(sublist, list):\n",
    "        raise ValueError(\"sublist must be a list\")\n",
    "    if not isinstance(lst, list):\n",
    "        raise ValueError(\"lst must be a list\")\n",
    "\n",
    "    sublist_len = len(sublist)\n",
    "    k=0\n",
    "    s=None\n",
    "\n",
    "    if (sublist_len > len(lst)):\n",
    "        return False\n",
    "    elif (sublist_len == 0):\n",
    "        return True\n",
    "\n",
    "    for x in lst:\n",
    "        if x == sublist[k]:\n",
    "            if (k == 0): s = x\n",
    "            elif (x != s): s = None\n",
    "            k += 1\n",
    "            if k == sublist_len:\n",
    "                return True\n",
    "        elif k > 0 and sublist[k-1] != s:\n",
    "            k = 0\n",
    "\n",
    "    return False\n",
    "\n",
    "# Function to capture if all elements exist in a list\n",
    "def all_exist(avalue, bvalue):\n",
    "    \"\"\"\n",
    "    Given a list of sentences/lists all_exist checks whether avalue list exists in bvalue\n",
    "\n",
    "    :avalue: list to search\n",
    "    :bvalue: list to be searched\n",
    "    :return: the list with the match\n",
    "    \"\"\"\n",
    "    return all(any(x in y for y in bvalue) for x in avalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The label included in the name of the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two categories of cases: the reported and the unreported ones. The reported cases include richer data while the unreported ones (the vast majority of cases) miss several data fields due to a request for annonimity from any of the parties involved in the legal dispute.\n",
    "\n",
    "The first two letters in the file name seem to follow some logic. Inspecting the documents reveals the following meanings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35305/35305 [00:00<00:00, 1588874.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Open jsonData file as data\n",
    "with open('./data/jsonDataFinal.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Loop over each decision and extract first two characters of the file's name\n",
    "for decision in tqdm(data):\n",
    "    # Only 'unteported' decisions include this 2-letter code\n",
    "    if decision.get('Status of case:') == 'Unreported':\n",
    "        string_code = decision.get('File')[:2]\n",
    "    else:\n",
    "        string_code = 'NA'\n",
    "    \n",
    "    # Add dictionary key 'Code label' with value string to the dictionary\n",
    "    decision.update({'Code label:': string_code})\n",
    "\n",
    "# Save data as a json file jsonDataFinal in data directory\n",
    "with open('./data/jsonDataFinal.json', 'w') as fout:\n",
    "    json.dump(data, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The court where the case was heard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An inspection of a sample of judicial decisions reveals that the name of the court is located in the first part of the document and it usually follows the expression \"Heard at\".\n",
    "\n",
    "The strategy to capture this field will consist of a search using regular expressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35305/35305 [00:01<00:00, 27089.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# Open jsonData file as data\n",
    "with open('./data/jsonDataFinal.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Loop over each text file and extract Court information\n",
    "for decision in tqdm(data):\n",
    "    # Obtain the text of the court decision\n",
    "    decision_string = decision.get('String')\n",
    "    # Deal with empty/corrupt files that didn't upload a sentence string\n",
    "    if decision_string:\n",
    "        # Regex expression: What comes after \"Heard at\" until hitting 3 balnks or new line\n",
    "        #regex = '(?<=Heard at).*[^\\S\\r\\n]{3,}'\n",
    "        regex = 'Heard at(.*)[\\S\\r\\n]| (?<=Heard at).*[^\\S\\r\\n]{3,}'\n",
    "        catch = re.search(regex, decision_string)\n",
    "\n",
    "        # If the catch is successful\n",
    "        if catch :\n",
    "            string = catch.group(0)\n",
    "            # Remove ':' if included in the catch\n",
    "            string = string.replace(':','')\n",
    "            # Remove leading and trailing spaces\n",
    "            string = string.strip()\n",
    "            # Avoids picking up parts of tables and '|'\n",
    "            string = string.split('   ')\n",
    "            string = string[0]\n",
    "            # Remove 'Heard at' if included in the catch\n",
    "            string = string.replace('Heard at ','')\n",
    "            # Remove 'manually' some strings often included in the catch\n",
    "            string = string.replace('|Decision & Reasons Promulgated','')\n",
    "            string = string.replace('|Decision and Reasons Promulgated','')\n",
    "            string = string.replace('| Decision & Reasons Promulgated','')\n",
    "            string = string.replace('Decision Promulgated','')\n",
    "            string = string.replace('|Decision & Reasons promulgated','')\n",
    "            string = string.replace('|Determination Promulgated','')\n",
    "            string = string.replace('Decision and Reasons Promulgated','')\n",
    "            string = string.replace('|Decision & Reasons  Promulgated','')\n",
    "            string = string.replace(' on 4 July 2003','')\n",
    "            string = string.replace('Determination Promulgated','')\n",
    "            string = string.replace('Decision & Reasons Promulgated','')\n",
    "            string = string.replace('|Decisions and Reasons Promulgated','')\n",
    "            string = string.replace('|Decision and Reasons','')\n",
    "            string = string.replace('UT(IAC)','')\n",
    "            string = string.replace('UT (IAC) ','')\n",
    "            string = string.replace('Date of Hearing  9 December 2005','')\n",
    "            string = string.replace(' | |SS (Risk-Manastry) Iran CG [2003] UKIAT 00035 |','')\n",
    "            # Strip of often found trailing characters\n",
    "            string = string.rstrip(',')\n",
    "            string = string.rstrip('|')\n",
    "            # Remove leading and trailing spaces (again)\n",
    "            string = string.strip()\n",
    "        else:\n",
    "            string = 'NA'\n",
    "        #print(string)\n",
    "        # Add dictionary key 'Heard at' with value string to the dictionary\n",
    "        decision.update({'Heard at:': string})\n",
    "    else:\n",
    "        continue\n",
    "# Save data as a json file jsonDataFinal in data directory\n",
    "with open('./data/jsonDataFinal.json', 'w') as fout:\n",
    "    json.dump(data, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. The judges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35305/35305 [00:01<00:00, 24965.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Open jsonData file as data\n",
    "with open('./data/jsonDataFinal.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Loop over each text file and extract Court information\n",
    "for decision in tqdm(data):\n",
    "    # Obtain the text of the court decision\n",
    "    decision_string = decision.get('String')\n",
    "    # Deal with empty/corrupt files that didn't upload a sentence string\n",
    "    if decision_string:\n",
    "        # Regex expression: What comes in between 'Before' and 'Between'\n",
    "        regex = '(?<=Before)([\\s\\S]*?)(?=Between)'\n",
    "        catch = re.search(regex, decision_string)\n",
    "        #If the catch is successful\n",
    "        if catch :\n",
    "            string = catch.group(0)\n",
    "\n",
    "            # Get rid of some table delimiters\n",
    "            string = string.replace('|','')\n",
    "            string = string.replace('?','')\n",
    "            string = string.replace(',','')\n",
    "\n",
    "            # Remove leading and trailing spaces\n",
    "            string = string.strip()\n",
    "            \n",
    "            # Split strings (spaces > 3 usually indicates two \"joint\" names)\n",
    "            # Alternative approach tried and discarded base on sentence tokenization \n",
    "            # from nltk.tokenize import sent_tokenize\n",
    "            listNames = string.split(\"   \")\n",
    "            # Make list of names with strings containijng names\n",
    "            # Capitalize the first letter of each word & delete \n",
    "            listNames = [name.strip().title() for name in listNames if name.strip()]\n",
    "\n",
    "            # Discard content in brackets as it's mostly titles and clutter\n",
    "            listNames = [re.sub('[\\(\\[].*?[\\)\\]]', '', x).strip() for x in listNames]\n",
    "\n",
    "            # Finally, delete titles, positions held and other clutter around the name\n",
    "            clutter = ['Judge', 'Tribunal', 'Court', 'Upper', 'Deputy', 'Senior', 'Of', 'The', 'Mr', 'Dr', 'Vice', 'President',\n",
    "            ':', 'Honourable', 'Hon.', '', '- - - - - - - - - - - - - - - - - - - -', 'Ut', 'Trinbunal', '-And-', 'Mrs', 'President,',\n",
    "            'Tribnunal', '-', 'Hon', 'And', 'Chairman', 'Vice-President', 'Immigration', 'Asylum Chamber', '-Vice', '(Senior',\n",
    "            '...............', 'Designated', 'His Honour', 'Respondent Representation: For Appellant', 'Secretary State For Home Department',\n",
    "            'Appellant', 'Lord', 'Sir', 'In Matter An Application For Judicial Review', 'I) Eu Regulation Number 604/2013 Human',\n",
    "            'Miss', 'Ms.', ':-']\n",
    "\n",
    "            # \n",
    "            listNames = [' '.join(filter(lambda x: x not in clutter,  name.split())) for name in listNames]\n",
    "            # Remove remaining 'issues' with empty strings ''\n",
    "            listNames = list(filter(None, listNames))\n",
    "            # Add a . following individual letters\n",
    "\n",
    "            #print(listNames)\n",
    "            \n",
    "        else:\n",
    "            listNames = ['NA']\n",
    "        \n",
    "        #print(decision.get('File'))\n",
    "        #print(listNames)\n",
    "        # Add dictionary key 'Judges:' with value list of strings to the dictionary\n",
    "        decision.update({'Judges:': listNames})\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Save data as a json file jsonDataFinal in data directory\n",
    "with open('./data/jsonDataFinal.json', 'w') as fout:\n",
    "    json.dump(data, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35305/35305 [00:00<00:00, 2771630.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# 'Manually' fix some mistakes with some judges\n",
    "\n",
    "# Open jsonData file as data\n",
    "with open('./data/jsonDataFinal.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Loop over each text file and extract Court information\n",
    "for decision in tqdm(data):\n",
    "\n",
    "    if decision.get('File') == '00046_ukut_iac_2020_ps_iran_cg':\n",
    "        listNames = ['J Barnes', 'A R Mackey', 'S L Batiste']\n",
    "        decision.update({'Judges:': listNames})\n",
    "    else:\n",
    "        continue\n",
    "    if decision.get('File') == '00393_ukut_iac_2019__jw_ors_ijr':\n",
    "        listNames = ['Rimington Jackson']\n",
    "        decision.update({'Judges:': listNames})\n",
    "    else:\n",
    "        continue\n",
    "    if decision.get('File') == '2004_ukiat_00248_gh_iraq_cg':\n",
    "        listNames = ['Rintoul', 'Bruce']\n",
    "        decision.update({'Judges:': listNames})\n",
    "    else:\n",
    "        continue\n",
    "    if decision.get('File') == '00270_ukut_iac_2015_mmw_ijr':\n",
    "        listNames = ['Justice Mccloskey']\n",
    "        decision.update({'Judges:': listNames})\n",
    "    else:\n",
    "        continue\n",
    "    if decision.get('File') == '00271_ukut_iac_2015_bh_ijr':\n",
    "        listNames = ['Justice Mccloskey', \"O'Connor\"]\n",
    "        decision.update({'Judges:': listNames})\n",
    "    else:\n",
    "        continue\n",
    "    if decision.get('File') == 'AA082212015':\n",
    "        listNames = ['Alis', 'I K']\n",
    "        decision.update({'Judges:': listNames})\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Save data as a json file jsonDataFinal in data directory\n",
    "with open('./data/jsonDataFinal.json', 'w') as fout:\n",
    "    json.dump(data, fout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. The legal representation for the appellant and the respondent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The legal team consists of the representation for the appellant and the respondent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35305/35305 [5:05:36<00:00,  1.93it/s]\n"
     ]
    }
   ],
   "source": [
    "representation = []\n",
    "files_legal = []\n",
    "\n",
    "# nlp sentence tokenizer with Stanford\n",
    "nlp = stanza.Pipeline(lang = 'en', processors = 'tokenize', tokenize_no_ssplit = True)\n",
    "\n",
    "# Open jsonData file as data\n",
    "with open('./data/jsonDataFinal.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Loop over each text file and extract Court information\n",
    "for decision in tqdm(data):\n",
    "    # Obtain the text of the court decision\n",
    "    decision_string = decision.get('String')\n",
    "    file_name = decision.get('File')\n",
    "    files_legal.append(file_name)\n",
    "    #print(file_name)\n",
    "    # Use only first third of text\n",
    "    string = decision_string[:len(decision_string)//3]\n",
    "    # All text in lower\n",
    "    string = string.lower()\n",
    "    # Apply stanford nlp to string\n",
    "    doc = nlp(string)\n",
    "\n",
    "    # List to store the ruling sentences\n",
    "    catch = []\n",
    "\n",
    "    # Make sentences\n",
    "    for i, sentence in enumerate(doc.sentences):\n",
    "        sente = [token.text for token in sentence.tokens]\n",
    "        # Keep only the alpha tokens\n",
    "        sente = [e for e in sente if e.isalpha()]\n",
    "        catch.append(sente)\n",
    "        #print(catch)\n",
    "    \n",
    "    # Look for partial hits (representation_leads_part) in string \n",
    "    representation_leads_part = [['representation', 'for', 'the', 'appellant'], ['representation', 'for', 'the', 'claimant'],\n",
    "    ['for', 'the', 'appellant'], ['representation', 'for', 'the', 'appellants'], ['for', 'the', 'first', 'appellant']]\n",
    "    \n",
    "    # Representation has not been found yet (flag = 0)\n",
    "    flag = 0\n",
    "\n",
    "    for element in catch:\n",
    "        for part in representation_leads_part:\n",
    "            # find index of part hit\n",
    "            idx_part = representation_leads_part.index(part)\n",
    "            # Condition flag == 0 to avoid greedy behaviour (several matches) Only matters 1st hit\n",
    "            if sublist(representation_leads_part[idx_part], element) and flag == 0:\n",
    "                index = catch.index(element)\n",
    "                # representaion lead found in catch\n",
    "                flag = 1\n",
    "                # Keep only sentence with the hit (it includes all needed info)\n",
    "                new_catch = catch[index]\n",
    "                representation.append(new_catch)\n",
    "                decision.update({'Representation:': new_catch})\n",
    "                #print(new_catch)\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "    # If information on the representation has not been found (flag = 0)\n",
    "    if flag == 0:\n",
    "        #print(f'Did not find a nationality {file_name} in catch: {catch}')\n",
    "        representation.append(np.nan)\n",
    "        decision.update({'Representation:': np.nan})\n",
    "        #print('Did not find a representation')\n",
    "        #print(catch)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Save data as a json file jsonDataFinal in data directory\n",
    "with open('./data/jsonDataFinal.json', 'w') as fout:\n",
    "    json.dump(data, fout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information on the legal representatives has been captured for a large number of decisions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File                 0\n",
       "Representation    3372\n",
       "dtype: int64"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_representation = {'File':files_legal,'Representation':representation}\n",
    "\n",
    "df_representation = pd.DataFrame(dict_representation, columns=['File','Representation'])\n",
    "df_representation.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The field Representation: includes a string with the information on the legal representatives. The following breaks it down into two pieces:\n",
    "- The legal representation of the appellant (legalAppellant).\n",
    "- The legal representation of the defendant (legalDefendant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35305/35305 [00:00<00:00, 101300.39it/s]\n"
     ]
    }
   ],
   "source": [
    "files_appellant = []\n",
    "appellants = []\n",
    "respondents = []\n",
    "\n",
    "# Open jsonData file as data\n",
    "with open('./data/jsonDataFinal.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Loop over each text file and extract Court information\n",
    "for decision in tqdm(data):\n",
    "    # Obtain the text of the court decision\n",
    "    representation_string = decision.get('Representation:')\n",
    "    file_name = decision.get('File')\n",
    "\n",
    "    #file_name = decision.get('File')\n",
    "    if isinstance(representation_string, float):\n",
    "        continue\n",
    "    else:\n",
    "        # If a label has not been found (flag = 0)\n",
    "        flag = 0\n",
    "        # The decisions are stored as a listt of tokens\n",
    "        string = ' '.join(x for x in representation_string)\n",
    "        #print(string)\n",
    "        files_appellant.append(string)\n",
    "        \n",
    "        # Catch what's between 'for the appellant/s and for the correspondent' \n",
    "        regex_appellant = '(?<=for the appellant)([\\s\\S]*?)(?=for the respondent)'\n",
    "        catch_appellant = re.search(regex_appellant, string)\n",
    "        if catch_appellant :\n",
    "            string_appellant = catch_appellant.group(0)\n",
    "            # Remove leading and trailing spaces\n",
    "            string_appellant = string_appellant.strip()\n",
    "            \n",
    "            if string_appellant.startswith('s'):\n",
    "                string_appellant = string_appellant[1:].strip()\n",
    "        \n",
    "        # Catch what's between 'for the claimant/s and for the correspondent' \n",
    "        regex_claimant = '(?<=for the claimant)([\\s\\S]*?)(?=for the respondent)'\n",
    "        catch_claimant = re.search(regex_claimant, string)\n",
    "        if catch_claimant :\n",
    "            string_appellant = catch_claimant.group(0)\n",
    "            # Remove leading and trailing spaces\n",
    "            string_appellant = string_appellant.strip()\n",
    "            \n",
    "            if string_appellant.startswith('s'):\n",
    "                string_appellant = string_appellant[1:].strip()\n",
    "                print(string_appellant)\n",
    "                \n",
    "        #print(string_appellant)\n",
    "        appellants.append(string_appellant)\n",
    "        decision.update({'Appellant:': string_appellant})\n",
    "\n",
    "        # Catch what's after 'for the correspondent' \n",
    "        regex_respondent = '(?<=for the respondent)([\\s\\S]*)'\n",
    "        catch_respondent = re.search(regex_respondent, string)\n",
    "        if catch_respondent :\n",
    "            string_respondent = catch_respondent.group(0)\n",
    "            # Remove leading and trailing spaces\n",
    "            string_respondent = string_respondent.strip()\n",
    "                \n",
    "            if string_respondent.startswith('s'):\n",
    "                string_respondent = string_respondent[1:].strip()\n",
    "\n",
    "        #print(string_respondent)\n",
    "        respondents.append(string_respondent)\n",
    "        decision.update({'Respondent:': string_respondent})\n",
    "\n",
    "# Save data as a json file jsonDataFinal in data directory\n",
    "with open('./data/jsonDataFinal.json', 'w') as fout:\n",
    "    json.dump(data, fout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31933\n",
      "31933\n",
      "31933\n",
      "                                          Representation  \\\n",
      "0      representation for the appellant mr j gajjar c...   \n",
      "1      representation for the appellant ms sardar cou...   \n",
      "2      representation for the appellant mr hussain fo...   \n",
      "3      representation for the appellant mr t melvin s...   \n",
      "4      for the appellant ms e rutherford instructed b...   \n",
      "...                                                  ...   \n",
      "31928  on august he lodged an appeal against the refu...   \n",
      "31929  the adjudicator rejected all the appellant cla...   \n",
      "31930  the appellant describes himself variously as a...   \n",
      "31931  ms s panagiotopoulou of counsel instructed by ...   \n",
      "31932  we are however concerned with the relevance of...   \n",
      "\n",
      "                                               Appellant  \\\n",
      "0      mr j gajjar counsel instructed by m a consulta...   \n",
      "1        ms sardar counsel instructed by duncan lewis co   \n",
      "2                                             mr hussain   \n",
      "3      mr t melvin senior home office presenting officer   \n",
      "4      ms e rutherford instructed by bond adam llp so...   \n",
      "...                                                  ...   \n",
      "31928            mrs g oliso of the refugee legal centre   \n",
      "31929            mrs g oliso of the refugee legal centre   \n",
      "31930            mrs g oliso of the refugee legal centre   \n",
      "31931            mrs g oliso of the refugee legal centre   \n",
      "31932            mrs g oliso of the refugee legal centre   \n",
      "\n",
      "                                              Respondent  \n",
      "0              mr e tufan home office presenting officer  \n",
      "1      mr whitwell senior home office presenting officer  \n",
      "2                   mr diwnycz senior presenting officer  \n",
      "3      mr a maqsood counsel instructed by iconsult im...  \n",
      "4            mr t lindsay home office presenting officer  \n",
      "...                                                  ...  \n",
      "31928  mr m blundell home office presenting officer t...  \n",
      "31929  mr m blundell home office presenting officer t...  \n",
      "31930  mr m blundell home office presenting officer t...  \n",
      "31931  mr m blundell home office presenting officer t...  \n",
      "31932  mr m blundell home office presenting officer t...  \n",
      "\n",
      "[31933 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Representation</th>\n",
       "      <th>Appellant</th>\n",
       "      <th>Respondent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31933</td>\n",
       "      <td>31933</td>\n",
       "      <td>31933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>30550</td>\n",
       "      <td>17626</td>\n",
       "      <td>8486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>for the appellant in person</td>\n",
       "      <td>no appearance</td>\n",
       "      <td>mr p duffy senior home office presenting officer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>35</td>\n",
       "      <td>423</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Representation      Appellant  \\\n",
       "count                         31933          31933   \n",
       "unique                        30550          17626   \n",
       "top     for the appellant in person  no appearance   \n",
       "freq                             35            423   \n",
       "\n",
       "                                              Respondent  \n",
       "count                                              31933  \n",
       "unique                                              8486  \n",
       "top     mr p duffy senior home office presenting officer  \n",
       "freq                                                 550  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(files_appellant))\n",
    "print(len(appellants))\n",
    "print(len(respondents))\n",
    "\n",
    "dict_sense_representation = {'Representation':files_appellant,'Appellant':appellants, 'Respondent':respondents}\n",
    "\n",
    "df_sense_representation = pd.DataFrame(dict_sense_representation, columns=['Representation','Appellant', 'Respondent'])\n",
    "df_sense_representation.isna().sum()\n",
    "df_sense_representation.sum()\n",
    "\n",
    "print(df_sense_representation)\n",
    "\n",
    "df_sense_representation.describe()\n",
    "#df_sense_representation.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35305/35305 [00:00<00:00, 116561.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get the legal firm or entitity involved as an appellant or respondent\n",
    "\n",
    "appellants = []\n",
    "appellants_firm = []\n",
    "respondents = []\n",
    "respondents_firm = []\n",
    "\n",
    "home_office_tags = ['senior presenting officer', 'senior home office presenting officer', 'home office presenting officer', 'home office']\n",
    "\n",
    "# Open jsonData file as data\n",
    "with open('./data/jsonDataFinal.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Loop over each text file and extract Court information\n",
    "for decision in tqdm(data):\n",
    "    # Obtain the text of the court decision\n",
    "    appellant_string = decision.get('Appellant:')\n",
    "    respondent_string = decision.get('Respondent:')\n",
    "    representation_string = decision.get('Representation:')\n",
    "\n",
    "    if isinstance(representation_string, float):\n",
    "        continue\n",
    "    else:\n",
    "        # First, proceed with appellant's related firm info\n",
    "        flag_appellant = 0\n",
    "        \n",
    "        # Catch what's after ' of ' \n",
    "        regex_appellant = '(?<= of )([\\s\\S]*)'\n",
    "        catch_appellant = re.search(regex_appellant, appellant_string)\n",
    "        if catch_appellant :\n",
    "            string_appellant_firm = catch_appellant.group(0)\n",
    "            # Remove leading and trailing spaces\n",
    "            string_appellant_firm = string_appellant_firm.strip()\n",
    "            flag_appellant = 1\n",
    "        \n",
    "        # Catch what's after 'legal representative' \n",
    "        regex_appellant = '(?<=legal representative)([\\s\\S]*)'\n",
    "        catch_appellant = re.search(regex_appellant, appellant_string)\n",
    "        if catch_appellant :\n",
    "            string_appellant_firm = catch_appellant.group(0)\n",
    "            # Remove leading and trailing spaces\n",
    "            string_appellant_firm = string_appellant_firm.strip()\n",
    "            flag_appellant = 1\n",
    "\n",
    "        # Catch what's after 'instructed by' \n",
    "        regex_appellant = '(?<=instructed by)([\\s\\S]*)'\n",
    "        catch_appellant = re.search(regex_appellant, appellant_string)\n",
    "        if catch_appellant :\n",
    "            string_appellant_firm = catch_appellant.group(0)\n",
    "            # Remove leading and trailing spaces\n",
    "            string_appellant_firm = string_appellant_firm.strip()\n",
    "            flag_appellant = 1\n",
    "\n",
    "        #print(appellant_string)\n",
    "        if flag_appellant == 1:\n",
    "            string_appellant_firm = string_appellant_firm\n",
    "            #print(string_appellant_firm)\n",
    "        else:\n",
    "            for tag in home_office_tags:\n",
    "                if appellant_string != None and tag in appellant_string:\n",
    "                    string_appellant_firm = 'Home Office'\n",
    "                    flag_appellant = 1\n",
    "                    break\n",
    "                else:\n",
    "                    string_appellant_firm = np.nan\n",
    "            #print(string_appellant_firm)\n",
    "        appellants_firm.append(string_appellant_firm)\n",
    "        appellants.append(appellant_string)\n",
    "        decision.update({'Appellant entity:': string_appellant_firm})\n",
    "\n",
    "\n",
    "        # Second, proceed with respondent's related firm info\n",
    "        flag_respondent = 0\n",
    "\n",
    "        # Catch what's after ' of ' \n",
    "        regex_respondent = '(?<= of )([\\s\\S]*)'\n",
    "        catch_respondent = re.search(regex_respondent, respondent_string)\n",
    "        if catch_respondent :\n",
    "            string_respondent_firm = catch_respondent.group(0)\n",
    "            # Remove leading and trailing spaces\n",
    "            string_respondent_firm = string_respondent_firm.strip()\n",
    "            flag_respondent = 1\n",
    "        \n",
    "        # Catch what's after 'legal representative' \n",
    "        regex_respondent = '(?<=legal representative)([\\s\\S]*)'\n",
    "        catch_respondent = re.search(regex_respondent, respondent_string)\n",
    "        if catch_respondent:\n",
    "            string_respondent_firm = catch_respondent.group(0)\n",
    "            # Remove leading and trailing spaces\n",
    "            string_respondent_firm = string_respondent_firm.strip()\n",
    "            flag_respondent = 1\n",
    "\n",
    "        # Catch what's after 'instructed by' \n",
    "        regex_respondent = '(?<=instructed by)([\\s\\S]*)'\n",
    "        catch_respondent = re.search(regex_respondent, respondent_string)\n",
    "        if catch_respondent :\n",
    "            string_respondent_firm = catch_respondent.group(0)\n",
    "            # Remove leading and trailing spaces\n",
    "            string_respondent_firm = string_respondent_firm.strip()\n",
    "            flag_respondent = 1\n",
    "\n",
    "        #print(respondent_string)\n",
    "        if flag_respondent == 1:\n",
    "            string_respondent_firm = string_respondent_firm\n",
    "            #print(string_respondent_firm)\n",
    "        else:\n",
    "            for tag in home_office_tags:\n",
    "                if respondent_string != None and tag in respondent_string:\n",
    "                    string_respondent_firm = 'Home Office'\n",
    "                    flag_respondent = 1\n",
    "                    break\n",
    "                else:\n",
    "                    string_respondent_firm = np.nan\n",
    "            #print(string_respondent_firm)\n",
    "        respondents_firm.append(string_respondent_firm)\n",
    "        respondents.append(respondent_string)\n",
    "        decision.update({'Respondent entity:': string_respondent_firm})\n",
    "\n",
    "# Save data as a json file jsonDataFinal in data directory\n",
    "with open('./data/jsonDataFinal.json', 'w') as fout:\n",
    "    json.dump(data, fout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31933\n",
      "31933\n",
      "31933\n",
      "31933\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(appellants))\n",
    "print(len(appellants_firm))\n",
    "\n",
    "print(len(respondents))\n",
    "print(len(respondents_firm))\n",
    "\n",
    "#data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. The decision of the judge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision of the judge is the most challenging piece of information to extract from the documents. # First isolate the part of the document most likely to include the decission the second half of the document. Second, get rid of annexes and appendixes. third, # classifying judgments is not the same as classifying cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 20:28:12 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "========================\n",
      "\n",
      "2021-11-13 20:28:12 INFO: Use device: cpu\n",
      "2021-11-13 20:28:12 INFO: Loading: tokenize\n",
      "2021-11-13 20:28:12 INFO: Done loading processors!\n",
      "100%|██████████| 35305/35305 [2:00:38<00:00,  4.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# nlp sentence tokenizer with Stanford\n",
    "nlp = stanza.Pipeline(lang = 'en', processors = 'tokenize', tokenize_no_ssplit = True)\n",
    "\n",
    "# Store decisions in a list to make a df\n",
    "decisions = []\n",
    "files_judge = []\n",
    "\n",
    "# Open jsonData file as data\n",
    "with open('./data/jsonDataFinal.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Loop over each text file and extract Court information\n",
    "for decision in tqdm(data):\n",
    "    # Obtain the full text of the court decision\n",
    "    string = decision.get('String')\n",
    "    file_name = decision.get('File')\n",
    "    files_judge.append(file_name)\n",
    "\n",
    "    # Use only second half of text (skip references to annxes and appendixes)\n",
    "    string = string[len(string)//2:]\n",
    "\n",
    "    # Discard text following appendix and annexes\n",
    "    string = string.rsplit(\"appendix\", 1)\n",
    "    string = string[0]\n",
    "    string = string.rsplit(\"annex\", 1)\n",
    "    string = string[0]\n",
    "\n",
    "    # Narrow down the search from the end\n",
    "    # Split on last occurrence of \"Signed\"\n",
    "    string = string.rsplit(\"Signed\", 1)\n",
    "    string = string[0].lower()\n",
    "\n",
    "\n",
    "    # Keep a max of 2000 characters\n",
    "    string = string[ min(-2000, len(string)):]\n",
    "\n",
    "    # Get rid of text after the last occurrence of 'anonymity'\n",
    "    string = string.rsplit(\"anonymity\", 1)\n",
    "    string = string[0]\n",
    "\n",
    "    # Apply stanford nlp\n",
    "    doc = nlp(string)\n",
    "\n",
    "    # List to store the ruling sentences\n",
    "    catch = []\n",
    "    # Flag = 1 when decision found\n",
    "    flag = 0\n",
    "        \n",
    "    # Make sentences\n",
    "    for i, sentence in enumerate(doc.sentences):\n",
    "        sente = [token.text for token in sentence.tokens]\n",
    "        # Keep only the alpha tokens\n",
    "        sente = [e for e in sente if e.isalpha()]\n",
    "        #print(type(sente))\n",
    "        catch.append(sente)\n",
    "        \n",
    "    # Identify decision leads in sentences\n",
    "    decision_leads = [['notice', 'of', 'decision'], ['decision'], ['decisions'], ['conclusions'], ['conclusion']]\n",
    "        \n",
    "    # When decision lead found, trim catch and update flag value \n",
    "    for lead in decision_leads:\n",
    "        try:\n",
    "            # Find index of decision lead in ruling\n",
    "            index = catch.index(lead)\n",
    "            # Remove sentences before the decision lead sentence\n",
    "            del catch[0:index]\n",
    "            # Flatten the list of lists/sentences\n",
    "            flat_catch = [item for sublist in catch for item in sublist]\n",
    "            # Decision found\n",
    "            flag = 1\n",
    "            # Store decision in decisions list\n",
    "            decisions.append(flat_catch)\n",
    "            decision.update({'Decision:': flat_catch})\n",
    "            #print('Found decision 1')\n",
    "            #print(flat_catch)\n",
    "            break\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    # If a decision has not been found yet (flag = 0)\n",
    "    if flag == 0:\n",
    "    # Look for partial hits in text \n",
    "        decision_leads_part = [['for', 'the', 'above', 'reasons'], ['for', 'the', 'reasons', 'i', 'have', 'given'], ['general', 'conclusions'],\n",
    "        ['for', 'the', 'reasons', 'set', 'out', 'above'], ['for', 'all', 'of', 'these', 'reasons'], ['decision', 'and', 'directions'], ['conclusions'],\n",
    "        ['notice', 'of', 'decision'], ['decision','the', 'application', 'for', 'judicial', 'review', 'is'], ['there', 'is', 'no', 'material', 'error', 'of', 'law', 'in'],\n",
    "        ['decision', 'the', 'decision', 'of', 'tribunal', 'judge', 'dean', 'promulgated'], ['the', 'decision', 'of', 'the', 'ftt', 'is', 'set', 'aside'],\n",
    "        ['i', 'grant', 'permission', 'to', 'appeal', 'i', 'set', 'aside', 'the', 'decision', 'of', 'the', 'tribunal'], ['i', 'set', 'aside', 'that', 'decision'],\n",
    "        ['the', 'appellant', 'appeal', 'as', 'originally', 'brought', 'to', 'the', 'ftt', 'is', 'dismissed'], ['i', 'do', 'not', 'set', 'aside', 'the', 'decision']]\n",
    "            \n",
    "        for element in catch:\n",
    "            for part in decision_leads_part:\n",
    "                idx_part = decision_leads_part.index(part)\n",
    "                if all_exist(decision_leads_part[idx_part], element):\n",
    "                    index = catch.index(element)\n",
    "                    # Decision found in catch\n",
    "                    flag = 1\n",
    "                    # Remove sentences before the decision lead sentence\n",
    "                    del catch[0:index]\n",
    "                    # Flatten the list of lists/sentences\n",
    "                    flat_catch = [item for sublist in catch for item in sublist]\n",
    "                    #print('Found decision 2')\n",
    "                    #print(flat_catch)\n",
    "                    break\n",
    "                \n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "        # If a decision has still not been found (flag = 0)\n",
    "        if flag == 0:\n",
    "            decisions.append(np.nan)\n",
    "            decision.update({'Decision:': np.nan})\n",
    "            #print('Did not find a decision')\n",
    "            #print(catch)\n",
    "        else:\n",
    "            # Store decision in decisions list\n",
    "            decisions.append(flat_catch)\n",
    "            decision.update({'Decision:': flat_catch})\n",
    "            continue\n",
    "\n",
    "\n",
    "# Save data as a json file jsonDataFinal in data directory\n",
    "with open('./data/jsonDataFinal.json', 'w') as fout:\n",
    "    json.dump(data, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35305\n",
      "35305\n",
      "['decision', 'the', 'determination', 'of', 'the', 'tribunal', 'having', 'been', 'found', 'to', 'contain', 'a', 'material', 'error', 'of', 'law', 'i', 'substitute', 'the', 'following', 'decision', 'the', 'appellant', 'appeal', 'is', 'allowed', 'under', 'the', 'immigration', 'rules']\n",
      "HU166042017\n",
      "['the', 'judge', 'also', 'went', 'on', 'to', 'consider', 'whether', 'or', 'not', 'any', 'exceptional', 'circumstances', 'existed', 'in', 'this', 'particular', 'case', 'the', 'findings', 'and', 'conclusions', 'are', 'comprehensive', 'and', 'when', 'the', 'decision', 'is', 'viewed', 'holistically', 'the', 'judge', 'consideration', 'is', 'entirely', 'sound', 'in', 'light', 'of', 'the', 'above', 'the', 'appellant', 'appeal', 'to', 'the', 'upper', 'tribunal', 'is', 'dismissed', 'and', 'the', 'decision', 'of', 'the', 'tribunal', 'stands', 'anonymity', 'i', 'make', 'no']\n",
      "PA098412018\n",
      "['notice', 'of', 'decision', 'for', 'the', 'above', 'reasons', 'the', 'decision', 'i', 'on', 'the', 'appellant', 'appeal', 'is', 'to', 'allow', 'it', 'on', 'asylum', 'grounds', 'to', 'conclude', 'as', 'found', 'in', 'my', 'previous', 'error', 'of', 'law', 'decision', 'the', 'ftt', 'judge', 'materially', 'erred', 'in', 'law', 'the', 'decision', 'i', 'is', 'to', 'allow', 'the', 'appellant', 'appeal', 'direction', 'regarding', 'anonymity', 'rule', 'of', 'the', 'tribunal', 'procedure', 'upper', 'tribunal', 'rules', 'unless', 'and', 'until', 'a', 'tribunal', 'or', 'court', 'directs', 'otherwise', 'the', 'appellant', 'is', 'granted']\n",
      "File           0\n",
      "Decision    5220\n",
      "dtype: int64\n",
      "35305\n",
      "35305\n"
     ]
    }
   ],
   "source": [
    "dict_decisions = {'File':files_judge,'Decision':decisions}\n",
    "\n",
    "df = pd.DataFrame(dict_decisions, columns=['File','Decision'])\n",
    "df.isna().sum()\n",
    "#print(data[49])\n",
    "print(len(files_judge))\n",
    "print(len(decisions))\n",
    "#print(decisions[32488])\n",
    "#print(files[5000])\n",
    "#rint(decisions[5000])\n",
    "#print(files[6000])\n",
    "print(decisions[6002])\n",
    "#print(df[df['Decision'].isnull()])\n",
    "print(df.isnull().sum(axis = 0))\n",
    "\n",
    "#print(json.dumps(data[32554], indent = 4, sort_keys = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Sense of the decision.\n",
    "\n",
    "The decision has been isolated. However, no information on whether the sentence accepts/rejects or is neutral. Sense of decision depends on the appellent. If appellent is home office, then... The decision of the First-tier Tribunal did not involve the  making  of an error of law and I uphold it\n",
    "is accepted, otherwise is rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35305/35305 [00:01<00:00, 28238.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# Store decisions in a list to make a df\n",
    "decision_text = []\n",
    "decision_label = []\n",
    "\n",
    "# Open jsonData file as data\n",
    "with open('./data/jsonDataFinal.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Loop over each text file and extract Court information\n",
    "for decision in tqdm(data):\n",
    "    # Obtain the full text of the court decision\n",
    "    string = decision.get('Decision:')\n",
    "    #file_name = decision.get('File')\n",
    "    if isinstance(string, float):\n",
    "        continue\n",
    "    else:\n",
    "        # If a label has not been found (flag = 0)\n",
    "        flag = 0\n",
    "        # The decisions are stored as a listt of tokens\n",
    "        string = ' '.join(x for x in string)\n",
    "        # print(string)\n",
    "        decision_text.append(string)\n",
    "        # Look for partial hits in text \n",
    "        decision_labels_reject = ['appeal dismissed', 'appeal is dismissed','this application is refused', 'the appeal is dismissed', 'the decision of the first-tier Tribunal stands',\n",
    "            'the decision of the tribunal did not involve the making of a material error of law', 'the original decision shall stand',\n",
    "            'did not involve the making of an error on a point of law', 'appeal remains dismissed', 'decision stands', 'not satisfied that the judge erred',\n",
    "            'not involve an error on', 'do not set aside the decision', 'this application is refused', 'i therefore uphold the decision of',\n",
    "            'does not contain a material error of law and shall stand', 'it shall stand', 'did not contain any error of law', 'did not involve the making of a material error of law',\n",
    "            'dismissing the claimant appeal', 'does not contain a material error of law','no material error of law has been established',\n",
    "            'the decision to dismiss the appellant appeal shall stand', 'the appeal is statutorily abandoned', 'tribunal decision is not vitiated by legal error',\n",
    "            'there is no material error of law in the tribunal judge decision', 'the appeal by the secretary of state is dismissed',\n",
    "            'decision of the tribunal does not disclose an error on a point of law', 'errors are not material such that the decision should be set aside',\n",
    "            'the appeal of the appellant is dismissed', 'reveals no error of law and stands', 'the appeal to the upper tribunal is dismissed',\n",
    "            'the respondent appeal be dismissed', 'the judge did not materially err in law', 'did not involve a making of or a material error of law',\n",
    "            'appeal to the upper tribunal is dismissed', 'i am dismissing', 'did not contain a material error of law', 'the decision of the ftt judge must stand',\n",
    "            'there are no errors of law', 'there is no material error of law', 'this appeal is dismissed', 'i dismiss the appeal', 'tribunal did not involve the making of an error of law',\n",
    "            'contains no material error of law', 'the decision of the tribunal stands', 'the decision of the tribunal did not involve the making of an error of law',\n",
    "            'this appeal is therefore dismissed', 'i refuse permission to appeal', 'the applicant appeal to the upper tribunal is therefore dismissed',\n",
    "            'decision of the ftt did not involve the making of an error of law', 'i do not set it aside', 'the decision of the tribunal did not involve the making of any error on a point of law',\n",
    "            'the appellant appeal to the upper tribunal is therefore dismissed', 'permission to appeal to the court of appeal is refused', 'the decision of the tribunal is upheld', 'the appeals are dismissed',\n",
    "            'did not make a material error of law', 'the decision of the tribunal shall stand', 'the appeal of the secretary of state is dismissed',\n",
    "            'the appeal of the secretary of state is dismissed', 'do not disclose any material error of law', 'the tribunal did not err in law',\n",
    "            'judge did not make an error of law', 'i uphold the decision to dismiss', 'no material error of law was made', 'did not make a material error on a point of law',\n",
    "            'there was no error of law made by the judge', 'we dismiss the secretary of state appeal', 'the appeals to the upper tribunal are dismissed',\n",
    "            'decision of the tribunal does not contain an error on a point', 'is disused', 'decision of the tribunal does not contain an error on a point of law',\n",
    "            'the appellants appeals are each dismissed', 'the decision by dismissing the appeal', 'i uphold the tribunal determination and dismiss the appeal'\n",
    "            'this appeal is dismissed', 'appeals dismissed for all the appellants', 'decision of the tribunal does not disclose an error in law', 'tribunal does not show a material error on a point of law',\n",
    "            'i uphold the tribunal determination and dismiss the appeal', 'these appeals are dismissed', 'determination does not disclose any material error of law',\n",
    "            'tribunal did not involve the making of a material error on a point of law', 'the decision of the tribunal containing no material error of law shall stand',\n",
    "            'decision of the tribunal does not disclose a material error on a point of law', 'there was no material error of law made by the judge',\n",
    "            'is free of legal error accordingly it must stand', 'decision of the tribunal does not contain errors of law that decision shall stand',\n",
    "            'the ftt judge did not err in law', 'i find no error of law', 'there is no error in law', 'no material error has been established',\n",
    "            'no material error of law has been demonstrated', 'there being no material error of law in the decision', 'the appeals of the appellants are dismissed',\n",
    "            'no material error of law is established in the decision', 'i dismissed the appellant appeal', 'i dismiss the appellant appeal', 'the decision of the tribunal contained a material error of law',\n",
    "            'i dismiss the appellant appeal', 'there is no error of law in the judge findings', 'i find no material error of law', 'the appeal of the claimant is dismissed',\n",
    "            'the decision of the original judge will stand', 'the appeal is to the upper tribunal is dismissed', 'did not involve the making of an error of law',\n",
    "            'the appeal is therefore dismissed', 'is dismissed', 'is refused', 'the appellants appeals are dismissed', 'i remake the decision on the appeal dismissing it',\n",
    "            'determination of the tribunal contains no error of law and it is upheld', 'the judge did not err in law', 'the appeal is as dismissed',\n",
    "            'the decision of the tribunal contains no error of law and shall stand', 'the claim is therefore dismissed', 'i find that there is no valid appeal before the tribunal',\n",
    "            'we have given we dismiss this appeal', 'this appeal must be dismissed', 'we conclude that no material error of law has been shown', 'there is no error of law',\n",
    "            'decision of the tribunal contains no error of law']\n",
    "\n",
    "        decision_labels_accept = ['i set it aside', 'did involve the making of an', 'decision of the tribunal is set aside', 'is set aside',\n",
    "            'i allow the claimant', 'appeal remains allowed', 'the appeal is allowed', 'appeal is granted', 'the appeal is allowed', 'the appellant is granted',\n",
    "            'i set aside the judge decision', 'i therefore set aside the decision', 'i set aside the decision', 'appeal allowed', 'appeal is allowed',\n",
    "            'set aside the decision', 'the decision of the first-tier tribunal has already been set aside', 'i allow the claimant', 'appeals allowed',\n",
    "            'i allow the appeal', 'is allowed', 'the first-tier tribunal erred in law', 'these appeals are allowed', 'the judge materially erred in law',\n",
    "            'does not contain an error of law', 'the appeals are allowed', 'the tribunal erred in law', 'the decision of the tribunal contained an error of law',\n",
    "            'involved the making of a material error of law', 'decision of the tribunal is tainted by material errors of law', 'i set the decision aside',\n",
    "            'tribunal involved an error on a point of law', 'did involve a material error of law', 'the appellants are granted', 'there is no material error of law in the determination',\n",
    "            'the judge erred in allowing this appeal', 'i remake the decision allowing the appellant appeal', 'did err in the making of', 'there are material errors of law',\n",
    "            'is therefore set aside', 'the appellant is granted', 'there is a material error of law', 'i allow the appellant eea appeal', 'should be set aside', 'by allowing the appeal',\n",
    "            'the tribunal decision involved the making of an error on a point of law', 'involved the making of an error on a point of law', 'by allowing the appellant appeal',\n",
    "            'involved the making of an error of law', 'the decision of the tribunal does not contain errors of law and it is upheld', 'decision of the tribunal has been set aside',\n",
    "            'the claimant appeal to the ftt is remade and allowed', 'tribunal was vitiated by legal error', 'discloses an error of law', 'we set aside that decision',\n",
    "            'the appeal is remitted to the tribunal for a hearing afresh', 'contains a material error of law', 'the tribunal made errors of law', 'the determination of the tribunal does not disclose a material error of law',\n",
    "            'the determination of the tribunal contained an error of law', 'the judge made an error on a point of law', 'the decision of the tribunal is hereby set aside for material error',\n",
    "            'the tribunal judge made errors of law', 'the appeal against the judge decision is therefore allowed', 'i allow the claim for asylum and on human rights grounds',\n",
    "            'the tribunal decision is vitiated by a material error of law', 'i find material error in law', 'the appellants appeals are allowed', 'the human rights appeals are allowed',\n",
    "            'i therefore allow the appeal', 'does not disclose an error of law and stands', 'determination does contain a material error of law', 'we allow the appeal',\n",
    "            'we have decided to allow this appeal', 'this appeal is accordingly allowed', 'both appeals are allowed', 'the appeals of the four appellants are allowed']\n",
    "\n",
    "        # Check first evidence of reject, if reject be done with it\n",
    "\n",
    "        for label in decision_labels_reject:\n",
    "            if string != None and label in string:\n",
    "                #print(\"Rejected!\")\n",
    "                flag = -1\n",
    "                decision_label.append('Rejected')\n",
    "                decision.update({'Decision label:': 'Rejected'})\n",
    "                break\n",
    "            else:\n",
    "                'Not found!'\n",
    "        if flag == -1:\n",
    "            continue\n",
    "        else:\n",
    "            # Check evidence for Accept\n",
    "            for label in decision_labels_accept:\n",
    "                if string != None and label in string:\n",
    "                    #print(\"Accepted!\")\n",
    "                    flag = 1\n",
    "                    decision_label.append('Accepted')\n",
    "                    decision.update({'Decision label:': 'Accepted'})\n",
    "                    break\n",
    "                else:\n",
    "                    'Not found!'\n",
    "        if flag == 0:\n",
    "            decision_label.append('Neutral')\n",
    "            decision.update({'Decision label:': 'Neutral'})\n",
    "\n",
    "    #print(flag)\n",
    "# The decision/ruling by the judge ('Decision:').\n",
    "\n",
    "# Save data as a json file jsonDataFinal in data directory\n",
    "with open('./data/jsonDataFinal.json', 'w') as fout:\n",
    "    json.dump(data, fout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30085\n",
      "30085\n",
      "                                           Decision text Decision label\n",
      "0      notice of decision directions the decision of ...       Accepted\n",
      "1      in light of my conclusions on that point littl...       Rejected\n",
      "2      notice of decision the decision of the tribuna...       Rejected\n",
      "3      notice of decision the decision of the tribuna...       Accepted\n",
      "4      decision the decision of tribunal judge malcol...       Accepted\n",
      "...                                                  ...            ...\n",
      "30080  for the reasons we have given in paragraph we ...       Accepted\n",
      "30081  conclusions a northern cyprus is not capable o...       Accepted\n",
      "30082  for the reasons we have given we dismiss this ...       Rejected\n",
      "30083  our conclusions on the general issues relating...       Rejected\n",
      "30084  conclusions for each of the main reason a and ...       Accepted\n",
      "\n",
      "[30085 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision text</th>\n",
       "      <th>Decision label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30085</td>\n",
       "      <td>30085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>24093</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>notice of decision the appeal is dismissed no</td>\n",
       "      <td>Accepted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>231</td>\n",
       "      <td>13711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Decision text Decision label\n",
       "count                                           30085          30085\n",
       "unique                                          24093              3\n",
       "top     notice of decision the appeal is dismissed no       Accepted\n",
       "freq                                              231          13711"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(decision_text))\n",
    "print(len(decision_label))\n",
    "\n",
    "dict_sense_decisions = {'Decision text':decision_text,'Decision label':decision_label}\n",
    "\n",
    "df_decision_sense = pd.DataFrame(dict_sense_decisions, columns=['Decision text','Decision label'])\n",
    "df_decision_sense.isna().sum()\n",
    "df_decision_sense.sum()\n",
    "\n",
    "print(df_decision_sense)\n",
    "\n",
    "df_decision_sense.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decision label\n",
       "Accepted          13711\n",
       "Rejected          12778\n",
       "Neutral            3596\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_decision_sense[['Decision label']].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_df = df_decision_sense[df_decision_sense['Decision label'] == 'Neutral']\n",
    "rslt_df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in decision_labels_accept:\n",
    "    idx_part = decision_labels_accept.index(label)\n",
    "    if all_exist(decision_labels_accept[idx_part], example):\n",
    "        flag = 1\n",
    "        break\n",
    "        #print('Accept')\n",
    "    else:\n",
    "        flag = 0\n",
    "        #print('Reject')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Nationality of the appellant. \n",
    "The field country is empty to a large extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of countries and nationalities to be checked against the text\n",
    "countries = ['Afghanistan', 'Aland Islands', 'Albania', 'Algeria', 'American Samoa', 'Andorra', 'Angola', 'Anguilla', 'Antarctica', 'Antigua', \n",
    "'Antigua and Barbuda', 'Argentina', 'Armenia', 'Aruba', 'Australia', 'Austria', 'Azerbaijan', 'Bahamas', 'Bahrain', 'Bangladesh', 'Barbados', 'Belarus',\n",
    "'Belgium', 'Belize', 'Benin', 'Bermuda', 'Bhutan', 'Bolivia', 'Bolivia, Plurinational State of', 'Bonaire', 'Bonaire, Sint Eustatius and Saba', \n",
    "'Bosnia and Herzegovina', 'Botswana', 'Bouvet Island', 'Brazil', 'British Indian Ocean Territory', 'Brunei Darussalam', 'Bulgaria', 'Burkina Faso', \n",
    "'Burundi', 'Cambodia', 'Cameroon', 'Canada', 'Cape Verde', 'Cayman Islands', 'Central African Republic', 'Chad', 'Chile', 'China', 'Christmas Island', \n",
    "'Cocos (Keeling) Islands', 'Colombia', 'Comoros', 'Congo', 'Congo, The Democratic Republic of the', 'Congo', 'Cook Islands', 'Costa Rica', \"Côte d'Ivoire\", \n",
    "'Croatia', 'Cuba', 'Curaçao', 'Cyprus', 'Czech Republic', 'Denmark', 'Djibouti', 'Dominica', 'Dominican Republic', 'Ecuador', 'Egypt', 'El Salvador', \n",
    "'Equatorial Guinea', 'Eritrea', 'Estonia', 'Ethiopia', 'Falkland Islands (Malvinas)', 'Faroe Islands', 'Fiji', 'Finland', 'France', 'French Guiana', \n",
    "'French Polynesia', 'French Southern Territories', 'Gabon', 'Gambia', 'Georgia', 'Germany', 'Ghana', 'Gibraltar', 'Greece', 'Greenland', 'Grenada', \n",
    "'Guadeloupe', 'Guam', 'Guatemala', 'Guernsey', 'Guinea', 'Guinea-Bissau', 'Guyana', 'Haiti', 'Heard Island and McDonald Islands', \n",
    "'Holy See (Vatican City State)', 'Honduras', 'Hong Kong', 'Hungary', 'Iceland', 'India', 'Indonesia', 'Iran, Islamic Republic of', 'Iraq', \n",
    "'Ireland', 'Isle of Man', 'Israel', 'Italy', 'Jamaica', 'Japan', 'Jersey', 'Jordan', 'Kazakhstan', 'Kenya', 'Kiribati', \n",
    "\"Korea, Democratic People's Republic of\", 'Korea, Republic of', 'Kuwait', 'Kyrgyzstan', \"Lao People's Democratic Republic\", 'Latvia', \n",
    "'Lebanon', 'Lesotho', 'Liberia', 'Libya', 'Liechtenstein', 'Lithuania', 'Luxembourg', 'Macao', 'Macedonia, Republic of', 'Madagascar', 'Malawi', \n",
    "'Malaysia', 'Maldives', 'Mali', 'Malta', 'Marshall Islands', 'Martinique', 'Mauritania', 'Mauritius', 'Mayotte', 'Mexico', 'Micronesia', \n",
    "'Federated States of', 'Micronesia', 'Moldova, Republic of', 'Moldova', 'Monaco', 'Mongolia', 'Montenegro', 'Montserrat', 'Morocco', 'Mozambique', \n",
    "'Myanmar', 'Namibia', 'Nauru', 'Nepal', 'Netherlands', 'New Caledonia', 'New Zealand', 'Nicaragua', 'Niger', 'Nigeria', 'Niue', 'Norfolk Island', \n",
    "'Northern Mariana Islands', 'Norway', 'Oman', 'Pakistan', 'Palau', 'Palestinian Territory, Occupied', 'Palestine', 'Panama', 'Papua New Guinea', \n",
    "'Paraguay', 'Peru', 'Philippines', 'Pitcairn', 'Poland', 'Portugal', 'Puerto Rico', 'Qatar', 'Réunion', 'Romania', 'Russian Federation', 'Russia', \n",
    "'Rwanda', 'Saint Barthélemy', 'Saint Helena, Ascension and Tristan da Cunha', 'Saint Kitts and Nevis', 'Saint Lucia', 'Saint Martin (French part)', \n",
    "'Saint Pierre and Miquelon', 'Saint Vincent and the Grenadines', 'Samoa', 'San Marino', 'Sao Tome and Principe', 'Saudi Arabia', 'Senegal', 'Serbia', \n",
    "'Seychelles', 'Sierra Leone', 'Singapore', 'Sint Maarten (Dutch part)', 'Slovakia', 'Slovenia', 'Solomon Islands', 'Somalia', 'South Africa', \n",
    "'South Georgia and the South Sandwich Islands', 'Spain', 'Sri Lanka', 'Sudan', 'Suriname', 'South Sudan', 'Svalbard and Jan Mayen', 'Swaziland', \n",
    "'Sweden', 'Switzerland', 'Syria', 'Syrian Arab Republic', 'Taiwan', 'Taiwan, Province of China', 'Tajikistan', 'Tanzania', \n",
    "'Tanzania, United Republic of', 'Thailand', 'Timor-Leste', 'Togo', 'Tokelau', 'Tonga', 'Trinidad and Tobago', 'Tunisia', 'Turkey', 'Turkmenistan', \n",
    "'Turks and Caicos Islands', 'Tuvalu', 'Uganda', 'Ukraine', 'United Arab Emirates', 'United States', 'United States Minor Outlying Islands', 'Uruguay', \n",
    "'Uzbekistan', 'Vanuatu', 'Venezuela', 'Venezuela, Bolivarian Republic of', 'Vietnam', 'Viet Nam', 'Virgin Islands, British', 'Virgin Islands, U.S.', \n",
    "'Wallis and Futuna', 'Yemen', 'Zambia', 'Zimbabwe', 'Pakistani', 'Iranian', 'Bangladeshi', 'Indian', 'Egyptian', 'Afghan', 'Albanian', 'Algerian', \n",
    "'American', 'Andorran', 'Angolan', 'Antiguans', 'Argentinean', 'Armenian', 'Australian', 'Austrian', 'Azerbaijani', 'Bahamian', 'Bahraini', 'Bangladeshi', 'Barbadian', 'Barbudans', 'Batswana', 'Belarusian', 'Belgian', 'Belizean', 'Beninese', 'Bhutanese', 'Bolivian', 'Bosnian', 'Brazilian', 'Bruneian', 'Bulgarian', 'Burkinabe', 'Burmese', 'Burundian', 'Cambodian', 'Cameroonian', 'Canadian', 'Cape Verdean', 'Central African', 'Chadian', 'Chilean', 'Chinese', 'Colombian', 'Comoran', 'Congolese', 'Costa Rican', 'Croatian', 'Cuban', 'Cypriot', 'Czech', 'Danish', 'Djibouti', 'Dominican', 'Dutch', 'Dutchman', 'Dutchwoman', 'East Timorese', 'Ecuadorean', 'Egyptian', 'Emirian', 'Equatorial Guinean', 'Eritrean', 'Estonian', 'Ethiopian', 'Fijian', 'Filipino', 'Finnish', 'French', 'Gabonese', 'Gambian', 'Georgian', 'German', 'Ghanaian', 'Greek', 'Grenadian', 'Guatemalan', 'Guinea-Bissauan', 'Guinean', 'Guyanese', 'Haitian', 'Herzegovinian', 'Honduran', 'Hungarian', 'I-Kiribati', 'Icelander', 'Indian', 'Indonesian', 'Iranian', 'Iraqi', 'Irish', 'Israeli', 'Italian', 'Ivorian', 'Jamaican', 'Japanese', 'Jordanian', 'Kazakhstani', 'Kenyan', 'Kittian and Nevisian', 'Kuwaiti', 'Kyrgyz', 'Laotian', 'Latvian', 'Lebanese', 'Liberian', 'Libyan', 'Liechtensteiner', 'Lithuanian', 'Luxembourger', 'Macedonian', 'Malagasy', 'Malawian', 'Malaysian', 'Maldivan', 'Malian', 'Maltese', 'Marshallese', 'Mauritanian', 'Mauritian', 'Mexican', 'Micronesian', 'Moldovan', 'Monacan', 'Mongolian', 'Moroccan', 'Mosotho', 'Motswana', 'Mozambican', 'Namibian', 'Nauruan', 'Nepalese', 'Netherlander', 'New Zealander', 'Ni-Vanuatu', 'Nicaraguan', 'Nigerian', 'Nigerien', 'North Korean', 'Northern Irish', 'Norwegian', 'Omani', 'Pakistani', 'Palauan', 'Panamanian', 'Papua New Guinean', 'Paraguayan', 'Peruvian', 'Polish', 'Portuguese', 'Qatari', 'Romanian', 'Russian', 'Rwandan', 'Saint Lucian', 'Salvadoran', 'Samoan', 'San Marinese', 'Sao Tomean', 'Saudi', 'Scottish', 'Senegalese', 'Serbian', 'Seychellois', 'Sierra Leonean', 'Singaporean', 'Slovakian', 'Slovenian', 'Solomon Islander', 'Somali', 'South African', 'South Korean', 'Spanish', 'Sri Lankan', 'Sudanese', 'Surinamer', 'Swazi', 'Swedish', 'Swiss', 'Syrian', 'Taiwanese', 'Tajik', 'Tanzanian', 'Thai', 'Togolese', 'Tongan', 'Trinidadian or Tobagonian', 'Tunisian', 'Turkish', 'Tuvaluan', 'Ugandan', 'Ukrainian', 'Uruguayan', 'Uzbekistani', 'Venezuelan', 'Vietnamese', 'Welsh', 'Yemenite', 'Zambian', 'Zimbabwean']\n",
    "\n",
    "countriesLower = [x.lower() for x in countries]\n",
    "#print(countriesLower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 18:00:58 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "========================\n",
      "\n",
      "2021-11-14 18:00:58 INFO: Use device: cpu\n",
      "2021-11-14 18:00:58 INFO: Loading: tokenize\n",
      "2021-11-14 18:00:58 INFO: Done loading processors!\n",
      "100%|██████████| 35305/35305 [5:04:39<00:00,  1.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Store decisions in a list to make a df\n",
    "nationalities = []\n",
    "files_nationalities = []\n",
    "\n",
    "# nlp sentence tokenizer with Stanford\n",
    "nlp = stanza.Pipeline(lang = 'en', processors = 'tokenize', tokenize_no_ssplit = True)\n",
    "\n",
    "# Open jsonData file as data\n",
    "with open('./data/jsonDataFinal.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Loop over each text file and extract Court information\n",
    "for decision in tqdm(data):\n",
    "    # Obtain the full text of the court decision\n",
    "    string = decision.get('String')\n",
    "    file_name = decision.get('File')\n",
    "    files_nationalities.append(file_name)\n",
    "\n",
    "    # Use only first third of text\n",
    "    string = string[:len(string)//3]\n",
    "    # All text in lower\n",
    "    string = string.lower()\n",
    "\n",
    "    # Apply stanford nlp\n",
    "    doc = nlp(string)\n",
    "\n",
    "    # List to store the ruling sentences\n",
    "    catch = []\n",
    "\n",
    "    # Make sentences\n",
    "    for i, sentence in enumerate(doc.sentences):\n",
    "        sente = [token.text for token in sentence.tokens]\n",
    "        # Keep only the alpha tokens\n",
    "        sente = [e for e in sente if e.isalpha()]\n",
    "        #print(type(sente))\n",
    "        catch.append(sente)\n",
    "    # Look for partial hits in text\n",
    "    nationality_leads_part = [['the', 'appellant', 'is', 'a', 'national', 'of'], ['the', 'appellant', 'is', 'a', 'citizen', 'of'],\n",
    "    ['the', 'respondent', 'is', 'a', 'citizen', 'of'], ['the', 'appellants', 'are', 'all', 'citizens', 'of'], ['citizen', 'of'],\n",
    "    ['national', 'of'], ['citizens', 'of']]\n",
    "    # Nationality not yet found (flag = 0)\n",
    "    flag = 0\n",
    "    for element in catch:\n",
    "        for part in nationality_leads_part:\n",
    "            idx_part = nationality_leads_part.index(part)\n",
    "            if sublist(nationality_leads_part[idx_part], element):\n",
    "                #print(nationality_leads_part[idx_part])\n",
    "                index = catch.index(element)\n",
    "                # Nationality lead found in catch\n",
    "                # Remove sentences before sentence with decision lead\n",
    "                new_catch = catch[index]\n",
    "                # flag2 = 1 when nationality is found in 1\n",
    "                for token in new_catch:\n",
    "                    #indx_country = countriesLower.index(country)\n",
    "                    if sublist([token], countriesLower):\n",
    "                        # Nationality found (flag = 1)\n",
    "                        flag = 1\n",
    "                        nationalities.append(token)\n",
    "                        decision.update({'Nationality:': token})\n",
    "                        #print(f'FOUND A NATIONALITY {token} in {file_name}')\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                    break\n",
    "            if flag == 1:\n",
    "                break\n",
    "        if flag == 1:\n",
    "            break\n",
    "    # If a decision has still not been found (flag = 0)\n",
    "    if flag == 0:\n",
    "        #print(f'Did not find a nationality {file_name} in catch: {catch}')\n",
    "        nationalities.append(np.nan)\n",
    "        decision.update({'Nationality:': np.nan})\n",
    "        #print(f'Did not find a nationality in {catch}')\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Save data as a json file jsonDataFinal in data directory\n",
    "with open('./data/jsonDataFinal.json', 'w') as fout:\n",
    "    json.dump(data, fout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The field \"nationality\" includes a mix of country names and nationalities. Nationalities are transformed to country names to harmonize the field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary with nationality key and country name as value\n",
    "dict_nationality_csv = pd.read_csv('data/countries.csv', header = None, index_col = 4, squeeze = False).to_dict()\n",
    "dict_nationality = dict_nationality_csv[3]\n",
    "#print(dict_nationality)\n",
    "\n",
    "# Dictionary from country name key to code3 as value\n",
    "dict_country_code3 = pd.read_csv('data/countries.csv', header = None, index_col = 3, squeeze = False).to_dict()\n",
    "dict_country = dict_country_code3[2]\n",
    "#print(dict_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35305/35305 [00:00<00:00, 962063.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# Open jsonData file as data\n",
    "with open('./data/jsonDataFinal.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Loop over each text file and extract Court information\n",
    "for decision in tqdm(data):\n",
    "    # Obtain the full text of the court decision\n",
    "    string = decision.get('Nationality:')\n",
    "    #file_name = decision.get('File')\n",
    "    if isinstance(string, float):\n",
    "        continue\n",
    "    else:\n",
    "        # If we are dealing with a nationality and not a country name\n",
    "        if string.capitalize() in dict_nationality:\n",
    "            country = dict_nationality[string.capitalize()]\n",
    "        else:\n",
    "            # Simply capitalize the name of the country\n",
    "            country = string.capitalize()\n",
    "        # Update decision in dict\n",
    "        decision.update({'Nationality:': country})\n",
    "        #print(country)\n",
    "\n",
    "# Save data as a json file jsonDataFinal in data directory\n",
    "with open('./data/jsonDataFinal.json', 'w') as fout:\n",
    "    json.dump(data, fout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a \"country\" field to the decision which includes the 3-digit code of the country of the subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 131482.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Open jsonData file as data\n",
    "with open('./data/jsonDataFinal.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Loop over each text file and extract Court information\n",
    "for decision in tqdm(data[:10]):\n",
    "    # Obtain the full text of the court decision\n",
    "    string = decision.get('Nationality:')\n",
    "    #file_name = decision.get('File')\n",
    "    if isinstance(string, float):\n",
    "        continue\n",
    "    else:\n",
    "        if string in dict_country:\n",
    "            # Get country code from dict_country\n",
    "            country = dict_country[string]\n",
    "        else:\n",
    "            country = np.nan\n",
    "        # Update decision in dict\n",
    "        decision.update({'Country:': country})\n",
    "        #print(country)\n",
    "\n",
    "# Save data as a json file jsonDataFinal in data directory\n",
    "with open('./data/jsonDataFinal.json', 'w') as fout:\n",
    "    json.dump(data, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Case title:': '',\n",
       " 'Appellant name:': '',\n",
       " 'Status of case:': 'Unreported',\n",
       " 'Hearing date:': '27 Aug 2021',\n",
       " 'Promulgation date:': '11 Oct 2021',\n",
       " 'Publication date:': '26 Oct 2021',\n",
       " 'Last updated on:': '26 Oct 2021',\n",
       " 'Country:': 'PAK',\n",
       " 'Judges:': ['Rintoul'],\n",
       " 'Document': 'https://moj-tribunals-documents-prod.s3.amazonaws.com/decision/doc_file/73739/HU202322019.doc',\n",
       " 'Reference': ['HU/20232/2019'],\n",
       " 'Download': 'Yes',\n",
       " 'File': 'HU202322019',\n",
       " 'String': '\\n                                    [pic]\\nIAC-FH-CK-V1\\n\\nUpper Tribunal\\n(Immigration and Asylum Chamber)    Appeal Number: HU/20232/2019\\n\\n\\n                            THE IMMIGRATION ACTS\\n\\n\\n|Heard at Field House                 |Decision & Reasons Promulgated       |\\n|On 27 August 2021                    |On the 11th October 2021             |\\n|Extempore                            |                                     |\\n\\n\\n                                   Before\\n\\n                        UPPER TRIBUNAL JUDGE RINTOUL\\n\\n\\n                                   Between\\n\\n                               Mr Nasir Iqbal\\n                       (ANONYMITY DIRECTION NOT MADE)\\n                                                                   Appellant\\n                                     and\\n\\n               THE SECRETARY OF STATE FOR THE HOME DEPARTMENT\\n                                                                  Respondent\\n\\n\\nRepresentation:\\nFor the Appellant:     Mr J Gajjar, Counsel instructed by M A Consultants\\n(Birmingham)\\nFor the Respondent:    Mr E Tufan, Home Office Presenting Officer\\n\\n\\n                            DECISION AND REASONS\\n\\nThe appellant is a citizen of Pakistan born on 13 March 1983.  He appeals\\nunder Section 82 of the Nationality, Immigration and Asylum Act 2002\\nagainst a decision of the Secretary of State made on 20 November 2019 to\\nrefuse his application for leave to remain in the United Kingdom.  His\\nappeal against that decision was heard in the First-tier Tribunal on 5\\nMarch 2020 and for the reasons set out in the decision of 29 April 2020\\nthat was refused.  For the reasons set out in my decision of 23 October\\n2020 (a copy of which is annexed) that decision was set aside.\\n\\nThe appellant entered the United Kingdom on 26 September 2013 with a visit\\nvisa but remained here without leave and whilst here formed a relationship\\nwith Miss Jabeen, who is also a citizen of Pakistan.  Miss Jabeen, who I\\nrefer to as the sponsor, has a son who is a British citizen from a previous\\nrelationship.  It is her case that there is no longer any contact with the\\nchild\\'s father and it is the appellant\\'s case that he has formed now a\\nparental relationship with the appellant.  The family live together and\\nuntil relatively recently the sponsor was employed.\\n\\nThe Secretary of State\\'s case before the First-tier Tribunal was that the\\nappellant did not meet the requirements of the Immigration Rules nor was it\\naccepted that the appellant had established a parental relationship.\\n\\nThe judge in the First-tier Tribunal made a number of findings.  She found\\nthat the requirements of the Immigration Rules were not met, which is not\\nchallenged, that there was a subsisting relationship between the appellant\\nand the sponsor and that there was a genuine and subsisting relationship,\\nparagraph 18, and that the appellant enjoyed a family life in the United\\nKingdom with his partner and her son.  The judge also found at paragraph 20\\nthat it was in the son\\'s best interests to remain in the United Kingdom and\\nit would be on balance not reasonable to expect him to leave the United\\nKingdom away from all his ties.  The judge did not, however, find that it\\nwould be a disproportionate interference with the appellant\\'s right to\\nrespect for his family life to leave the United Kingdom and dismissed the\\nappeal on that basis.\\n\\nThe appellant sought permission to appeal against that decision, which was\\ngranted on 15 June 2020 by First-tier Tribunal Judge Adio.  Subsequent to\\nthat the Secretary of State in a letter made pursuant to Rule 24 of the\\nProcedure Rules on 2 September 2020 stated that she did not oppose the\\napplication for permission and asked the Tribunal to determine the appeal\\nwith a fresh oral decision.  It was on that basis that on 23 October 2020 I\\nfound that the decision of the First-tier Tribunal involve the making of an\\nerror of law, albeit without the need for a hearing.  Certain findings of\\nthe First-tier Tribunal were preserved, first, that there was a subsisting\\nfamily life between the appellant, his partner and her son, and identified\\nthat it was necessary, however, to consider whether there was a parental\\nrelationship between the appellant and his stepson.\\n\\nI heard evidence from the appellant and the sponsor, both of whom adopted\\ntheir witness statements and gave evidence with the assistance of a court\\ninterpreter.  They were both cross-examined by Mr Tufan on behalf of the\\nSecretary of State.  I find some of the evidence of the appellant confusing\\nabout whether his wife was working or not and the nature of her work.\\nThere is unfortunately no documentary evidence as to the nature of her work\\nbeyond the payslips but taking their evidence together and looking at it in\\nthe round, I accept that she has ceased to work although she did work in\\nthe past.  The confusion about there being an online company is that I\\nthink that the company fulfilled online orders but the matter is not\\nentirely clear and I do accept the sponsor\\'s evidence that she is not\\nfamiliar with computers and she was not working in an online capacity but I\\nfind that despite some misgivings I might have about the evidence on that\\npoint I am satisfied that the relationship subsists and I accept that the\\nsponsor is in receipt of Universal Credit, which would make sense, given\\nthat she had previously been employed, which is not in dispute, and she is\\nalso in receipt of child benefit, which, again, would be normal in the\\ncircumstances.\\n\\nIt is for the appellant to show that his removal from the United Kingdom\\nwould be disproportionate in terms of Article 8.  It is accepted that he\\ndoes not meet the requirements of the Immigration Rules and that is the\\nstarting point for any assessment of his position with respect to his\\nArticle 8 rights.  This is a case in which I must have regard to Section\\n117B of the 2002 Act.  The starting point is that the appellant does not\\nmeet the requirements of the Immigration Rules.  He is here unlawfully and\\nhas never had any expectation of being able to stay here.  Taking that as a\\nstarting point, I consider then whether and how the subparagraphs of\\nSection 117B apply.\\n\\nFirst, the starting point would normally be that there is heavy weight to\\nbe attached in favour of removal given the failure to meet the requirements\\nof the Immigration Rules.  The appellant has not shown much of an ability\\nto speak English nor for that matter is he now financially independent and\\nthese are factors which would normally weigh against him.  Similarly,\\nprivate and family life little weight can be attached to, given the terms\\nof Section 117B(4) and 117B(5).  The question then turns on Section\\n117B(6), which requires me to make a finding of fact.\\n\\nWhether a parental relationship exists between somebody who is not the\\nbiological parent and a child is a fact-sensitive matter.  There are a\\nnumber of factors which I take into account.  First, it is not in doubt and\\nI accept that the appellant and the sponsor live together as a married\\ncouple.  I accept also that the child has had no contact with his\\nbiological father and I accept the evidence, albeit somewhat unusual, that\\nat the age of 13 he is taken to and from school by the appellant.  There is\\nalso sufficient evidence in the witness statement evidence of a close\\nrelationship between the appellant and his stepson.  Factors which would\\ntend to go against that is that it is a relatively recent relationship of\\nsome three years but I find, looking at the evidence as a whole, that I am\\nsatisfied on a balance of probabilities that a parental relationship does\\nexist between the appellant and his stepson.  It follows on that basis that\\nI am satisfied that Section 117B(6) of the 2002 Act applies in this case.\\n\\nMr Tufan for the Secretary of State urges me to dismiss the appeal on the\\nbasis primarily of the decision in Younas [2020] UKUT 129 on the basis that\\nit would be proportionate to expect the appellant to return to Pakistan and\\nmake an application for entry clearance.\\n\\nThe first point to be made about Younas is that it can be distinguished on\\nthe basis that the Tribunal in Younas found that Section 117B(6) did not\\napply, having found that it had not been established that it was\\nunreasonable to expect the child to leave the United Kingdom.  The facts of\\nthat case were very different and the child was much younger.  Secondly,\\nand perhaps more importantly, as the Tribunal noted in Younas, Section\\n117B(6) is in effect a standalone provision, that is it is described as\\nself-contained.  The discussion in Younas revolves around how a Tribunal\\nshould establish whether it is reasonable to expect a child to leave, and\\nthey concluded in that case it should. That finding is what distinguishes\\nthis appeal.\\n\\nI turn next to the more recent decision of the Court of Appeal in NA\\n(Bangladesh) [2021] EWCA Civ 953.  It is important to note what is said in\\nthat case at paragraphs 29 and 30.  At paragraph 30 the Court of Appeal, in\\nthis case Lord Justice Underhill, with whom Lord Justices Singh and Warby\\nagreed, said:\\n\\n\"It is important, however, to emphasise that the approach approved by Lord\\nCarnwath in KO (Nigeria) does not provide for a presumption in the opposite\\ndirection.  It represents no more than a common sense starting point\\nadopted for the reasons given at paras 18 to 19 of his judgment.  It\\nremains necessary in every case to evaluate all the circumstances in order\\nto establish whether it would be reasonable to expect the child to leave\\nthe United Kingdom with his or her parents\",\\n\\nI emphasise the following passage:\\n\\n\"If the conclusion of the evaluation is that this would not be reasonable,\\nthen the hypothesis that the parents will be leaving has to be abandoned\\nand the family as a whole will be entitled to leave to remain.  To spell it\\nout, in the case of a qualifying child that will be under paragraph\\n276ADE(1), in the case of the parents it will be under Article 8, applying\\nSection 117B(6).\"\\n\\nApplying that to this case, I find that as Section 117B(6) is engaged, then\\nthere is no public interest in requiring the appellant to leave the United\\nKingdom.  That is because of the express requirement of Section 117B (6).\\nFurther, given that there is no public interest, then the factors set out\\nin the remainder of section 117B do not attract materially adverse weight.\\n\\nMr Tufan\\'s submissions proceeds on the basis that there is a public\\ninterest in removal, and that notwithstanding the preserved finding that\\nsection 117B (6) is met, it is still proportionate to remove.\\n\\nWith respect, the fact that Section 117B(6) is met means that there is no\\npublic interest in removal and on that basis it is difficult to understand\\nhow in the circumstances of this case it could be proportionate, given that\\nwhilst the appellant might be able to stay with family in Pakistan, how\\nlong he would have to stay there is, given that it is on the Red List,\\nunclear and it is unclear how long it would be before he would be able to\\nbe returned.  Certainly, it would not be reasonable to require his wife and\\nstepson to go to stay with him in Pakistan, given that for the same reasons\\nit would be difficult for them to live there and to return within any\\nproper period without significant difficulty and certainly, the advice as\\nfar as I understand it , the current advice from the UK Government is that\\nnobody should be going to Pakistan (it being on the Red List) unless there\\nis a very good reason to do so.\\n\\nFurther, the fact that the appellant has a parental relationship with a\\nchild who cannot be expected to leave the United Kingdom is, given that\\nsection 117B (6) applies, a sufficiently compelling circumstance such that\\nremoval would not be proportionate.\\n\\nFor all these reasons and taking into account all the factors relevant\\nwithin section 117B, I conclude that requiring the appellant to leave the\\nUnited Kingdom amounts to a disproportionate interference with his Article\\n8 rights and I allow the appeal on that basis.  In conclusion therefore,\\nthe decision of the First-tier Tribunal involved the making of an error of\\nlaw and I set it aside.  I remake the decision by allowing the appeal on\\nArticle 8 grounds.\\n\\n\\n\\nNotice of Decision\\n\\n 1. The decision of the First-tier Tribunal involved the making of an error\\n    of law and I set it aside.\\n\\n 2. I remake the appeal by allowing the appeal on human rights grounds.\\n\\n\\n\\nNo anonymity direction is made.\\n\\n\\n\\nJeremy K H Rintoul\\nUpper Tribunal Judge Rintoul    Date 07 September 2021\\n\\n\\n\\n\\n\\n\\nANNEX - ERROR OF LAW DECISION\\n\\n                                    [pic]\\nIAC-AH-SAR-V1\\n\\nUpper Tribunal\\n(Immigration and Asylum Chamber)    Appeal Number: hu/20232/2019\\n\\n\\n                            THE IMMIGRATION ACTS\\n\\n\\n|Decided under Rule 34 Without a      |Decision & Reasons Promulgated       |\\n|Hearing                              |                                     |\\n|At Field House                       |                                     |\\n|On 23 October 2020                   |                                     |\\n|                                     |.....................................|\\n|                                     |..                                   |\\n\\n\\n                                   Before\\n\\n                        UPPER TRIBUNAL JUDGE RINTOUL\\n\\n\\n                                   Between\\n\\n                                 NASIR IQBAL\\n                        (no ANONYMITY DIRECTION MADE)\\n                                                                   Appellant\\n                                     and\\n\\n                 SECRETARY OF STATE FOR THE HOME DEPARTMENT\\n                                                                  Respondent\\n\\n\\n                            DECISION AND REASONS\\n\\n 1. The appellant appeals with permission against the decision of First-\\n    tier Tribunal Judge Phull promulgated on 29 April 2020, dismissing his\\n    appeal under the Nationality, Immigration and Asylum Act 2002 against a\\n    decision of the respondent made on 20 November 2019 to refuse him leave\\n    to remain and his human rights claim.\\n\\n 1. The appellant sought leave to remain on the basis of  his  relationship\\n    with his partner, who is settled her,  and  her  son  from  an  earlier\\n    relationship. He is a British Citizen.\\n\\n 2. The judge found [18] that the appellant has established a  family  life\\n    in the United Kingdom with his partner and her son; that it  would  not\\n    be reasonable to expect the son to leave the UK [20] but  that  removal\\n    would be proportionate as the sponsor could go  there;  or,  she  could\\n    support his application to return.\\n\\n 3. The appellant sought permission to appeal on the grounds that the judge\\n    had erred in not  making  any  finding  whether  there  is  a  parental\\n    relationship between the appellant and his partner\\'s son which would be\\n    material as if so, then section  117B(6)  of  the  2002  Act  would  be\\n    engaged; and, having found that it would not be  reasonable  to  expect\\n    the son to leave  the  United  Kingdom,  erred  in  her  assessment  of\\n    proportionality.\\n\\n 4. On 29 April 2020, First-tier Tribunal Judge Adio granted permission  on\\n    all grounds.\\n\\n 5. On 30 July 2020, Upper Tribunal  Judge  Norton-Taylor  gave  directions\\n    which  provided amongst other matters:\\n\\n      1. I have reviewed the file in this case.  In the light of the present\\n         need to take precautions against the spread of  Covid-19,  and  the\\n         overriding objective expressed in the Procedure  Rules[1],  I  have\\n         reached the provisional view,   that  it  would  in  this  case  be\\n         appropriate to determine the following questions without a hearing:\\n\\n          a) whether the  making  of  the  First-tier  Tribunal\\'s  decision\\n             involved the making of an error of law, and, if so\\n\\n          b) whether that decision should be set aside.\\n\\n      2. I therefore make the following DIRECTIONS:\\n\\n          i) The appellant may submit further submissions in support of the\\n             assertion of an error of law, and on the question whether  the\\n             First-tier Tribunal\\'s decision should be set aside if error of\\n             law is found, to be filed and served on all other  parties  no\\n             later than 14 days after this notice is sent out (the date  of\\n             sending is on the covering letter or covering email);\\n\\n         ii) Any other party may file and serve submissions in response, no\\n             later than 21 days after this notice is sent out;\\n\\n        iii) If submissions are made  in  accordance  with  paragraph  (ii)\\n             above the party who sought permission to appeal may  file  and\\n             serve a reply no later than 28 days after this notice is  sent\\n             out.\\n\\n         iv) All submissions that  rely  on  any  document  not  previously\\n             provided to all other  parties  in  electronic  form  must  be\\n             accompanied by electronic copies of any such document.\\n\\n      3. Any party who considers that despite  the  foregoing  directions  a\\n         hearing is necessary to consider the questions set out in paragraph\\n         1 (or either of them) above must submit reasons for  that  view  no\\n         later than 21 days after this notice is sent out and they  will  be\\n         taken into account by the Tribunal.  The directions in paragraph  2\\n         above must be complied with in every case.\\n\\n 6. On 2 September 2020, the respondent replied stating that  she  did  not\\n    oppose the application for permission, and invited the  Upper  Tribunal\\n    to determine the appeal at a further oral hearing to consider whether a\\n    parental relationship exists between the appellant  and  his  partner\\'s\\n    son.\\n\\n 7. The Tribunal has the power to make the decision without a hearing under\\n    Rule 34 of the Procedure Rules.  Rule 34(2) requires me to have  regard\\n    to the views of the parties.  Bearing in mind the overriding  objective\\n    in Rule 2 to enable the Tribunal to deal with cases fairly and  justly,\\n    and bearing in mind the concession by the respondent,  I  am  satisfied\\n    that in the particular circumstances of this  case  that  it  would  be\\n    correct to make a decision being made in the absence of a hearing.\\n\\n 8. I am satisfied that the judge did err in reaching her  decision  as  is\\n    claimed in the grounds of appeal and as is accepted by the  respondent.\\n    The decision clearly involved the making of an error of law as  claimed\\n    as these errors went to  the  weight  to  be  attached  to  the  public\\n    interest by operation of section 117B(6) of the 2002 Act. That required\\n    a finding as to whether a  parental  relationship  exists  between  the\\n    appellant and his partner\\'s son. That error  infects  the  findings  on\\n    proportionality which must also be set aside. Further, the judge  erred\\n    in considering that it would be reasonable to  expect  the  appellant\\'s\\n    partner to go back to Pakistan, given the finding made  that  it  would\\n    not be reasonable to expect her son to leave the United Kingdom.\\n\\n 9. I consider that the findings as to family life made by Judge Phull  can\\n    be preserved. It will, however, be necessary for the Upper Tribunal  to\\n    make findings as  to  whether  there  exists  a  parental  relationship\\n    between the appellant and his partner\\'s son and to make fresh  findings\\n    as to proportionality in any event, given the finding that it would not\\n    be reasonable to expect the appellant\\'s  partner\\'s  son  to  leave  the\\n    United Kingdom.\\n\\n\\n\\nNotice of Decision & Directions\\n\\n 1. The decision of the First-tier Tribunal did involve the  making  of  an\\n    error of law and I set it aside.\\n\\n 2. The appeal will be remade in the Upper Tribunal on a date to be fixed.\\n\\n 3. Having regard to the Pilot Practice Direction and  the  UTIAC  Guidance\\n    Note No 1 of 2020, the Upper Tribunal is provisionally of the view that\\n    the forthcoming hearing in this appeal can and should be held  face-to-\\n    face on a date to be fixed as it may be necessary to have further  oral\\n    evidence via a court interpreter.\\n\\n 4. Any party wishing to adduce further evidence must serve it at least  10\\n    working days before the next hearing,  accompanied  by  an  application\\n    made pursuant  to  rule  15  (2A)  of  the  Tribunal  Procedure  (Upper\\n    Tribunal) Rules 2008 explaining why it should be permitted\\n\\n\\n\\n\\n\\n\\n\\n       Signed                                Date 23 October 2020\\n\\n\\n       Jeremy K H Rintoul\\n             Upper Tribunal Judge Rintoul\\n\\n-----------------------\\n[1] The overriding objective is to enable the Upper Tribunal to deal with\\ncases fairly and justly: rule 2(1) of the Tribunal Procedure (Upper\\nTribunal) Rules 2008; see also rule 2(2) to (4).\\n\\n\\n',\n",
       " 'ID': '47771d4a-11ef-434c-91b4-407541e38b0d',\n",
       " 'Code label:': 'HU',\n",
       " 'Heard at:': 'Field House',\n",
       " 'Decision:': ['notice',\n",
       "  'of',\n",
       "  'decision',\n",
       "  'directions',\n",
       "  'the',\n",
       "  'decision',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tribunal',\n",
       "  'did',\n",
       "  'involve',\n",
       "  'the',\n",
       "  'making',\n",
       "  'of',\n",
       "  'an',\n",
       "  'error',\n",
       "  'of',\n",
       "  'law',\n",
       "  'and',\n",
       "  'i',\n",
       "  'set',\n",
       "  'it',\n",
       "  'aside',\n",
       "  'the',\n",
       "  'appeal',\n",
       "  'will',\n",
       "  'be',\n",
       "  'remade',\n",
       "  'in',\n",
       "  'the',\n",
       "  'upper',\n",
       "  'tribunal',\n",
       "  'on',\n",
       "  'a',\n",
       "  'date',\n",
       "  'to',\n",
       "  'be',\n",
       "  'fixed',\n",
       "  'having',\n",
       "  'regard',\n",
       "  'to',\n",
       "  'the',\n",
       "  'pilot',\n",
       "  'practice',\n",
       "  'direction',\n",
       "  'and',\n",
       "  'the',\n",
       "  'utiac',\n",
       "  'guidance',\n",
       "  'note',\n",
       "  'no',\n",
       "  'of',\n",
       "  'the',\n",
       "  'upper',\n",
       "  'tribunal',\n",
       "  'is',\n",
       "  'provisionally',\n",
       "  'of',\n",
       "  'the',\n",
       "  'view',\n",
       "  'that',\n",
       "  'the',\n",
       "  'forthcoming',\n",
       "  'hearing',\n",
       "  'in',\n",
       "  'this',\n",
       "  'appeal',\n",
       "  'can',\n",
       "  'and',\n",
       "  'should',\n",
       "  'be',\n",
       "  'held',\n",
       "  'face',\n",
       "  'to',\n",
       "  'face',\n",
       "  'on',\n",
       "  'a',\n",
       "  'date',\n",
       "  'to',\n",
       "  'be',\n",
       "  'fixed',\n",
       "  'as',\n",
       "  'it',\n",
       "  'may',\n",
       "  'be',\n",
       "  'necessary',\n",
       "  'to',\n",
       "  'have',\n",
       "  'further',\n",
       "  'oral',\n",
       "  'evidence',\n",
       "  'via',\n",
       "  'a',\n",
       "  'court',\n",
       "  'interpreter',\n",
       "  'any',\n",
       "  'party',\n",
       "  'wishing',\n",
       "  'to',\n",
       "  'adduce',\n",
       "  'further',\n",
       "  'evidence',\n",
       "  'must',\n",
       "  'serve',\n",
       "  'it',\n",
       "  'at',\n",
       "  'least',\n",
       "  'working',\n",
       "  'days',\n",
       "  'before',\n",
       "  'the',\n",
       "  'next',\n",
       "  'hearing',\n",
       "  'accompanied',\n",
       "  'by',\n",
       "  'an',\n",
       "  'application',\n",
       "  'made',\n",
       "  'pursuant',\n",
       "  'to',\n",
       "  'rule',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tribunal',\n",
       "  'procedure',\n",
       "  'upper',\n",
       "  'tribunal',\n",
       "  'rules',\n",
       "  'explaining',\n",
       "  'why',\n",
       "  'it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'permitted'],\n",
       " 'Nationality:': 'Pakistan',\n",
       " 'Representation:': ['representation',\n",
       "  'for',\n",
       "  'the',\n",
       "  'appellant',\n",
       "  'mr',\n",
       "  'j',\n",
       "  'gajjar',\n",
       "  'counsel',\n",
       "  'instructed',\n",
       "  'by',\n",
       "  'm',\n",
       "  'a',\n",
       "  'consultants',\n",
       "  'birmingham',\n",
       "  'for',\n",
       "  'the',\n",
       "  'respondent',\n",
       "  'mr',\n",
       "  'e',\n",
       "  'tufan',\n",
       "  'home',\n",
       "  'office',\n",
       "  'presenting',\n",
       "  'officer'],\n",
       " 'Appellant:': 'mr j gajjar counsel instructed by m a consultants birmingham',\n",
       " 'Respondent:': 'mr e tufan home office presenting officer',\n",
       " 'Decision label:': 'Accepted',\n",
       " 'Appellant entity:': 'm a consultants birmingham',\n",
       " 'Respondent entity:': 'Home Office'}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35305\n",
      "35305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "File               0\n",
       "Nationality    12537\n",
       "dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(files_nationalities))\n",
    "print(len(nationalities))\n",
    "#print(nationalities)\n",
    "dict_nationalities = {'File':files_nationalities,'Nationality':nationalities}\n",
    "df = pd.DataFrame(dict_nationalities, columns=['File','Nationality'])\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SANDBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with empty/corrupt files that didn't upload a sentence string\n",
    "# Regex expression: What comes in between 'Before' and 'Between'\n",
    "# regex = '(?<=Before)([\\s\\S]*?)(?=Between)'\n",
    "regex = 'representation:([\\S\\s]*)for the respondent'\n",
    "catch = re.search(regex, decision_string.lower())\n",
    "#If the catch is successful\n",
    "if catch :\n",
    "    string = catch.group(0)\n",
    "    delimiters = ['|', '?', ':']\n",
    "    # Get rid of some table delimiters\n",
    "    for i in delimiters:\n",
    "        string = string.replace(i,'')\n",
    "    # Remove leading and trailing spaces\n",
    "    string = string.strip()\n",
    "    print(string)\n",
    "\n",
    "# Path to the txt documents\n",
    "txt_path = './data/processed/txt_files_test/'\n",
    "print(os.listdir(txt_path))\n",
    "# Loop over each text file and extract Court information\n",
    "for text in os.listdir(txt_path):\n",
    "    print(text)\n",
    "\n",
    "    with open(txt_path + text, 'r') as file:\n",
    "        decision_string = file.read()\n",
    "        # Regex expression: What comes after \"Heard at\" until hitting 3 balnks or new line\n",
    "        #regex = '(?<=Heard at).*[^\\S\\r\\n]{3,}'\n",
    "        #regex = 'Before([\\S\\s]*)Between'\n",
    "        regex = '(?<=Before)([\\s\\S]*?)(?=Between)'\n",
    "\n",
    "        catch = re.search(regex, decision_string)\n",
    "        #If the catch is successful\n",
    "        if catch :\n",
    "            string = catch.group(0)\n",
    "\n",
    "            # Keep only alpha numeric\n",
    "            string = string.replace('|','')\n",
    "            #string = re.sub(r'[^A-Za-z0-9 ]+', '', string)\n",
    "            # Remove leading and trailing spaces\n",
    "            string = string.strip()\n",
    "            print(string)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n",
    "    # Loading string with court decision to data\n",
    "for txt_file in  tqdm(os.listdir(txt_path)):\n",
    "    \n",
    "    # Open file and obtain string and file_name\n",
    "    with open(txt_path + txt_file, 'r') as file:\n",
    "        string = file.read()\n",
    "        f_name, f_ext = os.path.splitext(file.name)\n",
    "        head, file_name = os.path.split(f_name)\n",
    "    # Search data list of dictionaries for dict where {\"File\":} = file_name\n",
    "    for d in data:\n",
    "        if d.get('File') == file_name:\n",
    "            # Add dictionary key 'String' with value string\n",
    "            d.update({'String': string})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for it in first half of string\n",
    "# GPE Countries, cities, states.\n",
    "# LOC Non-GPE locations, mountain ranges, bodies of water.\n",
    "#\n",
    "sp = spacy.load(\"en_core_web_sm\")\n",
    "# loop over every row in the 'Bio' column\n",
    "for text in df['Bio'].tolist():\n",
    "    # use spacy to extract the entities\n",
    "    doc = sp(text)\n",
    "    for ent in doc.ents:    \n",
    "        # check if entity is equal 'LOC' or 'GPE'\n",
    "        if ent.label_ in ['GPE']:\n",
    "            print(ent.text, ent.label_)  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0da6e46dab1e0b3d9fa32aec1170dd2df7038a4f7be3a54c97a348d8ad782954"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('tfm': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
